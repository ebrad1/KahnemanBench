Interview 7. The Motley Fool (June 2013):

Morgan Housel: We're very lucky today to have Dr. Daniel Kahneman with us. He is a psychologist from Princeton University. He's the author of the book Thinking, Fast and Slow. He's been called "one of the most influential psychologists since Sigmund Freud." He won the Nobel Prize in Economics in 2002. Please welcome Dr. Daniel Kahneman.
Dr. Kahneman, you won the Nobel Prize in economics, but you're not an economist; you're a psychologist. From what I understand, that's the first time that's ever happened in that award for economics.
To me, that's a confirmation that so much of what is important in economics and in investing has less to do with numbers and spreadsheets and Greek formulas as it does what's going on in our head, and fooling ourselves.
Just to get a background of your career, from what I understand the first time that your work intersected with economics was in the early 1970s when a colleague brought to you an economics paper and the first line of the paper was, "The agent of economic theory is rational, selfish, and his tastes do not change." For a psychologist, that's ridiculous, so what happened next?
Daniel Kahneman: Well, nothing happened immediately but I found that very surprising, actually, because the economics building was next door. I was at Hebrew University, Jerusalem, and we had one building and the economists were next door. I learned from that one sentence something I hadn't known before; that they sort of lived in a different intellectual world than we did.
For a psychologist it's obvious that people are not fully rational, and that they're not selfish, and that their tastes change. It was just a collection of statements that seemed almost absurd. I had no idea, at that stage, that a lot of my career would be dedicated to that conversation. That sort of happened almost by accident, later.
Morgan: In the last decade, behavioral economics has grown in influence. It's much more accepted now than it was in the past. I guess my question is, why did it take so long?
Kahneman: It didn't take long. Twenty-five years is a blink of an eye, in intellectual developments. Our first serious paper appeared in an economics journal, Econometric, in 1979. It appeared there by accident. We were not intending to influence economists. It was the best journal for this sort of theory paper.
I think my Nobel was 2002. That is very, very, very quick. They had two Clark medals. You know the Clark medal is really more prestigious than the Nobel in economics. It's given to the best economist under 40, and they had two behavioral ones. Twenty years is very, very fast.
Morgan: When you first started publishing the work, what was the response from different economists? What was their pushback?
Kahneman: The first response was real contempt. They just didn't take it seriously. They didn't take psychology seriously at all.
Economists know mathematics; more mathematics than other social scientists. If you know mathematics, you have a special attitude to the rest of the world, or to people who don't understand the formulas you have, so it took quite a while, actually.
Morgan: When psychology was brought into economics, was it fine-tuning around the edges, or was this taking existing theories and turning them upside down?
Kahneman: Well, it was brought as a series of challenges. The person who really created behavioral economics is Richard Thaler, who is an economist. He happened -- not "happened," it's not an accident -- he sought us out because he was a very unusual economist who was interested in what we were doing, as a graduate student.
He is the next president of the American Economic Association, so you are talking of a development in 30 years in his career.
In the 1980s he had a column in the Journal of Economic Perspectives, which was sort of the professional journal of the Economics Association. His column was called "Anomalies" and it was just facts in the world that look strange from the point of view of economic theory.
These columns were read by everybody because he writes very well and he's very witty, and everybody was exposed to it. I think that, more than almost anything else -- well, I don't want to exaggerate -- but that had a big effect on making behavioral economics respectable.
We didn't challenge the whole edifice, except that prospect theory was really saying that people cannot be quite as rational as they have been described. Dick Thaler and I did work on fairness, which showed that people are not as selfish as they've been described.
He has done a lot of work on self-control because, although that was not mentioned, self-control is viewed as part of rationality, but Dick Thaler has shown, and many others have, that people have "bounded self-control," as he describes it. They have procrastination problems.
They don't make themselves think seriously about things that matter, and they spend a lot of time dithering and thinking about things that don't matter.
The assumptions have been challenged, but economics is still pretty much the same discipline it was.
Morgan: You've talked before, that some people are more interested and curious in your work than they are in actually implementing it in their own lives and businesses, to put forth practices to make better decisions. Do you see that changing, that people are taking it more seriously, to put it into practice?
Kahneman: There is a fair amount of interest in the work. I actually don't know. The book might have some influence on this, my guess is, but otherwise my experience was giving a lot of talks at businesses and to executives, and so on.
They are really very, very interested in that stuff, until there's a sort of a hint that it might be applicable to their own business, and then they really lose interest very quickly.
This is threatening stuff, actually. It is threatening because the idea that you can question practices, or the idea that you want to reevaluate practices is threatening in any business.
They're very interested in the principles, but when it comes to something as elementary as evaluating your own performance and trying to improve your decision making... that looks like an obvious idea. You mention that idea in many contexts in financial firms, they really don't want to hear about that.
Morgan: Because they don't want to be told that they're doing it wrong.
Kahneman: They don't want to be told. That kind of message is threatening to the firm, it's threatening to the leadership of the firm. It goes very, very well until you mention something that, "Maybe you could do it yourself," and then you feel the chill in the room. It's immediate.
Morgan: Let's talk a little about your book, Thinking, Fast and Slow. The theme throughout the book is that there are two types of thinking, fast and slow; System 1 and System 2. Tell me about the difference between the two.
Kahneman: Fast thinking is, I think, most of the way that we think. It's what your memory delivers to you. You start talking, and you talk. You don't have to deliberate about one word and then the other. You walk. You don't deliberate and decide to put one foot in front of the other.
Most of what we do sort of comes automatically. Most of what we do is highly skilled and emotional -- some of it is emotional, much of it is highly skilled -- and all of that is automatic. There's just an awful lot of automatic stuff that goes on.
Then there is System 2.
If I say, "2 plus 2," a number came to your mind. That's System 1. If I say, "The relationship between China and Japan," now it's not one word that came to your mind, but a whole set of words, a whole set of ideas. I mentioned that, you were thinking islands, you were thinking war, you were thinking navies.
You might have been thinking about the history of China and Japan. A lot happened that you were not... it happened at once. Those are not explicit thoughts, but you are ready for a whole topic, as soon as I mention something. That's System 1.
I mention the word "mother," "your mother" -- you are having an emotion. That's System 1.
There's an awful lot that System 1 does. System 1 has judgments and opinions and attitudes and impressions that are generated -- like when I said, "Think of China and Japan" -- that a whole lot happened at once. You were not conscious of it all at once, but your mind was ready. It was getting ready with it.
That's the idea, that there is that thing going on in our minds, silently. Then you have System 2.
System 2 is the effortful one. It depends on the allocation of attention. It's what we are paying attention to, mostly. It's involved in computations. It's involved in difficult decisions. It's involved in controlling yourself and not telling somebody to go to hell. That demands System 2. It's all part of effortful system.
What's the relationship between the two of them? That's the interesting part.
I compare that, and maybe that image -- it's not in the book, but I now wish it had been -- I compare it to a newspaper room. You have the reporters and they are writing stories. They're interpreting the world.
Then you have an editor. In my story, the editor is sort of lazy, and is badly overworked. What the editor does mostly is endorse the stories and send them to the printer. Now, occasionally the editor will stop a story, think more slowly, assign it to another reporter, or altogether stop it, like not telling somebody to go to hell.
If you look at where the product is, the newspaper is really written by the reporters. It's not that the editor has no role. It's not that... the editor is a very important figure, but the newspaper was basically produced by the reporters. That's one theme of the book.
Basically, it's not that the editor produced the newspaper. The editor is, to a large extent, in the business of endorsing emotions and responses and impressions that come from somewhere else. The editor also is in the business of defending what's in the paper to the public.
Here went that story, and he endorsed it without really thinking about it, but now there is flak about it. Now he is asked, "Why did you publish that story?" He's not going to say, "Well, I just sent it to the printer." He's going to find a reason for why that story got...
That's the way our mind works. We believe the thing that we believe and we have the opinions that we have, not so much because we have reasons for them. If we had reasons for our religious beliefs, then people would change their religious beliefs. If we had reasons for our politics, we would change our views and arguments.
I don't want to say that nobody ever changes their minds, but people rarely change their minds. That's because our beliefs come from somewhere else. We believe the arguments that are compatible with our beliefs. It's not that we believe in things because we have the argument for them.
A lot of things, System 1 comes first, System 2 endorses and rationalizes. That's a big theme in the book, is this view of how the mind works.
Morgan: Is System 1 my gut and System 2 is my head? Is that a fair way of putting it?
Kahneman: Well, System 1 is extraordinarily clever. System 1 knows about the world. Your knowledge about the world, all your skills, are in System 1.
You drive without paying attention. That's System 1 because you have learned to drive. You maneuver social situations without getting into too much trouble most of the time. That's System 1 and it demands a lot of alertness to cues.
The "gut" -- to say System 1 is the gut -- that suggests that there is no thinking there. The best thinking we do is System 1. Creativity is stuff that comes from your memory. It's in that sense System 1.
It doesn't work the way we think it works, but it's not that System 2 is more elevated than System 1. Actually, it's... I don't want to say the reverse, but System 1 is much better at what it does than System 2 is good at what it does. That is, the automatic memory system really does an awful lot of stuff very quickly.
Morgan: When does paying attention to System 1 lead me astray and cause me to make bad decisions when I should have been paying attention to System 2?
Kahneman: Well, there are situations in which System 1 will lead you astray.
The point is, and that's another theme in the book, is that those conditions are knowable. There are kinds of judgments that we do badly, or that we don't do as well as we should. In principle, those mistakes happen in particular circumstances and for particular types of judgments.
The key thing that we did in our work was develop the notion of a bias. A bias is a systematic error, and a systematic error is very different from a random error. Systematic error is something that you can identify, when does it occur, and in principle you can correct for it.
If there is anything to be learned from the book in the applied sense, it's when to slow down. It is when to call in System 2 to correct for System 1.
Morgan: Is there the opposite side to that? When will System 1 help me make better judgments, when I should ignore System 2?
Kahneman: I think in general, when you're operating in a domain in which you're skilled, then trust yourself. It happens anyway.
When golfers want to correct their swing, they bring in System 2 and they ruin their performance for a while. That's the way that you correct your swing. It's that making yourself conscious of what you're doing, in order to do it differently.
There are many -- by and large, your advice -- if you're a good golfer, just golf. Don't ask yourself exactly what you're doing while you're doing it. Many situations where you want to trust in System 1. Not always.
Morgan: You write in the book about how not only are we not good at predicting the future, but we're not even good at remembering the past in certain situations. There was one example where you have two groups of people who are getting colonoscopies.
I'll butcher the example. I'll let you tell the story.
Kahneman: OK. Well, you know, in the first place, people here are too young to talk about colonoscopies, but in addition, colonoscopies have changed since we did that research. They used to be very painful procedures. Now they put you under and you just wake up.
At the time, it was a painful thing to go through, and colonoscopies used to last... in a study that we did, the shortest one was four minutes, I think, and the longest one was an hour and a quarter, so there's a tremendous range in terms of how long they last. There is variability within a colonoscopy. Sometimes it really hurts, and other times it's just unpleasant.
In a couple of big experiments, we had somebody next to the patient and every 60 seconds they would ask the patient, "How much does it hurt now?" on a scale from 0 to 10, I think. You get a profile of the patient's pain, and you know exactly what went on, so you know how long the colonoscopy was, and you know...
Then later, and in many different ways, we asked them about the memory they had kept from the colonoscopy. What was left with them?
It turned out that what was left was determined completely differently from what we would have thought. It was simply an average of the worst moment in the colonoscopy, and how badly it hurt when the procedure ended.
Those two variables really gave you excellent prediction of, when you ask people, "Would you want to have another one of those, or would you rather have another painful procedure?" Or you ask them, how much total pain was it? How bad was the whole experience?
There was one variable that had essentially no effect on that, and that's how long the colonoscopy was. That astonished us, how clear it was.
That's led me into a lot of thinking about what I call the Remembering Self and the Experiencing Self. That is, you have the Experiencing Self, the one who lived through the colonoscopy, but the Remembering Self is the one that keeps a score -- assigns a score and keeps a score.
Another interesting thing is that if we make our decisions, it's the Remembering Self that makes the decisions, and it doesn't always do what's best for the Experiencing Self.
Morgan: What are some other examples of how I fool myself when I remember the past?
Kahneman: I think that's the main one, but there are others. Let's not spend too much time on colonoscopies; let's discuss investing.
In the context of investing, people don't know how well they have done. There is just a lot of self-delusion that goes on when people evaluate their performance. That's an example, and an important example.
Then, in just about everything, how well the story ends is the key to how it's evaluated in the past. It's true, by the way, in presidential politics. In presidential politics, what happened in the first three years has very little impact on election results. It's really what happens, and how well the economy is doing and whether it's improving, during the last year, that determines elections.
In a lot of places, our memory just doesn't correspond to the facts.
Morgan: Is that why we remember Nixon differently than Clinton?
Kahneman: Well, I think there are many reasons we remember Nixon, but yeah.
Morgan: If I have problems remembering the past, and I'm fooling myself, how does that shape my view of the future?
Kahneman: The main thing, the main mistake that people make, it's not so much in remembering the past. It's in thinking about the past. That I spent a lot of time on, in the book.
Whenever something happens and we feel we understand it, mostly... we're surprised occasionally but by and large the world makes a lot of sense to us. It makes a lot of sense because when things happen we find their causes, and it's OK.
Except that, if you compare our ability to explain the past with our ability to forecast the future, the difference is really quite dramatic. We explain the past with the greatest of ease, and we're really crummy at forecasting the future.
What happens here is hindsight, the ability to explain the past, gives us the illusion that the world is understandable. It gives us the illusion that the world makes sense, even when it doesn't make sense. That's a big deal in producing mistakes in many fields.
Morgan: You've written about hindsight bias with the financial crisis in 2008.
Kahneman: Yeah.
Morgan: What can you tell me about that?
Kahneman: There's something I actually find shocking. There are now quite a few people who say, "I knew there was going to be a crisis."
I think that's perverse. It's a perverse use of the word "know." That's because we use the word "know" for something... when I believed in something, and my belief was true, those are the two conditions under which we're allowed to say the word "know." I believed it with very high confidence.
But in fact, they didn't know that there was to be a crisis. They thought there was going to be a crisis. Then there was a crisis, and then all of a sudden they "knew" it was going to be a crisis, but there were people who were just as smart, and as motivated and so on, who didn't think there was going to be a crisis.
What is very important about this is whether you conclude that the crisis was really knowable. Given the number and the quality of the people who failed to see it, the fact that there are many people now who are sure that they knew it doesn't convince me. I think it wasn't knowable.
It was much less knowable than we tend to think because of the ease with which we can explain it. Everybody who didn't predict it looks blind, in retrospect. That's hindsight.
Morgan: If we suffer from hindsight bias and we think that the past makes sense and was predictable, does that make us more optimistic about the future? If we think we understand the past, then we have to think we understand the future.
Kahneman: Oh, yeah. Oh, yeah, it makes us way overconfident about our knowledge of the future. Overconfidence is everywhere. If you are going to pick among the biases of judgment, then thinking that we know when we don't, that's a big one.
Thinking that we control things that we don't is another big one, so optimistic overconfidence accounts for a lot of the mistakes that are made.
In the financial context, there's a really frightening study that was published a couple of years ago. It shouldn't really surprise you, and maybe it won't, but here is the way it goes.
There is a study being conducted at Duke, I think, for many years now where they pick the CFOs of I think the biggest 500 companies and they send them a questionnaire every year. It has a lot of questions, including forecasts.
One of the things that they're asked to forecast is they're asked to set an 80% confidence interval for the S&P 500 over the next 12 months. They have thousands of those judgments because many people come year after year.
In the first place, they have no idea what the S&P is going to do. The correlation is negative between their judgment and what actually happens. It's barely significant. It's nothing. They have no idea.
The thing that's worse is how overconfident they are. When you set an 80% confidence interval, if you are at least aware of how ignorant you are, and you do that many, many times, then 80% of the time the truth will fall inside your confidence interval and 20% of the time you'll be surprised.
In fact -- I'm pretty sure that I have that correct -- they have not 20% surprises. They have 67% surprises. They have no idea, and their confidence intervals are way too narrow.
Let me tell you where the true confidence interval ought to be for the S&P 500, because I asked the authors of that study to compute it. For somebody who has no idea, looking I think at the last decade or so -- that was not counting the last two years; I think I had the computation done in 2011 -- somebody who doesn't know anything about the S&P 500, and that's everybody, the correct confidence interval, there is a true answer to that.
The correct confidence interval that the S&P with 80% probability is going to grow between -10 and +30. What's striking about this is that this sounds like you are saying nothing, and it is saying nothing because you know nothing.
That's what the confidence interval ought to be if you know nothing and you know that you know nothing. But those CFOs don't know it.
Morgan: You've also written about that we want our experts and our leaders to be optimistic. We would rather they be optimistic than realistic, which sounds crazy. Why is that?
Kahneman: We tend to take people, to a very large extent, as how they present themselves. If people are assertive and confident, we trust them. Sometimes we trust them more than we should.
We have a special taste in leaders. I think that, by and large, people like leaders who are very decisive and quick and not too deliberative, not too slow. We like people to be optimistic, and we like them to be confident.
The idea of leadership that admittedly doesn't know what it's doing, you don't want that.
Morgan: How has learning all this affected you, personally? Do you view the news differently? Do you look at money and politics differently? How has it changed your behavior?
Kahneman: It really is hard to tell. I've been studying that stuff for so long. I don't know that it's changed things fundamentally for me. I do have that deep sense that I don't understand anything, or very, very little, and that certainly I cannot forecast anything beyond a fairly short horizon.
That I'm clearer about than I think I was. I'm also a pessimist, but I always was, so that's genetic.
Morgan: This hasn't made you more pessimistic, though?
Kahneman: No, you couldn't be more pessimistic than my mother.
Morgan: To put it in a practical sense, what are some things that I can do, and everyone else can do to help live a better, more fulfilling life based on some of the stuff that you have found?
Kahneman: I would say there are a number of things, actually, that you can do.
One of them is, we do tend to neglect our Experiencing Self. I think we do too much to build up a resume, and I don't mean that in a narrow way. The resume, what I mean by that, is each of us has a story, has a narrative; the narrative of our life. It's our prized possession and we do a lot to keep it looking good. We may be doing too much for it.
There is also a matter of living, of living your life. There are decisions that you might make differently. For example, in the life/work balance, there are decisions you might make differently if you are thinking of the Experiencing Self and not only of accomplishments and goals, and things like that.
Morgan: Do we have questions?
David Gardner: Dr. Kahneman, thank you so much for visiting us at The Motley Fool. We are really pleased. We've all learned a lot from you, and we've learned even more in this hour.
When you mentioned, "The more you live, the less you feel that you know," it reminds me of a great quote from, I think it was Archbishop William Temple, who once said, "The greater the island of knowledge, the longer the coastline of mystery." I think that's a wonderful way of thinking about the progression that we all go through over the course of our lives.
I wanted to ask you simply, I see something in the financial world, because that's our world, that looks broken to me and it's probably also broken in other areas of the world, and it's that there is no scorekeeping mechanism.
If people can make predictions and no one's actually holding them accountable or scoring them, then if you think of systems thinking, it's just fundamentally broken and we can't progress. But as soon as you do start to score -- I often liken it to baseball, where everything is scored -- I wish that more for our financial world, for our political world, and others.
Do you see good score systems in the world that we should all learn from, and/or do you have any thoughts about scorekeeping? Thank you.
Kahneman: I think there is really too little scorekeeping. It's sort of astonishing when you think of those CFOs coming in year after year, and making predictions that make no sense, and they come back next year with the same level of confidence. There is no improvement. There is some absence of scorekeeping there.
On the other hand, there are really many people I think that -- most of us -- have a lot to lose from accurate scorekeeping. That's because of what I said earlier, of our ability for self-delusion, which is really a major asset in our lives. That we can lose.
I have given that advice, to keep score and when you make a decision, document the options that you considered but didn't choose. I was giving that advice a lot, and there was one place -- I didn't know it immediately -- somebody took my advice.
It was in a financial firm. I won't mention what it was. For a year, he kept track of every decision he made and the options he considered and rejected. There was a fair amount of material collected by the end of the year.
Then they told me about it, and we analyzed it. That guy was making well in excess of a million a year, and the conclusion, which I didn't share with anybody, they didn't need him. They could have saved a million dollars. He was adding nothing.
That's the kind of thing that people expose themselves to when they keep score. It's a dangerous activity.
Audience member: First off, is there a title for Nobel Prize winners? "His Nobleness"? OK, just wanted to make sure I wasn't stepping on any toes.
Have you run across any organizations or institutions that you think demonstrate good statistical thinking? Maybe you could talk a little bit about how you think that they do?
Kahneman: I think there is a lot of very good thinking that goes on in the financial world, and that most of it is proprietary so you don't get to see it.
I have seen really very good, what I thought was excellent thinking, in a couple of venture capital firms where there is acute awareness of their biases and there is acute awareness of how incentives affect biases and how you can engineer the process of decision-making so as to optimize results.
That takes a very dispassionate look at the way we do, a dispassionate look at the errors that we're most prone to, and what can we do to avoid those errors?
It takes extremely confident leadership to do that, because the moment you implement a thing like that there is a standard that allows decisions to be evaluated, and that's the big risk.
Morgan: You've talked before, too, about George Soros. One of the keys to his success is that he's so well aware of what he's bad at, and his errors.
Kahneman: There are many keys to George Soros' success. That one, by the way... that one I didn't know. It's not from me.
He claims to have a theory. He's very interesting that way. The famous story about him is that he claims to have a theory that -- and there may be something to it, but other people don't understand what it is -- but his son says that basically he has a skill, and that actually when he feels sick, that's when he sells, so that he actually listens to his gut.
That's not the way he talks. I sort of believe it. Having met him, I believe he has that skill because he is dealing at a level... he's not dealing at the level of markets. He's dealing at a level where I think there is structure that he may understand better than most other people.
Morgan: Do any other investors that you can think of have a smart decision-making process that stick out to you?
Kahneman: Well, everybody mentions Warren Buffett, who obviously is a sage, but Warren Buffett, he doesn't buy stocks. He buys companies, and he buys companies he knows a lot about. Then he has a big advantage that whenever he buys something prices rise. That's something that other people could wish for but don't have.
Audience member: Thank you for coming. We deal with a lot of members here, and psychology is a huge part of that, particularly trying to get them to lengthen their time horizon for investment. In 2008 and 2009 that was certainly a challenge.
You mentioned executives and CEOs and share buybacks; we see that they tend to buy back much more of their stock when the price is high, and then they stop those when it gets low.
Do you have any suggestions for us, as people that communicate to investors on a regular basis, to help them get encouraged to stay the course and think long-term about investing and not speculating? Thank you.
Kahneman: I think that having a very good discussion of regret with investors is a good idea, because regret is the killer. You're losing, and then you decide, "Oh, it was all wrong. Let me stop," and that's when disaster strikes, I think. It's changing course.
I think it is very important not to encourage people not to do things that are likely to expose them to regret. The potential for regret is something that investors should know about themselves. "How much am I going to suffer if this decision of mine doesn't work out?"
"How easily am I going to think, 'Oh, I made a mistake'? How prone am I to think that I made a mistake?" It's a big variable, and really worth discussing, I think, with clients because part of the inability to stay the course... you have to inoculate yourself against regret.
You have to be prepared for things to go bad. You have to anticipate that possibility. There is a lot, I think, that can be done, but not everybody is going to end up with the same advice or in the same place, because some people are much more vulnerable to these emotions than other people and they should be much more conservative.
Morgan: There's a story -- hopefully I'll get this example right -- there's a story that you wrote where you met with a financial advisor and you told her, "I don't want to get any richer. I just want to keep living how I am right now," and she told you, "I can't work with you."
Kahneman: Yeah, she fired me.
Morgan: She fired you. How do you invest your own money?
Kahneman: Terribly, I think.
I lived through a period of very high inflation in Israel for many years, where inflation was like 30%-40% a year. It really changes your outlook on life when you live through a period of high inflation.
I'm really comfortable. I really don't need to... I'm comfortable and old. I don't need to get richer.
This was a few years ago, but I told that lady this. "I don't need to get richer. I just want to guarantee that I can spend about that level for the rest of my days," and I am invested accordingly. Apparently, not optimally even for that objective, but...
The one rule I have is I give very general instructions to my financial advisor, and then I don't monitor it. I think that's good, both because it causes more anguish than pleasure, on average, and because you're tempted to make stupid decisions if you monitor things too closely.
One advice I would give to people, I think a quarterly report is probably too frequent. Just don't look too often.
Audience member: I've recently been studying an advertising agency that's been using a lot of your work to make very emotional advertisements, or advertisements that appeal to emotion. They've had some early and astounding success.
My question is, as people become more aware that they are emotional decision-makers, will the effectiveness of appealing to emotion to get people to make decisions, will that effectiveness go down?
Kahneman: It could. What happens with this, by and large, when somebody tells you something or you get a message, our inclination is to believe what we hear and to be influenced by what we hear, including emotional appeals.
Our main defense against that is to tell an alternative story. "This person is lying to me. They're manipulating me. They're lying to me." You can't keep telling that to yourself, but if an advertising agency or a whole thing gets a reputation of being manipulative and dishonest, people may be able to resist their ads better.
But by and large, it's very difficult to resist advertisement because it works not only on emotional appeal. It works on sheer frequency. It's something that is almost impossible to resist, something that gets repeated a lot feels truer. It feels more believable, and they really work on that.
Audience member: One of the great points in the wonderful book, Influence, by Robert Cialdini, is that once we take a public stand it's very difficult for us to change our minds.
I was just watching an interview with Steve Jobs last night in which he said, essentially, "I don't care about being right or wrong. I care about success. I'm willing to change my mind every five minutes when I find that there's information that I didn't have, no matter how strong the stand I took was, or how aggressive or even rude I was about that point. If I find that I was wrong I'll change my mind immediately."
I wanted to hear what you think about the process of changing your mind, and how we might encourage that inside our company.
Kahneman: I think what you point out is really one of the major difficulties in people thinking, and probably in companies and institutions; that there is some stigma attached to changing your mind.
Now, I happen to be very extreme on this dimension. I change my mind all the time, and I change my mind in research all the time. That drives my collaborators -- also, I like to collaborate so I work with people -- and I drive my collaborators crazy. I change my mind.
I keep telling them... and also I am not very respectful of their ideas, either. I keep telling them, "Look. I treat my ideas as badly as I treat yours. This is part of the process."
I think encouraging people to change their minds is a very, very good thing for an organization to do. That is, rewarding it. That we want people who can "think again."
One of the things that I find astonishing -- I now work in consulting, so it's very much on top of my mind -- you mention something to people in the business world; you suggest they should do X. Then they do X. Then two days later, I don't think they should do X. I've found a flaw in it. I think they should do X-prime or Y.
You can feel that this is really alien to them, and can they trust me if I change my own mind?
Recognizing that the ability to change your mind is just part of good thinking... that improvements in thinking are incremental. You don't find a flaw and fix it. You find a flaw and fix it, and then you find another flaw in the fixed thing. That's the way it works.
Recognizing that this is the process is very difficult, and I think very useful. Thanks for the question, by the way. I'd never heard that one before.
Audience member: In thinking about how we can apply your kind of framework to our decision-making in day-to-day life, in what domains do we stand to benefit most from System 1 thinking, and in what domains do we stand to benefit the most from System 2 thinking?
Kahneman: I think you need System 2 thinking, and you need statistics, when you're dealing with a world where there is a signal but it's faint relative to noise. That is where intuitions are worst, I think. In a world where it's not completely chaotic -- and I think the financial world is probably like that.
There are domains where there are skills that people can acquire. My guess would be -- I'm sure that's not what you do -- but that high-speed trading is probably something that people can get good at. It's a skill, like driving. You get a sense for what's going on.
I don't think you can get a sense for where the market is going. What you can get is the illusion that you have that sense, so being critical and asking, "Is it possible that we really can trust our intuitions on this? Do we have the goods? Do we have the evidence to support the proposition that intuition can be trusted here?"
Intuition can be trusted for physicians. I'll bring that example. There are domains, for a given physician; there are diagnoses that he can recognize. That doesn't mean that he can trust his intuitions, or her intuitions, about everything.
You have to know when you have the skills, and you have to know when you are guessing, which is quite difficult to do, actually.
Morgan: Who should win the Nobel Prize this year?
Kahneman: I have a perennial candidate. I want Richard Thaler to win because I invited him to Stockholm. He has to return that invitation, and it had better be in my lifetime.
He is not only my candidate. I think he's a good candidate.
Morgan: Thank you very much.
