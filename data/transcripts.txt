List of interviews

1.	Nobel Prize Interview (2002):
https://www.nobelprize.org/prizes/economic-sciences/2002/kahneman/interview/

2.	The Guardian ("We’re beautiful devices", 2011):
https://www.theguardian.com/science/2011/nov/14/daniel-kahneman-psychologist

3.	The Spectator ("He knew he was wrong", 2011):
https://www.spectator.co.uk/article/he-knew-he-was-wrong-daniel-kahneman-interview/

4.	Fareed Zakaria GPS (CNN, Jan 2012):
https://transcripts.cnn.com/show/fzgps/date/2012-01-01/segment/01

5.	Charlie Rose (Feb 2012):
https://charlierose.com/videos/15620

6.	The Guardian ("This much I know", 2012):
https://www.theguardian.com/science/2012/jul/08/this-much-i-know-daniel-kahneman

7.	The Motley Fool (June 2013):
https://www.fool.com/investing/general/2013/06/28/an-interview-with-dr-daniel-kahneman.aspx

8.	The Guardian ("Magic wand? Overconfidence", 2015):
https://www.theguardian.com/books/2015/jul/18/daniel-kahneman-books-interview

9.	Behavioral Exchange Conference (BX2015):
https://www.youtube.com/watch?v=maog6rAOI78

10.	On Being with Krista Tippett (2017):
https://onbeing.org/programs/daniel-kahneman-why-we-contradict-ourselves-and-confound-each-other/

11.	Conversations with Tyler (2018):
https://conversationswithtyler.com/episodes/daniel-kahneman/

12.	The Knowledge Project #68 (2019):
Interview: https://theknowledgeproject.libsyn.com/68-daniel-kahneman-putting-your-intuition-on-ice
Transcript: https://www.happyscribe.com/public/the-knowledge-project-with-shane-parrish/68-daniel-kahneman-putting-your-intuition-on-ice

13.	People I (Mostly) Admire (Freakonomics, 2021):
https://freakonomics.com/podcast/daniel-kahneman-on-why-our-judgment-is-flawed-and-what-to-do-about-it-people-i-mostly-admire-ep-27/

14.	Masters in Business (Bloomberg, 2021):
Interview: https://ritholtz.com/2021/05/mib-danny-kahneman-on-noise/
Transcript: https://ritholtz.com/2021/05/transcript-danny-kahneman/

15.	Issues in Science & Technology (2022):
https://issues.org/daniel-kahneman-interview-noise-judgment-decisionmaking/

16.	Max Raskin Interview (2022):
https://www.maxraskin.com/interviews/daniel-kahneman

17.	Strategy+Business 2003 https://www.strategy-business.com/article/03409 

18.	The Economist 2024 https://www.economist.com/podcasts/2024/03/30/an-interview-with-daniel-kahneman (no transcript)

19.	BBC More or Less 2012 https://www.bbc.co.uk/programmes/p00sw2w4 

20.	TIME 2024 https://time.com/6961454/daniel-kahneman-death-interview-thinking/ 

21.	NPR Hidden Brain https://www.npr.org/transcripts/592986190 

22.	A Conversation with Daniel Kahneman Catherine Herfeld https://philarchive.org/archive/HERACW-2 

23.	Interview 23. TED Adam Grant Taken for Granted: Daniel Kahneman Doesn't Trust Your Intuition https://www.ted.com/podcasts/taken-for-granted-daniel-kahneman-doesnt-trust-your-intuition-transcript 

24.	Daniel Kahneman on wellbeing and how to measure it | University of Oxford 2022 https://www.youtube.com/watch?v=rf8rLu6vKgM&ab_channel=WellbeingResearchCentre%28UniversityofOxford%29 

25.	UNSW Daniel Kahneman in Conversation https://www.youtube.com/watch?v=I-R3W5GNqxM&ab_channel=UNSW 

26.	The Psychology Podcast Best of Series: A Remarkable Life, Fast and Slow || Daniel Kahneman https://www.youtube.com/watch?v=0daBYBs4ojM&ab_channel=ThePsychologyPodcast 

27.	TED Audio Collective 2022 https://www.youtube.com/watch?v=vvMYBEaz8bo&ab_channel=TEDAudioCollective 
 

Nobel Prize Interview (2002)
https://www.nobelprize.org/prizes/economic-sciences/2002/kahneman/interview/ 

Interview with the 2002 Laureates in Economics, Daniel Kahneman and Vernon L. Smith, December 12, 2002. Interviewers are Professor Karl-Gustaf Löfgren and Dr Anne-Sophie Crepin.
The Laureates talk about why they decided to become economists, their work (3:35), the challenges working in different disciplines (9:03), if there is a life in economics after 50 (15:14), give advice to young students (20:08) and talk about their recent work (24:18).
Interview transcript
Welcome. I’m Karl-Gustaf Löfgren, Professor of Economics at the Umeå University. Next to me is Anne-Sophie Crepin who holds a PhD in Economics from Stockholm University. Together we have the pleasure of interviewing the winners of the 2002 Bank of Sweden Prize in Economic Sciences in memory of Alfred Nobel. The winners are Professor Daniel Kahneman from Princeton University and Professor Vernon Smith from George Mason University. Professor Kahneman is a psychologist who has changed the way economists think about decision making and, in particular, decision making under uncertainty. Professor Smith has taught economists how to conduct and learn from experiments like in the sciences and I’ll ask you Anne-Sophie to ask the first question.  Please go ahead.
Well Professor Kahneman, what made you decide to become a scientist?
Daniel Kahneman: I wanted to be a philosopher actually and I decided, I became interested in psychology as a substitute for philosophy, as a way of answering questions about the human condition but answering them by looking at facts rather than by discussing words. So that’s how I became a psychologist.
And Professor Smith, your answer too?
Vernon Smith: Actually I was interested in philosophy at one point. This is before I really was seriously into my undergraduate training, so it was just a reading interest of my own and I read Sir James Jeans’ Physics and Philosophy and Sir Arthur Eddington’s books and Burton Russell; I was interested in science and philosophy and originally I expected to study science and I went to Caltech for that reason and I did study physics and would have taken my degree in physics, my undergraduate degree, except for one hurdle.
 So I took electrical engineering because I chickened out …
To take the degree in physics you had to take Smyth’s course, a famous course that was very, very hard to get through. By taking my degree in electrical engineering I didn’t have to take Smyth’s course but I took everything else in physics. So I took electrical engineering because I chickened out and I wanted to finish on time. But I got interested in economics as a senior; I took a course in economics and at the time I thought, well you know, this just looks like physics and little did I know how deceptive that was. But anyway that was my naïve view at the time.
Well if we turn to your research. I mean one of you has shown that people are frequently irrational in their economic decision making and the other has shown that the market mechanism works efficiently, at least in the lab. How would you reconcile these seemingly different views, I mean both of you?
Vernon Smith: Question to me?
To both of you.
Vernon Smith: Well, let me begin. I think it’s fairly simple. In experimental economics we have three classes of results. We have situations in which people do better for themselves as individuals and as a group and is predicted by economic theory. Ok. I call that super rationality. We have a second class of results where the predictions of economic theory do very well and they conform and I’ll come back to what those are shortly and thirdly we have results which people do not do as well as predicted by theory. The first is in two person extensive form games. We use the term personal exchange there. Too many people cooperate relative to the predictions of the economic, not everyone in single play games but up to half and so we have to come to terms with that. The experiments where the theory of markets does extremely well is where we’re talking about production and consumption markets; flows. We think of consumers as daily or regularly enjoying the value from what they buy in markets and producers regularly incurring a cost to produce that.
Those markets, if you study them in the lab are remarkable efficient and although their ability to converge to the equilibrium predicted by the theory varies with the institution, they basically all function quite well but the third class of phenomena where the predictions are not good is in what we call asset markets or capital markets and there’s an inherent uncertainty in stock markets and we capture that in these laboratory games and those do not converge quickly and easily to what you might call rational expectations equilibrium. If you hold the environment constant for kind of 3 times back, and now we’re talking about 6 hours of experiment, it gets home, ok, but that’s not very inspiring or encouraging because the world out there it doesn’t stand still while people look for the rational expectations equilibrium. So does that help to clarify?
Yes, I think so. Professor Kahneman?
Daniel Kahneman: Well the first comment I would make is about the word irrationality as characterising the research that we have done. I never think of myself as having demonstrated irrationality. There is a definition of rationality within the contest of economic theory or decision theory more broadly, which is a completely unrealistic conception of a human agent with a complete preference order about all states of the world, with a Bayesian set of beliefs about all possible states and this defines rationality in the context of economic theory.
Now as a descriptive hypothesis this is a totally implausible hypothesis and, you know, it is fairly easy to show that that hypothesis isn’t true and we’ve been doing that, my late colleague Amos Tversky and I, and many others. It’s also not particularly interesting to show that it isn’t true because it’s so easy to do. We have been able to show some of the ways in which people depart from this ideal of rationality but this is not irrationality. People are reasonable, they’re prudent agents. It’s just that the definition of rationality that is used in economic theory is, I think, a very implausible definition and it fails descriptively and we have been able to document some of these failures and explain them.
Both of you have worked in the frontier between different fields; economics and psychology and natural sciences with experiments. What kind of difficulties or what kind of challenges did that implement for you?
Vernon Smith: Well, I think if you are curious about some of the things we observe in economics and you want to better understand this phenomena, whether it’s in a laboratory or the field, I really think you have to reach outside of economics because economics, although it has an incredible body of technique it’s developed and the methodology that has value it’s much too, I think, restrictive to embrace the range of observations. So you have to reach outside and actually if you go back to the Scottish philosophers, David Hume and Adam Smith, they were not narrowly oriented in the way that we often think of as modern economics. Adam Smith had huge breadth. He wrote the definitive History of Astronomy, 18th century. He was probably the first great post Newtonian scientist and he wrote on other aspects of human sociality besides just what has become known as economics narrowly construed.
I guess he was a philosopher of moral philosophy wasn’t he?
Vernon Smith: Well, yes and of course we didn’t have a clear delineation of the fields like we have now. Well I think a lot of the work on experimental economics points us back to that period and a need to pick up on some of the inspiration that was behind people like Smith and Ferguson and Hume and others and I hope in fact my work will help to encourage that, not because they had it right, it’s because we know a lot more, obviously, after 200 years but there’s certain themes there that we’ve lost, that we’ve sort of abandoned and that’s unfortunate.
Professor Kahneman?
Daniel Kahneman: Amos Tversky and I started working together on the field of judgment and decision making and we were just doing psychology. So we were not intending to talk across the disciplines but eventually, and that came as a bit of a surprise to us, the work that we did was, to some extent, influential in economics. I mean this is of course why the prize is given because of the influence. Now what is remarkable to me about this is actually both the ease and the difficulty of communicating across disciplines. In our case I think we’ve had a very easy time. You know, it’s not that economists have flocked to the ideas that we’re bringing, you know, behavioural economics is a minority movement and not everybody is convinced of its value but by and large I would say that, you know, I have been quite surprised by, you know 20 years is a short time for ideas to have an effect and, you know, our ideas have had whatever influence they’ve had relatively quickly.
What impresses me is how chancy this is, that is this is entirely accidental, that is the communication if we had published exactly the same paper, which is cited in the award prospect theory, if we’d published that word for word in Psychological Review, in the Journal of Psychological Theory there would have been no Nobel Prize for this work today. So it was because it happened to be published in Econometrica that this happened.
But also the most cited paper in Econometric ever.
Daniel Kahneman: Yes, but in part it is a very highly cited paper. I should add, you know, this doesn’t make it all that influential in economics because most of the people who cite the paper are not economists. So I don’t know how many economists cited it; it’s a well known paper in economics as well but if it had been published in another discipline it would simply not have had an impact and I think this is in part what Vernon is saying, economists do not spontaneously look outside the discipline. So if you look at the journals that are cited in the economics literature they tend to be economics journals. So we were quite lucky, you know, in the sense that publishing in Econometrica and we did that because it was the prestige journal for decision theory at that time. We thought we had a good paper and so we sent it to the best journal that would publish it and we were then lucky in a completely different way in that a young and very brilliant economist, Richard Thaler, read about our work actually before it was published and was influenced by it and he really, not we, developed behavioural economics. So it was his doing and it was through his work that our work became known and he deserves a great deal of the credit for, you know, what’s happened since.
Ok. Before we leave the research side of things, I mean you published your award winning papers before 50. Is there a life in research after 50 or is economics a young man’s game like mathematics?
Vernon Smith: Well I think that’s probably not unusual across most of the prizes although I’m just conjecturing that that’s probably true. Certainly Albert Einstein had some of his basic instincts before he was of age and particularly I think that’s true in physics but it’s young minds that tend to get inspired. I think it also has to do with the sociology of professional work. It’s young people who chart new courses that change things. It’s not the existing scientific community that suddenly has a transformation and, you know, my friend Paul Samuelson points out that science progresses funeral by funeral.
Daniel Kahneman: Well, I mean to your question of whether there is life after 50, I certainly hope so. I think Vernon has done some of the work that, you know, has done wonderful work in very recent years so there may be life after 70 and, you know, to some extent this again is accidental and is self selection, that is if you are going to have people who are going to have important ideas, they may have them fairly early in their career and then they spend the rest of their careers elaborating on these ideas and so it looks as if, you know, people have their best ideas early on but that’s because they spend the rest of their lives working on them and I think, you know, this happens to most people who have one important theme to develop.
Vernon Smith: Well I think young people are sort of maybe more likely to make technical or mythological breakthroughs but just looking at my own history I didn’t really appreciate the full ramifications at the time I was doing that work. I didn’t come close to it and I think that can come with maturity so that the contribution you can make after aged 50, and I hope after age 75, is perhaps a different type of contribution than one makes when you’re younger.
Daniel Kahneman: Yes, I would echo that. It takes a long time to understand what you’ve been saying. So, you know, you say it first and then, over the years, you understand what it was that you really meant because you don’t know that immediately. In my particular case I was fortunate because there were two of us and that process of understanding what we said worked faster because we understood each other but when you work alone, understanding what you’re saying is a long drawn process.
Vernon Smith: Well and I recognise, understood early that a component of what I was doing had to do with institutions and rule systems but I didn’t begin to understand it the way I now do and a lot of that understanding came from interacting with other people over the years, Charlie Plott is a prime example, and also Martin Shubik, he and I are exactly the same age. I think I’ve known Martin for over 40 years, I think about 45 years and we often exchanged ideas, having to do with institutions and Martin was very interested in and that interchange was very valuable to me even though we never worked together and of course I worked with Charlie Plott and a lot of our insights came working together.
What kind of advice would you give to young people considering a research career?
 … I tell my graduate students that if they don’t fall asleep thinking about work, you know, then they’re not working hard enough …
Daniel Kahneman: Oh, you know, there are lots of pieces of advice. I tell my graduate students that if they don’t fall asleep thinking about work, you know, then they’re not working hard enough actually, you know, so that’s the first piece of advice that you would give them and the second one is to try not to get trapped in uninteresting problems just because you began them. So one of the important things to have in science is to avoid the sunk cost fallacy, just to keep going with something just because you began it and have made an investment. So the ability to just make a quick turn when you’ve had an idea that looks better and drop everything else and follow the best idea that you have at the moment, that is certainly one of the thing that I think worked for me and I think it may work for other people as well.
Professor Smith?
Vernon Smith: Yes, I would echo that. Don’t follow the path of least resistance. Be prepared to break the informal rules. You have to of course live in your environment and so there’s a limit to how far you can go in breaking the rules. I was interested in experimental economics long before I could really make a living at it so I did other things and I didn’t get tenure doing experimental economics, I got it doing other things but I returned to experimental economics and one of the problems can be that in getting tenure you develop all these bad habits and then you can’t get out of doing the bad habits, which is doing what’s easy, you know, following your sunk cost and doing trivial kind of extensions of that.
Daniel Kahneman: And trying to salvage failures, that is when something is not working there are people who spend a lot of time trying to get something out of an experiment just because they did it. I’m sure that’s good advice to avoid that.
Vernon Smith: I think young people in economics are well advised to read widely outside of economics too and I think fairly narrowly within economics is good enough because the theories tend to be very similar anyway. Once you sort of get that basic model it’s better to … I read Science and I read Nature, those 2 magazines, they’re weeklies. I can’t follow everything in them but I do find things in there that intrigue me.
Daniel Kahneman: This is unusual, you know, in economics. 18 years ago when we first came to Berkeley, George Akerlof invited me to co-teach a course with him and we taught a course on economics and psychology and there are two things to be said about that course. One is, he didn’t get credit for teaching it because it was considered a frivolous thing to do and the other one was that he kept advising and warning the students not to be seduced by it because he thought it could ruin their careers if they followed that path. So he would tell them, you had better stick to what he called meat and potatoes economics and, you know, you can afford to do those strange things after you get tenure.
Vernon Smith: Too late, he’d formed all his bad habits.
Well how important has it been to you? I mean your scientific result can be applied to, what did Nobel say, to the benefit of mankind? I mean you followed your track, you found something that was interesting and pursued that?
Daniel Kahneman: I would say that the conscious sense of doing something that could be truly beneficial, well I had that early on when I thought that people could be educated to think, you know, more closely and these efforts of mine have not been rewarded. In recent years I’m consciously trying to do something for the benefit of mankind and this is to develop new and better measures of human welfare and human wellbeing that could be applied as another measure of how society is doing and I’m doing that with collaborators, including an economist at Princeton, Alan Krueger, and that is truly with the idea of trying to do something that could be useful to policy making.
You have something to say Vernon?
 … the laboratory is a very useful tool for allowing people to get experience …
Vernon Smith: Well, I’ve become more interested, particularly in the last 20 years roughly as against the first 20 years, in utilising what we’ve learned about markets to do a better job of helping to design markets in new areas where people don’t have any experience, any field experience and I think the laboratory is a very useful tool for allowing people to get experience. It doesn’t provide the final experience and the final answers but the point is it is experiential and it gives people an opportunity to try out and test bed new rule systems, practitioners for example, and we found business and government, in some situations, very receptive to that. In governments, particularly in New Zealand and Australia, with respect to the liberalisation of electric power and I think we’ve seen in the California fiasco how bad things can be if you don’t think about some fundamental issues and furthermore, in that case, a lot those issues had long been studied in the laboratory and in fact influenced New Zealand and Australia but we didn’t have an opportunity to have that much influence in California. It isn’t that we didn’t communicate with any of the people that might have made a difference, it’s just that we couldn’t convince them or influence them enough. And also it turned out to be far worse than even we would have imagined as to the consequences of really not getting some elementary features of these markets right.
Daniel Kahneman: They need some help. Many years ago when we were studying failures of rationality in judgement and decision making I thought, you know, that there was a contribution to be made, for example to government decision making or to making political decisions but 25-30 years ago that was a period when the discipline of decision analysis looked extremely helpful and hopeful and it seemed as if the combination of psychology and decision analysis could be very, very useful. It has not been. I mean by and large I think this has been a failure and the reasons are quite interesting. The reasons are that the leaders do not want the help, that is the people who make decisions, important decisions, by and large do not want the kind of help that decision analysis or decision aids have to offer that we would think, you know, would certainly improve the quality of decision making. So there is a great deal of resistance and that, by itself, is quite interesting, that it’s been 30 or 40 years, you know, since decision analysis was first proposed and, by and large, very little has happened.
Well, after this interesting word I would like to thank you on behalf of the Nobel Foundation for giving this interview. Thank you very much both of you.
Daniel Kahneman: Thank you very much.
Vernon Smith: It’s a pleasure to be here.
 
Interview 2. The Guardian ("We’re beautiful devices", 2011):

The Nobel prize-winning psychologist Daniel Kahneman lives in an airy penthouse on the 14th floor of an apartment block in downtown Manhattan, not far from the Eighth Street subway station. But never mind that for a moment. Instead, without thinking too hard about it, try answering the following question: roughly what percentage of the member states of the United Nations are in Africa? (I'll wait.)
The correct figure isn't what's important here. What matters is that your answer is likely to be lower than if you had first been informed that Kahneman is 77 years old, or if I had claimed his apartment – where he lives with his wife, the British-born psychologist Ann Triesman – was 60 floors up, and near the 86th Street station. This is the phenomenon known as the "anchoring effect", and it is typical of Kahneman's contributions to psychology in that it suggests something rather disturbing about the human mind: not just that we're susceptible to making skewed judgments, but that we're influenced by factors more subtle and preposterous than we could ever imagine.
Kahneman's new book, Thinking, Fast and Slow, is a meaty memoir of his life's work that describes countless such cognitive quirks – but don't imagine that reading it will cure your irrationality. "It's not a case of: 'Read this book and then you'll think differently,'" he says. "I've written this book, and I don't think differently." Kahneman, whom Steven Pinker calls "the most important psychologist alive", is twinkly and energetic. But beneath the surface, he is a pessimist. And he is allergic to the notion that his book might be mistaken for self-help. It's his first work aimed at a mass audience, and he hated writing it: "I really did not want to disgrace myself in front of my colleagues, and I worried the public wouldn't like it if it read like a textbook. Also, I really don't like old men's books, and I felt I was writing an old man's book." Eventually, in despair, he arranged to pay four younger psychologists $2,000 each to review his manuscript anonymously, and to tell him the brutal truth: should he bother finishing?
They liked it. So did I. It's hard not to: Kahneman's approach to psychology spurns heart-sinking tables and formulae in favour of short, intriguing questions that elegantly illustrate the ways our intuitions mislead us.
Take the famous "Linda question": Linda is a single 31-year-old, who is very bright and deeply concerned with issues of social justice. Which of the following statements is more probable: a) that Linda works in a bank, or b) that Linda works in a bank and is active in the feminist movement? The overwhelming majority of respondents go for b), even though that's logically impossible. (It can't be more likely that both things are true than that just one of them is.) This is the "conjunctive fallacy", whereby our judgment is warped by the persuasive combination of plausible details. We are much better storytellers than we are logicians.
If any of this sounds familiar, it's because Kahneman and his collaborator Amos Tversky, who died in 1999, are the primary inspiration for many of the past decade's pop-psychology books – the publishing phenomenon that brought you tipping points and freakonomics, the wisdom of crowds, black swans, and "predictable irrationality". It is a trend that one unimpressed reviewer of Kahneman's book labelled "the effect effect". In the early days, academics took a similarly sniffy view of Kahneman and Tversky's research: Kahneman recalls one well-known American philosopher turning his back on him at a party with the disdainful words: "I am not really interested in the psychology of stupidity." That soon changed, though, as the pair's influence spread rapidly throughout the social sciences, culminating in 2002, when Kahneman became one of a handful of non-economists to win the Nobel prize in economics.
"The psychology of stupidity" is not, in any case, a very apt summary. Kahneman's point isn't that we're all wildly bizarre or idiotic, but that our mental apparatus, which works so well most of the time, sometimes leads us astray in predictable ways. "We're beautiful devices," he says. "The devices work well; we're all experts in what we do. But when the mechanism fails, those failures can tell you a lot about how the mind works."
In Thinking, Fast and Slow, he presents this as a drama with two "characters": System One, which is the domain of intuitive responses, and System Two, the domain of conscious, effortful thought. System One – the kind of mental ability celebrated in Malcolm Gladwell's book Blink – kicks in without our needing to think about it. The problem is that it always tries to help, even when it shouldn't, and that it works with whatever it's got, which isn't always the most sensible information.
The biggest challenge this posed was to economists, most of whom assumed that people were basically rational and selfish and acted in their own best interests. The work that won Kahneman the Nobel showed otherwise. For example, we hate losing things more than we like gaining them, which is why people refuse to sell their home for less than they paid, even if it makes financial sense to do so. Similar biases make us behave strangely where risk is involved, too: if forced to choose between being given £500 for certain, or a 50% chance of winning £1,000, most of us will opt for the sure thing. But if the choice is between losing £500 for sure, or a 50% chance of losing £1,000, most of us will take the gamble.
Then there's the much-cited thought experiment involving tickets to the theatre. Suppose a woman plans to buy a ticket for a play costing £40, but en route to the theatre she realises she has lost two £20 notes in the street: would she still buy the ticket? Most people, when asked this question, assume that she would. But what if she bought the ticket in advance, then arrived at the theatre to find she'd lost it? In that case, people assume she'd go home without buying another ticket – even though the scenarios are financially identical. As Richard Thaler, another leading light in the revolution that became known as behavioural economics, told an interviewer, Kahneman and Tversky's research meant that "rationality was fucked". Kahneman, on the other hand, likes to say that you'd need to study economics for years before you'd find his research surprising: it didn't surprise his mother at all.
Kahneman was born in 1934, the son of Lithuanian Jews, and grew up in France. Life was generally good until 1940, when German forces swept in. He recalls drawing, around that time, "what was probably the first graph I ever drew", showing his family's fortunes over time – "and around 1940 the curve crossed into the negative domain." His father was captured during a large-scale sweep of Jews in France, but somehow escaped being sent to a concentration camp and was let go instead. ("The story of my father's release, which I never fully understood, also involved a beautiful woman and a German general who loved her," he wrote.) The family kept moving across France. "The feeling was of being hunted," Kahneman recalls. At one point their home was a chicken coop at the back of a pub. In 1944 his father died of insufficiently treated diabetes, six weeks short of D-day. As soon as the war ended, his mother took the family to live in Palestine, in what would soon become Israel.
Kahneman was drafted into the Israeli army in 1955, where he served as an infantryman for a year – "it was a very tense time, but I never fired a shot in anger" – then worked as a military psychologist. One of his roles was to evaluate new recruits by watching them perform the "leaderless group challenge", in which teams of eight men had to transfer themselves, and a large log, over a 6ft-high wall, without anybody, or the log, touching the wall. The task was designed to reveal the participants' true character, and thus demonstrate who had the making of a future leader. As a method of psychological evaluation, it wasn't much good: Kahneman made predictions, but follow-up research revealed them to be little better than guesses. What the experience taught him, in the end, wasn't how to spot a future hero, but rather how hard it was to expunge his own confidence in his predictions. "We knew as a general fact that our predictions were little better than random guesses," he writes. "But we continued to feel and act as if each particular prediction was valid." Confidence is a feeling, not a logical conclusion reached after analysing statistics. Kahneman would later encounter the same phenomenon among investment advisers, who clung to their belief in their abilities even after it was demonstrated that their stock-picking skills left their clients no better off than rolling dice.
The intellectual relationship that defined his career began in the late 1960s at Hebrew University in Jerusalem, when he met Tversky, a young colleague. Kahneman describes their bond as "magical", and it sounds much more like a loving friendship than a scholarly collaboration. For several years, the two spent hours every afternoon in freewheeling conversations, examining their own hunches and intuitions, gradually developing the list of biases and fallacies for which they became famous. "He got up late, and I was a morning person, so we started with lunch, and took it from there," Kahneman remembers. "This kind of collaboration is very unusual in science. We were just extraordinarily lucky, and we knew it." The editor of the journal to which they submitted their first major paper rejected it; their work seemed too frivolous for the academic establishment. "Psychologists really aim to be scientists, white-coat stuff, with elaborate statistics, running experiments," Kahneman says. "The idea that you can ask one question and it makes the point ... well, that wasn't how psychology was done at the time."
With hindsight, however, those single questions seem anything but frivolous. The irrational traits they uncovered are, to pick one notable example, hugely important in understanding the causes of the current economic crisis, which has its roots in (among others) the overconfidence bias and the illusion of skill. If we can't hope to correct such biases in any lasting way, we can perhaps seek to cultivate some humility about the limits of our mental powers. Being the puppet of subtle psychological influences we cannot even recognise is annoying. But at least we can try to remember that that's what's likely to be happening. Well, it's a start.
Interview 3: The Spectator ("He knew he was wrong", 2011):

When I was 13, my school cricket team received a visit from a top professional cricket coach, an intoxicating visit from the big leagues. I tried to hear what the great man was saying as he watched us, how he advised our teacher. ‘Never praise kids — they only mess it up next time,’ I overheard him say. After pausing to berate me for a below-average cover drive, he whispered to the teacher, ‘It’s different with criticism — that really works.’

Like a typical cocky teenager, I longed for a clever riposte. Perhaps fortunately, I didn’t have the intellectual insight to deliver one. But last week I met up with the man who did — Daniel Kahneman, professor of psychology, winner of the Nobel prize for economics and author of the newly published Thinking, Fast and Slow.

In the late 1970s, he was teaching flight instructors in the Israeli Air Force about the psychology of effective training. He told the instructors that praise rather than criticism was the best way to help the cadets improve. An experienced instructor disagreed with him: ‘On many occasions I have praised cadets… the next time they usually do worse. On the other hand, I have often screamed into a cadet’s earphone for bad execution, and in general he does better on his next try.’


Kahneman realised that the instructor was making a mistake. If a cadet did something better than normal, his next attempt at the task would in all likelihood not be as good, whether or not he was praised. In the same way, if he performed unusually badly, his next attempt would probably be better, whether or not he was criticised. The trainer was attaching a causal interpretation to the fluctuations of a random process; simple regression to the mean. Kahneman had been teaching regression to the mean for decades, and had the scholarship to understand how the instructor was being misled by his intuition. He knew it was possible to infer wrong explanations even from accurate observations.

‘That was a true Eureka moment,’ Kahneman explains to me, looking anxiously in the direction of a pianist who is threatening to start playing in the lobby of his central London hotel. ‘It was like being in a place for the first time that nobody has seen before. I enjoyed that quite a lot.’ Much of his career has been spent testing similar cases, when intuition seems sound but is logically and statistically misleading. Kahneman is the master student of human error.

Seventy-seven years old, soberly but neatly dressed in a grey suit with a dark green tie, with immaculate manners and a mischievous expression, Kahneman speaks in measured, precise sentences. A lifetime of studying overconfidence has made him careful to avoid the same mistake himself. His book distinguishes between two distinct modes of thinking. System one operates automatically and quickly, with little effort and no sense of control. System two requires reflection, concentration and complex calculations.

The problem comes when we use system one in an inappropriate environment, when we use intuition when it cannot be trusted. ‘Type one is specialised for making instantaneous connections. You get a cold, you ask “Where did I catch it?” We’re constantly looking for causals and telling stories. It’s really absurd.’

Many of Kahneman’s experiments were designed to disprove his intuitions, to catch himself indulging misleading hunches. As a professor, he suspected himself of marking exam papers lazily by giving undue weight to the examinee’s first answer, sticking with a snap judgment. It’s called the halo effect: once a good impression exists, it is difficult to dislodge. His solution was to stop marking exam booklets beginning to end. Instead, he marked the first answer of every student, writing each mark on the inside back page of the booklet where he couldn’t see it. Then he marked all the second answers, and so on. As he puts it, he wants ‘to decorrelate error’.

Kahneman had a distinguished collaboration with Amos Tversky. ‘We posed riddles to each other and invented questions in an attempt to elicit intuitions which were wrong.’ In a famous experiment, Tversky tested the basketball cliché that a player gets a ‘hot hand’ when he shoots three or four consecutive baskets, making him more likely to succeed with his next attempt. There is no such thing as a ‘hot hand’. Some shooters are more accurate than others. But the sequence of successes and misses is no different from those achieved by random tests. Conclusion: coaches should give the match-deciding shot to their consistently highest percentage player, not to the guy on a hot streak that day.

As I’m hearing about the flaws of intuition, I can’t help wondering if there are some dangers to the Kahneman approach. As a cricket captain, I had to make dozens of decisions, usually on incomplete evidence. Kahneman-type thinking would have made me mistrust my gut instinct. Even if I’d made better decisions, I would have radiated less confidence in them — and leadership is often about appearances as much as reality. After all, there are two elements to any plan. The first is the decision, the second is the execution — and your conviction that it’s the right idea can affect the execution.

I’m quite surprised that Kahneman agrees. ‘Being an optimist is clearly very good in the context of execution. I agree that confident leaders attract resources and gain loyalty. Confidence and optimism are wonderful things to have, but the cost can be that people take risks that they shouldn’t with the lives of other people.’

Given his awareness of those risks, could he have been a man of action, a politician, a general or a CEO? ‘I couldn’t be any one of those things because I second-guess myself too much. Leaders are selected for the ability to resist second-guessing themselves.’ But he can’t resist adding a Kahneman refinement. ‘I think we penalise reflective leaders because they appear to lack decisiveness. People confuse decisiveness with speed. It’s rare to hear a good word about President Obama these days. But actually he is both slow and decisive. He tries to be reasonable and that’s not what we want in a leader.’

We may not want it in a leader (though we may need it). But we definitely want it an academic.
 
Interview 4: Fareed Zakaria GPS (CNN, Jan 2012):

My next guest is Daniel Kahneman and he will explain. He is the recipient of the Nobel Prize for Economics, but he is actually a psychologist. And he has a new book out, a terrific book, "Thinking, Fast and Slow."

Welcome. Professor, pleasure to have you on.

DANIEL KAHNEMAN, PHD, NOBEL LAUREATE IN ECONOMIC SCIENCES; AUTHOR OF "THINKING, FAST AND SLOW": Glad to be here.

ZAKARIA: So what struck me about that example is that it is a perfect example of why it's not a good idea to think fast. You know, you're convinced you're right and it's dead wrong. What is it that we're doing there that - that makes that happen?

KAHNEMAN: You know, there are two things. One is something that happens in your mind, it's the association. For some reason that problem brings $0.10 to mind. And the other thing is something that doesn't happen. You don't think and that's the key difference.

ZAKARIA: Right. If you wrote it out as an equation I found, you can't make a mistake.

KAHNEMAN: Then you don't make a mistake. But if people just check, they would know that $0.10 and another dollar that amounts to $1.20, so that's wrong. They don't check (ph).

And there are interesting differences between the people who check (ph) and the people who don't. And, you know, at Harvard, MIT or Princeton, half of the people, or a little over half in some cases make a mistake on that one. Other universities, you know, I have to stand up for Princeton, other universities it's worse.

ZAKARIA: But - but tell me this, is this a pattern that you - you detect in human behavior that there are some things that people think fast about and some things they think slow about? How would you describe this difference?

KAHNEMAN: Well, you know, most of the time we think fast. And most of the time we're really expert at what we're doing and most of the time what we do is right. And we do it with very little work and very little effort.

Now, there is slow thinking, it's effortful, it's hard work. And it turns out that by and large we clearly - most people are wired to avoid it. We try to do as little as possible of the slow thinking. It's very hard work.

And so sometimes when, you know, the fast thinking delivers the wrong suggestion and the slow thinking doesn't block it, then people come out with mistakes.

ZAKARIA: My people have pointed out that racism is often the, you know, a kind of a product of that kind of very quick thinking. That prejudice comes to mind very quickly.

KAHNEMAN: Well, of course. I mean, you know, we have associations to things. We have, you know, we have associations to tables and to - and to dogs and to cats and to Harvard professors and that's the way the mind works. It's an association machine.

ZAKARIA: When you think about this, does it make you feel that the way in which economics is done, the way we think about economics is all wrong? Because there is a sense in which what you're describing is - is the human capacity to really make false judgments all the time, so to not know what is in your best rational self-interest.

KAHNEMAN: The idea that people are completely rational it really entails something very important, which is that the - that the government has the responsibility to ensure disclosure. That people are given correct information when they interact in the market.

But it doesn't matter for a rational agent whether the print is small or large. It matters a lot for people with a lazy sort of system, too, lazy, slow thinking. They don't read the small print. None of us read, you know, those things that flash on the computer screen and that you say I agree at the end.

And that is a place where behavior economics is making an important contribution and I think a correction to the old, classical economic model of the rational agent.

ZAKARIA: The sort of classic example of what you're saying is that you - you give people the default option to save rather than not to save. So that on their - on their, you know, salary forms you say check here if you want to opt out of the IRA or the savings plan so that the default is that they save and the result is you have many, many more people saving.

KAHNEMAN: Well, I mean, you know, one of the most dramatic examples of that is in Europe. They have about half of the country on organ donation have an opt-in form so that you have to check if you want to donate your organs, otherwise you don't default as you don't.

The other half, the default is, is you do donate and you have to check if you don't. And the percentage of donations is roughly I think 90 percent in one case and about 15 percent in the other.

ZAKARIA: Wow.

KAHNEMAN: So on very consequential decisions people can be guided by those really - I would think completely superficial aspects of the situation.

ZAKARIA: Do you think what this tells you is that the government should be more active in trying to shape people's choices? And what areas would you advocate more is done?

KAHNEMAN: Well, you know, I think this is something that is actually happening today, I mean, in the Obama White House because you have a behavior economist, Cass Sunstein, who is in charge of regulation. And the focus there is consumer protection.

It's making sure not only that things are disclosed, which everybody agrees, I mean that's the law, they have to be disclosed, but they are disclosed in a way that accommodates the code (ph) of limitations of people.

ZAKARIA: And you don't think it interferes with the good - the good functioning of a market.

KAHNEMAN: Well, you know, I mean, that nobody wants a world in which another government will decide what you eat. That's not what will prevent people from eating fat food. So there is a limit. There is a balance.

There is a balance between freedom, which everybody wants to protect and, you know, the need of individuals to be in some cases helped make decisions that they would want to have made. I mean it's not that you're forcing people into things they don't want.

In the case of saving, most people want to save more than they do. And they're grateful when you help them save more than they do. So that is the balance that, you know, they're seeking and it's a difficult balance to achieve.

ZAKARIA: When you first saw that baseball bat and ball question, did you get it wrong or right?

KAHNEMAN: Well, I think I got it right. But I'm, you know, I'm good at those things and I check, so -

ZAKARIA: Daniel Kahneman, pleasure to have you on.

KAHNEMAN: It was a pleasure to be here. Thank you.
 
Interview 5: Charlie Rose (Feb 2012):


Charlie Rose: at Princeton in 2002. He was awarded the Nobel Prize in economics for his analysis of decision-making and uncertainty. He's the only non-economist to have won that award. Steven Thinker (ph) calls him among the most influential psychologists in history and certainly the most important psychologist alive today. He writes about the ideas that have driven his career over the past five decades in a new book. It is called "Thinking, Fast and Slow." I am pleased to have Daniel Kahneman here at this table for the first time and it is about time. So I'm glad you're here.
00:39
Daniel Kahneman: I am delighted to be here.
00:41
Charlie Rose: Let's -- let's give credit where credit should be given to your colleague, the late Tversky.
00:44
Daniel Kahneman: Amos Tversky.
00:46
Charlie Rose: Yes, a great friendship.
00:47
Daniel Kahneman: Yes.
00:49
Charlie Rose: And a great -- tell me about the friendship first.
00:52
Daniel Kahneman: Well, you know, we were extraordinarily lucky, so this was one of those collaborations that people dream of and there are very few who are that lucky. We -- we like each other, so we spent all of our days, you know, hours every day and --
01:06
Charlie Rose: Doing what?
01:09
Daniel Kahneman: Talking about everything, but mostly our subject was the study of intuition and specifically the study of the stakes of intuition so what we were doing that was work that counted as work later but it was all fun was to invent problems where we knew the solution but intuitively we had another idea, and -- and it was that that we did for --
01:33
Charlie Rose: Give me an example of that.
01:37
Daniel Kahneman: Well, ok. An example of that, here it is. You have, you are trying to predict, assign probabilities to -- to events --
01:52
Charlie Rose: Right.
01:55
Daniel Kahneman: -- and one of these events is that -- well, a flood somewhere in the United States killing at least 1,000 people over the next ten years. That's one event. The other event is an earthquake in California causing a flood in which more than 1,000 people will die and drown sometime within the next ten years. Now, the second event obviously is less probable than the first, but when you take two groups and you have one group judge the first event, the other group judge the second event, the earthquake event looks much more probable, so that's the kind of, you know, where clearly there is a logical rule --
02:36
Charlie Rose: When in fact it is --
02:38
Daniel Kahneman: -- of course it couldn't be.
02:40
Charlie Rose: Right.
02:42
Daniel Kahneman: Yes, I will give you another example while we're at it. It is not our research but very similar. During the time that there was a lot of terrorism in Europe, people asked about travel insurance. And they were asked how much would you be willing to pay for an insurance policy that pays $100,000 in case of death for any reason? And others were asked how much would you be willing to pay for insurance policy that paid $100,000 in case of death in a terrorist incident? The second policy is worth more than the first. Now, this is absurd, I mean, obviously, you know, dying in a terrorist incident is an event that's included in the event of dying, but what? People are more afraid of dying in a terrorist incident than they are afraid of dying. So that's where the intuition comes from, it comes from the fear. And you have a judgment of probability that is distorted by something else, so those were the kinds of problems.
03:41
Charlie Rose: Now you were discussing every afternoon.
03:42
Daniel Kahneman: Yes, yes.
03:44
Charlie Rose: And is it fair to say he would have won the Nobel with you.
03:50
Daniel Kahneman: Of course.
03:52
Charlie Rose: But they don't give Nobel prizes to people who are deceased.
03:55
Daniel Kahneman: No.
03:57
Charlie Rose: And I assume his name would have been on this book as well.
04:02
Daniel Kahneman: Well you know it's up still because we might not have agreed on this book, this is my book. But -- but the ideas on which it's based and the history of the book are joint.
04:12
Charlie Rose: Yes. Is there a connecting dot to all these ideas? Is there a central mutable fact?
04:19
Daniel Kahneman: Well, yes there is and it's -- that there are two ways of thinking about the world and thinking about anything. There is the -- what I call thinking fast.
04:28
Charlie Rose: Yes.
04:31
Daniel Kahneman: The intuitive way and thinking slow, the reasonable way.
04:35
Charlie Rose: That's System 1 and System 2.
04:36
Daniel Kahneman: System 1 and System 2 and that we didn't have those terms. But we had that idea that here are problems where we can figure out the solution, but our intuitions, fast thinking as I would now call it goes the other way. So that's -- that really was a theme of our research, both on judgment, which we studied for many years and on decision-making, which -- to which we moved afterwards.
04:58
Charlie Rose: Explain System 1 and System 2.
05:00
Daniel Kahneman: Well, there are two kinds of thinking, first of all, really and everybody can recognize that, because one is what happens to you when I say two plus two.
05:11
Charlie Rose: Right.
05:14
Daniel Kahneman: And you know something comes to your mind. When I say capital of France, something comes to your mind. This is associative memory working. It's working automatically, you don't have to decide it. It's something that happens to you. It's just like seeing that somebody's hair is dark.
05:29
Charlie Rose: Yes, is that part of your unconscious mind?
05:31
Daniel Kahneman: Well you are not really conscious of how it is happening.
05:35
Charlie Rose: Right.
05:36
Daniel Kahneman: You are conscious of the results.
05:38
Charlie Rose: Right.
05:40
Daniel Kahneman: You are conscious of your impression but you're not aware at all of the workings of associative memory. So that's System 1. And System 2 has two functions. One of them is, you know, to compute things like 24 times 17. Now nothing came to mind immediately.
05:56
Charlie Rose: Yes.
05:59
Daniel Kahneman: You have to work at it laboriously if you're going to do it at all. And another function of System 2 is to supervise the mind and to supervise behavior. And -- and that is work, that function, the function of control, the function of -- so System 2 -- what characterizes System 2 is that its effortful. And we invest effort and we have a sense of urgency when System 2 is involved. We have a sense of this is our thing this is something that I do. It is not something that is happening to me. So that's --
06:36
Charlie Rose: Now is it important know when System 1 is appropriate and when System 2 is appropriate?
06:41
Daniel Kahneman: Oh, yes. It's very important to know, because many mistakes of, you know, most of the time we run on System 1.
06:46
Charlie Rose: Right.
06:48
Daniel Kahneman: I mean System 1 is the software most of the time we work.
06:53
Charlie Rose: When you see the light turn green we walk.
06:55
Daniel Kahneman: Yes. And it's not only that, even when we are exchanging pleasantries with a colleague at work, you know we're not working very hard.
07:04
Charlie Rose: Right, right.
07:06
Daniel Kahneman: So most of the time it's System 1. And -- and most of the time System 1 works just fine, because we have a lot of practice at what we do. We are very good at what we do. Occasionally, you hit a problem like, you know, the problem of buying insurance where actually it's a very complicated problem and your intuitions aren't right but you don't know it. So that's -- it's --
07:29
Charlie Rose: And you don't know when intuition --
07:33
Daniel Kahneman: You don't know.
07:36
Charlie Rose: So that's the crucial reason that you need to know when to use System 2, because --
07:40
Daniel Kahneman: You need to recognize, this is a situation.
07:43
Charlie Rose: Which requires --
07:45
Daniel Kahneman: Where I am prone to error. This is a situation --
07:50
Charlie Rose: And how do you discover that?
07:51
Daniel Kahneman: It's very hard to do and I'm not terribly optimistic about people, you know --
07:55
Charlie Rose: Yes.
07:57
Daniel Kahneman: -- becoming very good at it. But there are certain principles that, you know, you can learn to recognize. So for example, I know about myself that I am wildly overconfident, you know. When I have opinions I'm sure they are right, but -- but I have had enough experience to know that I am overconfident, so the feeling of overconfidence are there, but if it matters I can slow myself down and become more reasonable.
08:23
Charlie Rose: Yes.
08:26
Daniel Kahneman: So that's a case where System 1 would make you very confident and System 2 slows you down.
08:32
Charlie Rose: How does it work -- and you referenced this -- how does it work in terms of people knowing what someone expects, so therefore they feed them that kind of information and therefore the people at the end of - - the recipients of the information make bad decisions?
08:45
Daniel Kahneman: Well --
08:47
Charlie Rose: The Iraqi war is Exhibit 1 on this.
08:51
Daniel Kahneman: Yes. What's -- what is happening is -- and that happens a great deal, is that people are convinced -- and it's not that people go to war because of reasons, you know, it's really very often works the other way around.
09:06
Charlie Rose: We go to war because --
09:07
Daniel Kahneman: People want to go to war and then they find the reasons.
09:13
Charlie Rose: Ah.
09:14
Daniel Kahneman: So if System 1 is very engaged and -- and there is a strong intuition that war is needed that war is right and so on, then System 2 is -- becomes the slave of System 1 and that happens a great deal.
09:28
Charlie Rose: You credit Bush 43, President Bush 43 as a clear example of System 1 person.
09:33
Daniel Kahneman: Well, I may have mentioned that, yes.
09:36
Charlie Rose: Well yes.
09:37
Daniel Kahneman: I mean I -- I probably cited somebody else who said that.
09:42
Charlie Rose: Yes ok --
09:43
Daniel Kahneman: I mean, clearly, you know when somebody does --
09:47
Charlie Rose: He's a man who operated by intuition, his instincts, his gut was what got him and he said that essentially.
09:53
Daniel Kahneman: Yes, he was proud of it. And so he -- he was a man who was saying, I trust my gut and that's how I get, I got to where I am and -- and so yes, he was definitely --
10:02
Charlie Rose: So he became overconfident about his gut?
10:04
Daniel Kahneman: Well, I think most people who trust their gut are overconfident about their guts on important matters which he clearly was. So --
10:11
Charlie Rose: And President Obama you say is clearly a System 2 person.
10:14
Daniel Kahneman: Well yes. He may be at the other extreme I mean and that maybe part of his --
10:21
Charlie Rose: He deliberates too much?
10:23
Daniel Kahneman: That may be part of his political difficulties, because the public has a stereotype of what makes a strong leader. And they like leaders who are decisive. They like leaders who operate quickly. And they don't like leaders who take their time.
10:34
Charlie Rose: And they think -- they are likely to seem to think --
10:40
Daniel Kahneman: And they likely those who seem to know exactly what they are going to do. And you know we attribute magic to intuition, so when things work out as -- as planned, then you know --
10:51
Charlie Rose: So could the sub title of this book be "intuition is way over-valued"?
10:58
Daniel Kahneman: Well, I would prefer as a sub title, Intuition, the Marvels and the Flaws.
11:02
Charlie Rose: Ah.
11:05
Daniel Kahneman: Because the marvels, which I don't speak about much because they are less interesting than the flaws, the marvels are, you know, how much we do with intuition and how good our intuitions are, you know. So I'll give you some examples, you can -- you can drive without thinking about it, you know, that's the same machinery that does intuition. I can tell you a sentence -- one of my favorite experiments is people listen to sentences and British upper class male voice says and I am not going to try it.
11:35
Charlie Rose: Yes, it's a great story.
11:38
Daniel Kahneman: So it says I have large tattoos all down my back and it takes about a third of a second and the brain reacts with a surprise.
11:45
Charlie Rose: Yes.
11:47
Daniel Kahneman: Now that's extraordinary, you have to figure out --
11:50
Charlie Rose: A man with a deep British voice would not have tattoos.
11:54
Daniel Kahneman: That's right. But you know the amount of world knowledge that has to be brought to bear on that problem within a third of a second for the brain to recognize that there is an incongruity, this is extraordinary. So -- and it and intuition is like that, so that a chess player will recognize a chess situation very quickly. I recognize my wife's mood one word on the telephone.
12:17
Charlie Rose: You can say -- so you say what's wrong? Are you ok?
12:21
Daniel Kahneman: Yes, sure. I mean and -- and that you can hear it. All it takes is a lot of practice.
12:30
Charlie Rose: Take us to the realm of traders -- people who we think have enormous instincts.
12:36
Daniel Kahneman: You know, there is a -- there is a debate about where intuition does and does not work in financial markets. So I am on pretty safe ground when I say that in the stock market in picking individual stocks --
12:52
Charlie Rose: Trace (ph) all the numbers.
12:56
Daniel Kahneman: It's -- it is luck. They are playing a game of luck, they feel they are playing a game of skill, but most of them are playing a game of luck.
13:05
Charlie Rose: So you could do all the System 2 you want it will not tell you what you need to know, it's just luck.
13:10
Daniel Kahneman: No. No because -- and that's -- that is not anybody's fault, you know. It's the same thing with pundits trying to predict what's going to be the state of the United States or of China in 15 years. Pundits are no better at it than -- than readers of "The New York Times."
13:24
Charlie Rose: Ok but why not? I mean doesn't history matter? Doesn't --
13:28
Daniel Kahneman: No. Because --
13:31
Charlie Rose: -- empirical data matter?
13:33
Daniel Kahneman: Well in some cases it does and in others it doesn't.
13:36
Charlie Rose: So when -- if you know the difference?
13:38
Daniel Kahneman: Yes, we do know actually. I mean we know that the stock market is chaotic, it is extremely complicated. And it is not -- it doesn't have enough regularity for people to learn.
13:47
Charlie Rose: So what about all of these people who have made billions and billions of dollars every year because they put these very smart mathematical models in silos and the silos tell them the way the market is going to operate and then they make --
13:58
Daniel Kahneman: Well, what those mathematical models are doing they are not picking individual stocks, they are picking up trends and some of these are micro trends and some of these are macro trends and you know, they are -- they are able -- if you're able to predict what the market will do in the next five seconds, you can become very rich doing that.
14:15
Charlie Rose: Right.
14:18
Daniel Kahneman: And so a lot of these work on programs that's in effect, you know, it is no longer --
14:26
Charlie Rose: Let me give you two examples of people who made a lot of money because they made huge bets. One was George Soros betting on the British currency.
14:32
Daniel Kahneman: Yes.
14:33
Charlie Rose: And the other was John Paulson betting on the subprime.
14:37
Daniel Kahneman: Yes. Well, they are both very interesting examples. I mean, I would never sell George Soros -- he -- he operates and his big bets are on an understanding of the world economy and of trends and -- and -- and in an ability he claims to anticipate how people will react to these trends.
14:55
Charlie Rose: Anticipate -- that is your business that he says he understands, how people will react.
15:03
Daniel Kahneman: Will -- will react. That's --
15:07
Charlie Rose: That's your business, not an economic model.
15:09
Daniel Kahneman: He claims he can do it. And you know --
15:13
Charlie Rose: His track record speaks for itself.
15:16
Daniel Kahneman: He has a track record; he's very, very good. Paulson you know I mean, at least in some of the trade that we know about, I mean he was shooting fish in a barrel. I mean it's not --
15:23
Charlie Rose: Oh, yes. Shooting fish in a barrel.
15:26
Daniel Kahneman: So that is not -- some of the great successes are because people were already billionaires and had a lot of control.
15:31
Charlie Rose: Yes and then he had -- he's had a rough plodding for a while.
15:34
Daniel Kahneman: Yes.
15:36
Charlie Rose: Big year and then came back and had a not so big year.
15:39
Daniel Kahneman: Yes, they have a lot more information than other people.
15:42
Charlie Rose: So if you are so smart and you win all the time and maybe we should say and history proves that that's not true.
15:47
Daniel Kahneman: I -- I don't think that winning a few times proves that you are smart and losing a few times doesn't prove that -- you have to look at the world. That is, you have to ask whether the world actually affords enough regularity so that it becomes learnable.
16:01
Charlie Rose: And your answer is?
16:04
Daniel Kahneman: My answer is, in some cases, like chess or my wife's moods or you know, many of the problems that people solve, the answer is yes. And in the stock market and in long-term forecasting and sometimes even in medium term forecasting as in wars, the answer is no.
16:23
Charlie Rose: So what's the difference in long-term forecasting and chess?
16:27
Daniel Kahneman: Well, in chess, there are regularities, so you can predict what's going to happen. If you know where you are now you can predict what's going to happen next and that is how people develop intuitions. Now, that's how people learn to read, so chess and reading have a lot in common, you recognize situations and you know snap diagnosis by medical experts, there are regularities, they pick them up. They learn those regularities. When there are no regularities I would say forget it, it's not going to happen.
17:02
Charlie Rose: Yes, Michael Lewis wrote a profile of you.
17:03
Daniel Kahneman: Yes. For "Vanity Fair." Indeed.
17:09
Charlie Rose: What was the story?
17:11
Daniel Kahneman: Well, Michael Lewis wrote "Moneyball."
17:12
Charlie Rose: Right.
17:14
Daniel Kahneman: And he wrote "Moneyball" about Billy Beane, he was that - - that man and --
17:17
Charlie Rose: And a movie.
17:19
Daniel Kahneman: And a beautiful movie.
17:21
Charlie Rose: Yes.
17:23
Daniel Kahneman: And so he did that. Now, that book was reviewed by a couple of friends of mine who were well-known behavioral economists I mean, Richard Thaler (ph) and Cass Sunstein (ph), they reviewed Michael's book for the "New Republic."
17:35
Charlie Rose: Right.
17:36
Daniel Kahneman: And they said, "Michael wrote that magnificent piece. He doesn't seem to know that a lot of that is known to psychologists. That's -- actually if you apply mechanicals or statistical system to prediction you will do better than what is called clinical prediction. So an algorithm would beat scouts if -- if you give decent information to both. The algorithm will use the information better than the scouts will. And so that got --
18:11
Charlie Rose: So -- but if that's true then why hasn't -- I mean, why isn't it proven to be true since -- why have other people adopted it and therefore (ph) they use it smartly.
18:18
Daniel Kahneman: Oh yes, they are.
18:21
Charlie Rose: So in other words the -- the algorithm that was being used by Billy Beane's team at the Oklahoma A's is being used by many people today.
18:27
Daniel Kahneman: You know if you remember the end of the film --
18:31
Charlie Rose: Right, he didn't go to Boston.
18:34
Daniel Kahneman: He's offered -- he didn't go to Boston, but Boston adopted his system.
18:37
Charlie Rose: Ah.
18:39
Daniel Kahneman: And they won -- they won the pennant two years later. So the game has changed.
18:45
Charlie Rose: I'm going to read some things that are interesting.
18:48
Daniel Kahneman: Yes.
18:50
Charlie Rose: At the end of a basketball game why does it make sense for the last shot to go to the player with the best overall shooting percentage not the player with the hot hand? Because a lot of people say if you've got a player with the hot hand you want him to take the last shot. You say no, you want --
19:01
Daniel Kahneman: Yes.
19:02
Charlie Rose: You want who -- who do you want to shoot the last shot?
19:06
Daniel Kahneman: I definitely want to -- you know the player who is the most reliable player should have the last shot, period.
19:11
Charlie Rose: Period. Hot hand does not matter?
19:14
Daniel Kahneman: The hot hand, you know, to the best as we know the hot hand doesn't exist so it is an illusion, people feel that there is a hot hand.
19:21
Charlie Rose: When they can see the basket looks like it's as big as --
19:25
Daniel Kahneman: Yes. And they -- they can, you know, they can feel it and furthermore the player feels it and everybody feels it, but it is a -- it's a shared illusion and actually we know how this works, because if -- if you have a grid, a ten by ten grid and then you sprinkle red color on the grid. And you do that randomly, when you do it randomly, it will not appear random. For a grid to appear random, it has to be somewhat systematic. That's what we know. And the hot hand is one of those phenomenon.
19:59
Charlie Rose: Now here is another example. All of these are in the book. When people -- when shoppers for Campbell Soup see a sign reading limit of 12 per person they buy an average of seven cans, twice as many as they bought when there was no sign.
20:13
Daniel Kahneman: Well, that is a phenomenon that we call anchoring.
20:17
Charlie Rose: Yes the anchor effect.
20:20
Daniel Kahneman: And it's yes. It's one of the biggest and most robust phenomena there are. I mean, you know, you can -- any number that you think about, as a solution to a problem, you are going to be affected by it. I mean they had that study of German judges who tossed a pair of dice.
20:37
Charlie Rose: All right.
20:40
Daniel Kahneman: And then they had to -- and then they had to judge how many months somebody you know -- a shoplifter would go to jail.
20:47
Charlie Rose: Right, right.
20:50
Daniel Kahneman: And they were strongly influenced by the number that the dice showed, that's an anchoring effect and we -- we understand it and we know how it happens and it's very powerful.
20:58
Charlie Rose: Yes. Are behavioral economists on the rise?
21:02
Daniel Kahneman: No question. I mean the -- behavioral economics now is a major input into policies.
21:07
Charlie Rose: Right.
21:08
Daniel Kahneman: That's --
21:10
Charlie Rose: Economic policies.
21:12
Daniel Kahneman: -- economic policies.
21:13
Charlie Rose: Political policies, foreign policy decisions.
21:16
Daniel Kahneman: Regulation.
21:18
Charlie Rose: Regulation.
21:19
Daniel Kahneman: Regulation is very strongly informed by behavior economics, so Cass Sunstein (ph) who is the chief regulator.
21:23
Charlie Rose: Right, right.
21:24
Daniel Kahneman: He wrote a book with Richard Thaler who is the guru of behavior economics.
21:29
Charlie Rose: Right.
21:30
Daniel Kahneman: They wrote "Nudge" together. So --
21:33
Charlie Rose: Explain "Nudge."
21:35
Daniel Kahneman: Nudge is -- is the idea that you can't help people make good decisions without forcing them to making any particular decision. For example, you know, the most dramatic example is -- is organ donation. So there are countries in Europe where the default is that you don't donate your organ, but when you get your driver's license, there is a box which says if you want to donate your organ, check the box.
21:58
Charlie Rose: Yes.
22:00
Daniel Kahneman: There are other countries that default is reversed, you donate your organs, but.
22:07
Charlie Rose: If you choose not to.
22:09
Daniel Kahneman: Yes you have to opt out. Now, the proportion of donations is about 94 percent if I recall in one group of countries and 18 percent in the other. So the effect of default options is enormous, now people are completely free to choose, but you know, one of these choices is much better than the other.
22:31
Charlie Rose: Who comes to you and pays you lots of money to consult with them? What kinds of people?
22:36
Daniel Kahneman: Well, not many people come to me personally to consult with me.
22:41
Charlie Rose: But to --
22:43
Daniel Kahneman: You know, quite a few people are curious about it.
22:48
Charlie Rose: Yes.
22:51
Daniel Kahneman: But there is actually enormous resistance, I think, within organizations to implementing programs that would improve the rationality of their decisions.
22:58
Charlie Rose: Why?
23:00
Daniel Kahneman: Well because -- because it creates difficulties for the leadership. The moment you have a system that is more, you know, structured system, then that system can be used to second-guess the decisions of people and people don't like to be second-guessed. So that there is a lot of interest in ways to improve rationality but I have not found -- and you know I've been invited to many places and given many talks and been very well received. When it comes to implementation, enthusiasm wanes distinctly.
23:37
Charlie Rose: Because of some instinct for security?
23:39
Daniel Kahneman: Because --
23:41
Charlie Rose: Or you don't want to be found out? You don't want to be found out.
23:44
Daniel Kahneman: You are naked.
23:46
Charlie Rose: Yes.
23:48
Daniel Kahneman: And this is a real problem. This is a real problem. So how to promote rationality within organizations and how to prevent mistakes that takes sort of architecture --
23:59
Charlie Rose: It takes it -- well, that takes a mindset to say I am going to insist on rationality?
24:03
Daniel Kahneman: Yes and without --
24:05
Charlie Rose: And then you will be naked and we will you know -- you have to defend your ideas.
24:12
Daniel Kahneman: I'm going to insist on rationality but I'm not going to allow paralysis.
24:16
Charlie Rose: Yes.
24:18
Daniel Kahneman: So you'll have to decide, I'm going to look for the proper mix of intuition and -- and reasoning. You know it's a complicated process, very difficult and very few people have done it, you know, very systemically, some firms have actually.
24:30
Charlie Rose: Some --
24:32
Daniel Kahneman: You know, there are hedge funds, venture capitalists.
24:36
Charlie Rose: Right, right, right.
24:38
Daniel Kahneman: Who have a systematic process to optimize their decision- making and I think --
24:42
Charlie Rose: And they have done better than others.
24:43
Daniel Kahneman: -- and I think they do very well.
24:45
Charlie Rose: I do too. I think I know what you are talking about. Yes, absolutely. I mean that's, in fact, that was an example that I was thinking about when I brought it up.
24:52
Daniel Kahneman: Yes, there's -- because they are not working a perfect market.
24:56
Charlie Rose: Right.
24:57
Daniel Kahneman: You know there are actually opportunities for them and so there, a good process will -- will, in general, make them thrive.
25:05
Charlie Rose: Are you -- what question do you not know the answer to that you most want to understand?
25:10
Daniel Kahneman: Well, you know, for the last few years I have been -- I've been studying well-being.
25:15
Charlie Rose: Well-being?
25:17
Daniel Kahneman: Yes. And the question that I would most like to understand and there seems to be two facets to well-being. One is, what is your mood in real-time? And the other is how satisfied are you with your life when you think about it? Both are very important. Skills (ph) are both are very important. They are not the same. So we know what causes one. We know what causes the other.
25:43
Charlie Rose: Repeat that to me because I really want to understand it.
25:46
Daniel Kahneman: Yes.
25:47
Charlie Rose: So the first one is --
25:49
Daniel Kahneman: Is how happy you are in real-time. What's your mood like?
25:52
Charlie Rose: Right, right, exactly.
25:54
Daniel Kahneman: You know -- are you interested? Are you aware? Are you vital, you know?
25:58
Charlie Rose: Right, right.
26:00
Daniel Kahneman: Do you feel energy? The other one is -- when you think about your life, how satisfied are you with your life?
26:05
Charlie Rose: Yes.
26:07
Daniel Kahneman: It turns out those two are very different.
26:08
Charlie Rose: And so what do you want to understand?
26:11
Daniel Kahneman: And what I would like to know is which of them has the bigger effect on health. So if you asked me, you know, what question I would like to know before I totally quit, that question is --
26:21
Charlie Rose: And what does your intuition tell you?
26:23
Daniel Kahneman: I don't know, I don't trust my intuition.
26:24
Charlie Rose: Yes.
26:26
Daniel Kahneman: No. I mean, there are so many surprising results here that my intuition is not useful.
26:32
Charlie Rose: Everything you have learned just told you not to trust intuition?
26:36
Daniel Kahneman: Well, yes. Not to trust.
26:40
Charlie Rose: So what did you think about that book Malcolm Gladwell wrote called "Blink?"
26:45
Daniel Kahneman: Well, Malcolm Gladwell actually did not -- does not believe that intuition is magic. He really doesn't believe it. It's very clear he has chapters where he shows, for example, he has a chapter on why President Harding was elected just because he looked the part. So intuition is not always a winner. But Malcolm Gladwell definitely created in the public of readers the impression that intuition is magical. And that I think, that I regret. You know, I have enormous respect of Malcolm Gladwell, you know his piece is always the first one that I read when it's in "The New Yorker."
27:21
Charlie Rose: Right.
27:24
Daniel Kahneman: But here, his story has helped people in a belief they want to have, which is that intuition works magically and that belief is false.
27:31
Charlie Rose: "Thinking Fast and Slow," Daniel Kahneman. I thank you and I'm honored to meet you.
27:36
Daniel Kahneman: Thank you very much.
 
Interview 6. The Guardian ("This much I know", 2012):

Human beings cannot comprehend very large or very small numbers. It would be useful for us to acknowledge that fact.
My main work has concerned judgment and decision-making. But I never felt I was studying the stupidity of mankind in the third person. I always felt I was studying my own mistakes.
Happiness is complicated. There are two components. One is strongly genetic; the second is a question of how you feel at any moment. I am pretty content, but I had a very pessimistic mother, and I've always been known as a pessimist.
It was always assumed I would be a professor. I grew up thinking it.
There is a powerful idea that we should want to be richer. I went to a financial advisor in the States and said: "I don't really want to get richer, but I would like to continue to live like I do." She said: "I can't work with you."
Collaboration is not only more creative, it is more fun. Amos Tversky, my research partner, and I were better together than on our own. We sort of knew that. Mostly it was extremely pleasant not trying to work everything out yourself.
A sense of irony is essential. When we wrote our first paper, "The Law of Small Numbers", we were laughing all the time we wrote it. A colleague we showed it to said: "This is going to change things." I didn't take him seriously.
Many people now say they knew a financial crisis was coming, but they didn't really. After a crisis we tell ourselves we understand why it happened and maintain the illusion that the world is understandable. In fact, we should accept the world is incomprehensible much of the time.
Motives are rarely straightforward. When the war started my father was chief of research for a company that was part of L'Oréal in Paris. The owner of L'Oréal was also a main funder of the fascist party in France, and antisemitic. But he protected my [Jewish] father during the war when he was taken by the Nazis.
People who wouldn't even come to your funeral seem to take simple pleasure in the fact that you have won the Nobel prize [for economic sciences], and it makes them feel good about themselves to feel that way. For a while you are spreading joy.
Investment bankers believe in what they do. They don't want to hear that their decisions are no better than chance. The rest of us pay for their delusions.
Despite 45 years of work in the field, I am still inclined to make over-confident predictions.
Economists have a mystique among social scientists because they know mathematics. They are quite good at explaining what has happened after it has happened, but rarely before. I don't think of myself as an economist at all.
I enjoy being active but I look forward to the day when I can retire to the internet.
 
Interview 7. The Motley Fool (June 2013):

Morgan Housel: We're very lucky today to have Dr. Daniel Kahneman with us. He is a psychologist from Princeton University. He's the author of the book Thinking, Fast and Slow. He's been called "one of the most influential psychologists since Sigmund Freud." He won the Nobel Prize in Economics in 2002. Please welcome Dr. Daniel Kahneman.
Dr. Kahneman, you won the Nobel Prize in economics, but you're not an economist; you're a psychologist. From what I understand, that's the first time that's ever happened in that award for economics.
To me, that's a confirmation that so much of what is important in economics and in investing has less to do with numbers and spreadsheets and Greek formulas as it does what's going on in our head, and fooling ourselves.
Just to get a background of your career, from what I understand the first time that your work intersected with economics was in the early 1970s when a colleague brought to you an economics paper and the first line of the paper was, "The agent of economic theory is rational, selfish, and his tastes do not change." For a psychologist, that's ridiculous, so what happened next?
Daniel Kahneman: Well, nothing happened immediately but I found that very surprising, actually, because the economics building was next door. I was at Hebrew University, Jerusalem, and we had one building and the economists were next door. I learned from that one sentence something I hadn't known before; that they sort of lived in a different intellectual world than we did.
For a psychologist it's obvious that people are not fully rational, and that they're not selfish, and that their tastes change. It was just a collection of statements that seemed almost absurd. I had no idea, at that stage, that a lot of my career would be dedicated to that conversation. That sort of happened almost by accident, later.
Morgan: In the last decade, behavioral economics has grown in influence. It's much more accepted now than it was in the past. I guess my question is, why did it take so long?
Kahneman: It didn't take long. Twenty-five years is a blink of an eye, in intellectual developments. Our first serious paper appeared in an economics journal, Econometric, in 1979. It appeared there by accident. We were not intending to influence economists. It was the best journal for this sort of theory paper.
I think my Nobel was 2002. That is very, very, very quick. They had two Clark medals. You know the Clark medal is really more prestigious than the Nobel in economics. It's given to the best economist under 40, and they had two behavioral ones. Twenty years is very, very fast.
Morgan: When you first started publishing the work, what was the response from different economists? What was their pushback?
Kahneman: The first response was real contempt. They just didn't take it seriously. They didn't take psychology seriously at all.
Economists know mathematics; more mathematics than other social scientists. If you know mathematics, you have a special attitude to the rest of the world, or to people who don't understand the formulas you have, so it took quite a while, actually.
Morgan: When psychology was brought into economics, was it fine-tuning around the edges, or was this taking existing theories and turning them upside down?
Kahneman: Well, it was brought as a series of challenges. The person who really created behavioral economics is Richard Thaler, who is an economist. He happened -- not "happened," it's not an accident -- he sought us out because he was a very unusual economist who was interested in what we were doing, as a graduate student.
He is the next president of the American Economic Association, so you are talking of a development in 30 years in his career.
In the 1980s he had a column in the Journal of Economic Perspectives, which was sort of the professional journal of the Economics Association. His column was called "Anomalies" and it was just facts in the world that look strange from the point of view of economic theory.
These columns were read by everybody because he writes very well and he's very witty, and everybody was exposed to it. I think that, more than almost anything else -- well, I don't want to exaggerate -- but that had a big effect on making behavioral economics respectable.
We didn't challenge the whole edifice, except that prospect theory was really saying that people cannot be quite as rational as they have been described. Dick Thaler and I did work on fairness, which showed that people are not as selfish as they've been described.
He has done a lot of work on self-control because, although that was not mentioned, self-control is viewed as part of rationality, but Dick Thaler has shown, and many others have, that people have "bounded self-control," as he describes it. They have procrastination problems.
They don't make themselves think seriously about things that matter, and they spend a lot of time dithering and thinking about things that don't matter.
The assumptions have been challenged, but economics is still pretty much the same discipline it was.
Morgan: You've talked before, that some people are more interested and curious in your work than they are in actually implementing it in their own lives and businesses, to put forth practices to make better decisions. Do you see that changing, that people are taking it more seriously, to put it into practice?
Kahneman: There is a fair amount of interest in the work. I actually don't know. The book might have some influence on this, my guess is, but otherwise my experience was giving a lot of talks at businesses and to executives, and so on.
They are really very, very interested in that stuff, until there's a sort of a hint that it might be applicable to their own business, and then they really lose interest very quickly.
This is threatening stuff, actually. It is threatening because the idea that you can question practices, or the idea that you want to reevaluate practices is threatening in any business.
They're very interested in the principles, but when it comes to something as elementary as evaluating your own performance and trying to improve your decision making... that looks like an obvious idea. You mention that idea in many contexts in financial firms, they really don't want to hear about that.
Morgan: Because they don't want to be told that they're doing it wrong.
Kahneman: They don't want to be told. That kind of message is threatening to the firm, it's threatening to the leadership of the firm. It goes very, very well until you mention something that, "Maybe you could do it yourself," and then you feel the chill in the room. It's immediate.
Morgan: Let's talk a little about your book, Thinking, Fast and Slow. The theme throughout the book is that there are two types of thinking, fast and slow; System 1 and System 2. Tell me about the difference between the two.
Kahneman: Fast thinking is, I think, most of the way that we think. It's what your memory delivers to you. You start talking, and you talk. You don't have to deliberate about one word and then the other. You walk. You don't deliberate and decide to put one foot in front of the other.
Most of what we do sort of comes automatically. Most of what we do is highly skilled and emotional -- some of it is emotional, much of it is highly skilled -- and all of that is automatic. There's just an awful lot of automatic stuff that goes on.
Then there is System 2.
If I say, "2 plus 2," a number came to your mind. That's System 1. If I say, "The relationship between China and Japan," now it's not one word that came to your mind, but a whole set of words, a whole set of ideas. I mentioned that, you were thinking islands, you were thinking war, you were thinking navies.
You might have been thinking about the history of China and Japan. A lot happened that you were not... it happened at once. Those are not explicit thoughts, but you are ready for a whole topic, as soon as I mention something. That's System 1.
I mention the word "mother," "your mother" -- you are having an emotion. That's System 1.
There's an awful lot that System 1 does. System 1 has judgments and opinions and attitudes and impressions that are generated -- like when I said, "Think of China and Japan" -- that a whole lot happened at once. You were not conscious of it all at once, but your mind was ready. It was getting ready with it.
That's the idea, that there is that thing going on in our minds, silently. Then you have System 2.
System 2 is the effortful one. It depends on the allocation of attention. It's what we are paying attention to, mostly. It's involved in computations. It's involved in difficult decisions. It's involved in controlling yourself and not telling somebody to go to hell. That demands System 2. It's all part of effortful system.
What's the relationship between the two of them? That's the interesting part.
I compare that, and maybe that image -- it's not in the book, but I now wish it had been -- I compare it to a newspaper room. You have the reporters and they are writing stories. They're interpreting the world.
Then you have an editor. In my story, the editor is sort of lazy, and is badly overworked. What the editor does mostly is endorse the stories and send them to the printer. Now, occasionally the editor will stop a story, think more slowly, assign it to another reporter, or altogether stop it, like not telling somebody to go to hell.
If you look at where the product is, the newspaper is really written by the reporters. It's not that the editor has no role. It's not that... the editor is a very important figure, but the newspaper was basically produced by the reporters. That's one theme of the book.
Basically, it's not that the editor produced the newspaper. The editor is, to a large extent, in the business of endorsing emotions and responses and impressions that come from somewhere else. The editor also is in the business of defending what's in the paper to the public.
Here went that story, and he endorsed it without really thinking about it, but now there is flak about it. Now he is asked, "Why did you publish that story?" He's not going to say, "Well, I just sent it to the printer." He's going to find a reason for why that story got...
That's the way our mind works. We believe the thing that we believe and we have the opinions that we have, not so much because we have reasons for them. If we had reasons for our religious beliefs, then people would change their religious beliefs. If we had reasons for our politics, we would change our views and arguments.
I don't want to say that nobody ever changes their minds, but people rarely change their minds. That's because our beliefs come from somewhere else. We believe the arguments that are compatible with our beliefs. It's not that we believe in things because we have the argument for them.
A lot of things, System 1 comes first, System 2 endorses and rationalizes. That's a big theme in the book, is this view of how the mind works.
Morgan: Is System 1 my gut and System 2 is my head? Is that a fair way of putting it?
Kahneman: Well, System 1 is extraordinarily clever. System 1 knows about the world. Your knowledge about the world, all your skills, are in System 1.
You drive without paying attention. That's System 1 because you have learned to drive. You maneuver social situations without getting into too much trouble most of the time. That's System 1 and it demands a lot of alertness to cues.
The "gut" -- to say System 1 is the gut -- that suggests that there is no thinking there. The best thinking we do is System 1. Creativity is stuff that comes from your memory. It's in that sense System 1.
It doesn't work the way we think it works, but it's not that System 2 is more elevated than System 1. Actually, it's... I don't want to say the reverse, but System 1 is much better at what it does than System 2 is good at what it does. That is, the automatic memory system really does an awful lot of stuff very quickly.
Morgan: When does paying attention to System 1 lead me astray and cause me to make bad decisions when I should have been paying attention to System 2?
Kahneman: Well, there are situations in which System 1 will lead you astray.
The point is, and that's another theme in the book, is that those conditions are knowable. There are kinds of judgments that we do badly, or that we don't do as well as we should. In principle, those mistakes happen in particular circumstances and for particular types of judgments.
The key thing that we did in our work was develop the notion of a bias. A bias is a systematic error, and a systematic error is very different from a random error. Systematic error is something that you can identify, when does it occur, and in principle you can correct for it.
If there is anything to be learned from the book in the applied sense, it's when to slow down. It is when to call in System 2 to correct for System 1.
Morgan: Is there the opposite side to that? When will System 1 help me make better judgments, when I should ignore System 2?
Kahneman: I think in general, when you're operating in a domain in which you're skilled, then trust yourself. It happens anyway.
When golfers want to correct their swing, they bring in System 2 and they ruin their performance for a while. That's the way that you correct your swing. It's that making yourself conscious of what you're doing, in order to do it differently.
There are many -- by and large, your advice -- if you're a good golfer, just golf. Don't ask yourself exactly what you're doing while you're doing it. Many situations where you want to trust in System 1. Not always.
Morgan: You write in the book about how not only are we not good at predicting the future, but we're not even good at remembering the past in certain situations. There was one example where you have two groups of people who are getting colonoscopies.
I'll butcher the example. I'll let you tell the story.
Kahneman: OK. Well, you know, in the first place, people here are too young to talk about colonoscopies, but in addition, colonoscopies have changed since we did that research. They used to be very painful procedures. Now they put you under and you just wake up.
At the time, it was a painful thing to go through, and colonoscopies used to last... in a study that we did, the shortest one was four minutes, I think, and the longest one was an hour and a quarter, so there's a tremendous range in terms of how long they last. There is variability within a colonoscopy. Sometimes it really hurts, and other times it's just unpleasant.
In a couple of big experiments, we had somebody next to the patient and every 60 seconds they would ask the patient, "How much does it hurt now?" on a scale from 0 to 10, I think. You get a profile of the patient's pain, and you know exactly what went on, so you know how long the colonoscopy was, and you know...
Then later, and in many different ways, we asked them about the memory they had kept from the colonoscopy. What was left with them?
It turned out that what was left was determined completely differently from what we would have thought. It was simply an average of the worst moment in the colonoscopy, and how badly it hurt when the procedure ended.
Those two variables really gave you excellent prediction of, when you ask people, "Would you want to have another one of those, or would you rather have another painful procedure?" Or you ask them, how much total pain was it? How bad was the whole experience?
There was one variable that had essentially no effect on that, and that's how long the colonoscopy was. That astonished us, how clear it was.
That's led me into a lot of thinking about what I call the Remembering Self and the Experiencing Self. That is, you have the Experiencing Self, the one who lived through the colonoscopy, but the Remembering Self is the one that keeps a score -- assigns a score and keeps a score.
Another interesting thing is that if we make our decisions, it's the Remembering Self that makes the decisions, and it doesn't always do what's best for the Experiencing Self.
Morgan: What are some other examples of how I fool myself when I remember the past?
Kahneman: I think that's the main one, but there are others. Let's not spend too much time on colonoscopies; let's discuss investing.
In the context of investing, people don't know how well they have done. There is just a lot of self-delusion that goes on when people evaluate their performance. That's an example, and an important example.
Then, in just about everything, how well the story ends is the key to how it's evaluated in the past. It's true, by the way, in presidential politics. In presidential politics, what happened in the first three years has very little impact on election results. It's really what happens, and how well the economy is doing and whether it's improving, during the last year, that determines elections.
In a lot of places, our memory just doesn't correspond to the facts.
Morgan: Is that why we remember Nixon differently than Clinton?
Kahneman: Well, I think there are many reasons we remember Nixon, but yeah.
Morgan: If I have problems remembering the past, and I'm fooling myself, how does that shape my view of the future?
Kahneman: The main thing, the main mistake that people make, it's not so much in remembering the past. It's in thinking about the past. That I spent a lot of time on, in the book.
Whenever something happens and we feel we understand it, mostly... we're surprised occasionally but by and large the world makes a lot of sense to us. It makes a lot of sense because when things happen we find their causes, and it's OK.
Except that, if you compare our ability to explain the past with our ability to forecast the future, the difference is really quite dramatic. We explain the past with the greatest of ease, and we're really crummy at forecasting the future.
What happens here is hindsight, the ability to explain the past, gives us the illusion that the world is understandable. It gives us the illusion that the world makes sense, even when it doesn't make sense. That's a big deal in producing mistakes in many fields.
Morgan: You've written about hindsight bias with the financial crisis in 2008.
Kahneman: Yeah.
Morgan: What can you tell me about that?
Kahneman: There's something I actually find shocking. There are now quite a few people who say, "I knew there was going to be a crisis."
I think that's perverse. It's a perverse use of the word "know." That's because we use the word "know" for something... when I believed in something, and my belief was true, those are the two conditions under which we're allowed to say the word "know." I believed it with very high confidence.
But in fact, they didn't know that there was to be a crisis. They thought there was going to be a crisis. Then there was a crisis, and then all of a sudden they "knew" it was going to be a crisis, but there were people who were just as smart, and as motivated and so on, who didn't think there was going to be a crisis.
What is very important about this is whether you conclude that the crisis was really knowable. Given the number and the quality of the people who failed to see it, the fact that there are many people now who are sure that they knew it doesn't convince me. I think it wasn't knowable.
It was much less knowable than we tend to think because of the ease with which we can explain it. Everybody who didn't predict it looks blind, in retrospect. That's hindsight.
Morgan: If we suffer from hindsight bias and we think that the past makes sense and was predictable, does that make us more optimistic about the future? If we think we understand the past, then we have to think we understand the future.
Kahneman: Oh, yeah. Oh, yeah, it makes us way overconfident about our knowledge of the future. Overconfidence is everywhere. If you are going to pick among the biases of judgment, then thinking that we know when we don't, that's a big one.
Thinking that we control things that we don't is another big one, so optimistic overconfidence accounts for a lot of the mistakes that are made.
In the financial context, there's a really frightening study that was published a couple of years ago. It shouldn't really surprise you, and maybe it won't, but here is the way it goes.
There is a study being conducted at Duke, I think, for many years now where they pick the CFOs of I think the biggest 500 companies and they send them a questionnaire every year. It has a lot of questions, including forecasts.
One of the things that they're asked to forecast is they're asked to set an 80% confidence interval for the S&P 500 over the next 12 months. They have thousands of those judgments because many people come year after year.
In the first place, they have no idea what the S&P is going to do. The correlation is negative between their judgment and what actually happens. It's barely significant. It's nothing. They have no idea.
The thing that's worse is how overconfident they are. When you set an 80% confidence interval, if you are at least aware of how ignorant you are, and you do that many, many times, then 80% of the time the truth will fall inside your confidence interval and 20% of the time you'll be surprised.
In fact -- I'm pretty sure that I have that correct -- they have not 20% surprises. They have 67% surprises. They have no idea, and their confidence intervals are way too narrow.
Let me tell you where the true confidence interval ought to be for the S&P 500, because I asked the authors of that study to compute it. For somebody who has no idea, looking I think at the last decade or so -- that was not counting the last two years; I think I had the computation done in 2011 -- somebody who doesn't know anything about the S&P 500, and that's everybody, the correct confidence interval, there is a true answer to that.
The correct confidence interval that the S&P with 80% probability is going to grow between -10 and +30. What's striking about this is that this sounds like you are saying nothing, and it is saying nothing because you know nothing.
That's what the confidence interval ought to be if you know nothing and you know that you know nothing. But those CFOs don't know it.
Morgan: You've also written about that we want our experts and our leaders to be optimistic. We would rather they be optimistic than realistic, which sounds crazy. Why is that?
Kahneman: We tend to take people, to a very large extent, as how they present themselves. If people are assertive and confident, we trust them. Sometimes we trust them more than we should.
We have a special taste in leaders. I think that, by and large, people like leaders who are very decisive and quick and not too deliberative, not too slow. We like people to be optimistic, and we like them to be confident.
The idea of leadership that admittedly doesn't know what it's doing, you don't want that.
Morgan: How has learning all this affected you, personally? Do you view the news differently? Do you look at money and politics differently? How has it changed your behavior?
Kahneman: It really is hard to tell. I've been studying that stuff for so long. I don't know that it's changed things fundamentally for me. I do have that deep sense that I don't understand anything, or very, very little, and that certainly I cannot forecast anything beyond a fairly short horizon.
That I'm clearer about than I think I was. I'm also a pessimist, but I always was, so that's genetic.
Morgan: This hasn't made you more pessimistic, though?
Kahneman: No, you couldn't be more pessimistic than my mother.
Morgan: To put it in a practical sense, what are some things that I can do, and everyone else can do to help live a better, more fulfilling life based on some of the stuff that you have found?
Kahneman: I would say there are a number of things, actually, that you can do.
One of them is, we do tend to neglect our Experiencing Self. I think we do too much to build up a resume, and I don't mean that in a narrow way. The resume, what I mean by that, is each of us has a story, has a narrative; the narrative of our life. It's our prized possession and we do a lot to keep it looking good. We may be doing too much for it.
There is also a matter of living, of living your life. There are decisions that you might make differently. For example, in the life/work balance, there are decisions you might make differently if you are thinking of the Experiencing Self and not only of accomplishments and goals, and things like that.
Morgan: Do we have questions?
David Gardner: Dr. Kahneman, thank you so much for visiting us at The Motley Fool. We are really pleased. We've all learned a lot from you, and we've learned even more in this hour.
When you mentioned, "The more you live, the less you feel that you know," it reminds me of a great quote from, I think it was Archbishop William Temple, who once said, "The greater the island of knowledge, the longer the coastline of mystery." I think that's a wonderful way of thinking about the progression that we all go through over the course of our lives.
I wanted to ask you simply, I see something in the financial world, because that's our world, that looks broken to me and it's probably also broken in other areas of the world, and it's that there is no scorekeeping mechanism.
If people can make predictions and no one's actually holding them accountable or scoring them, then if you think of systems thinking, it's just fundamentally broken and we can't progress. But as soon as you do start to score -- I often liken it to baseball, where everything is scored -- I wish that more for our financial world, for our political world, and others.
Do you see good score systems in the world that we should all learn from, and/or do you have any thoughts about scorekeeping? Thank you.
Kahneman: I think there is really too little scorekeeping. It's sort of astonishing when you think of those CFOs coming in year after year, and making predictions that make no sense, and they come back next year with the same level of confidence. There is no improvement. There is some absence of scorekeeping there.
On the other hand, there are really many people I think that -- most of us -- have a lot to lose from accurate scorekeeping. That's because of what I said earlier, of our ability for self-delusion, which is really a major asset in our lives. That we can lose.
I have given that advice, to keep score and when you make a decision, document the options that you considered but didn't choose. I was giving that advice a lot, and there was one place -- I didn't know it immediately -- somebody took my advice.
It was in a financial firm. I won't mention what it was. For a year, he kept track of every decision he made and the options he considered and rejected. There was a fair amount of material collected by the end of the year.
Then they told me about it, and we analyzed it. That guy was making well in excess of a million a year, and the conclusion, which I didn't share with anybody, they didn't need him. They could have saved a million dollars. He was adding nothing.
That's the kind of thing that people expose themselves to when they keep score. It's a dangerous activity.
Audience member: First off, is there a title for Nobel Prize winners? "His Nobleness"? OK, just wanted to make sure I wasn't stepping on any toes.
Have you run across any organizations or institutions that you think demonstrate good statistical thinking? Maybe you could talk a little bit about how you think that they do?
Kahneman: I think there is a lot of very good thinking that goes on in the financial world, and that most of it is proprietary so you don't get to see it.
I have seen really very good, what I thought was excellent thinking, in a couple of venture capital firms where there is acute awareness of their biases and there is acute awareness of how incentives affect biases and how you can engineer the process of decision-making so as to optimize results.
That takes a very dispassionate look at the way we do, a dispassionate look at the errors that we're most prone to, and what can we do to avoid those errors?
It takes extremely confident leadership to do that, because the moment you implement a thing like that there is a standard that allows decisions to be evaluated, and that's the big risk.
Morgan: You've talked before, too, about George Soros. One of the keys to his success is that he's so well aware of what he's bad at, and his errors.
Kahneman: There are many keys to George Soros' success. That one, by the way... that one I didn't know. It's not from me.
He claims to have a theory. He's very interesting that way. The famous story about him is that he claims to have a theory that -- and there may be something to it, but other people don't understand what it is -- but his son says that basically he has a skill, and that actually when he feels sick, that's when he sells, so that he actually listens to his gut.
That's not the way he talks. I sort of believe it. Having met him, I believe he has that skill because he is dealing at a level... he's not dealing at the level of markets. He's dealing at a level where I think there is structure that he may understand better than most other people.
Morgan: Do any other investors that you can think of have a smart decision-making process that stick out to you?
Kahneman: Well, everybody mentions Warren Buffett, who obviously is a sage, but Warren Buffett, he doesn't buy stocks. He buys companies, and he buys companies he knows a lot about. Then he has a big advantage that whenever he buys something prices rise. That's something that other people could wish for but don't have.
Audience member: Thank you for coming. We deal with a lot of members here, and psychology is a huge part of that, particularly trying to get them to lengthen their time horizon for investment. In 2008 and 2009 that was certainly a challenge.
You mentioned executives and CEOs and share buybacks; we see that they tend to buy back much more of their stock when the price is high, and then they stop those when it gets low.
Do you have any suggestions for us, as people that communicate to investors on a regular basis, to help them get encouraged to stay the course and think long-term about investing and not speculating? Thank you.
Kahneman: I think that having a very good discussion of regret with investors is a good idea, because regret is the killer. You're losing, and then you decide, "Oh, it was all wrong. Let me stop," and that's when disaster strikes, I think. It's changing course.
I think it is very important not to encourage people not to do things that are likely to expose them to regret. The potential for regret is something that investors should know about themselves. "How much am I going to suffer if this decision of mine doesn't work out?"
"How easily am I going to think, 'Oh, I made a mistake'? How prone am I to think that I made a mistake?" It's a big variable, and really worth discussing, I think, with clients because part of the inability to stay the course... you have to inoculate yourself against regret.
You have to be prepared for things to go bad. You have to anticipate that possibility. There is a lot, I think, that can be done, but not everybody is going to end up with the same advice or in the same place, because some people are much more vulnerable to these emotions than other people and they should be much more conservative.
Morgan: There's a story -- hopefully I'll get this example right -- there's a story that you wrote where you met with a financial advisor and you told her, "I don't want to get any richer. I just want to keep living how I am right now," and she told you, "I can't work with you."
Kahneman: Yeah, she fired me.
Morgan: She fired you. How do you invest your own money?
Kahneman: Terribly, I think.
I lived through a period of very high inflation in Israel for many years, where inflation was like 30%-40% a year. It really changes your outlook on life when you live through a period of high inflation.
I'm really comfortable. I really don't need to... I'm comfortable and old. I don't need to get richer.
This was a few years ago, but I told that lady this. "I don't need to get richer. I just want to guarantee that I can spend about that level for the rest of my days," and I am invested accordingly. Apparently, not optimally even for that objective, but...
The one rule I have is I give very general instructions to my financial advisor, and then I don't monitor it. I think that's good, both because it causes more anguish than pleasure, on average, and because you're tempted to make stupid decisions if you monitor things too closely.
One advice I would give to people, I think a quarterly report is probably too frequent. Just don't look too often.
Audience member: I've recently been studying an advertising agency that's been using a lot of your work to make very emotional advertisements, or advertisements that appeal to emotion. They've had some early and astounding success.
My question is, as people become more aware that they are emotional decision-makers, will the effectiveness of appealing to emotion to get people to make decisions, will that effectiveness go down?
Kahneman: It could. What happens with this, by and large, when somebody tells you something or you get a message, our inclination is to believe what we hear and to be influenced by what we hear, including emotional appeals.
Our main defense against that is to tell an alternative story. "This person is lying to me. They're manipulating me. They're lying to me." You can't keep telling that to yourself, but if an advertising agency or a whole thing gets a reputation of being manipulative and dishonest, people may be able to resist their ads better.
But by and large, it's very difficult to resist advertisement because it works not only on emotional appeal. It works on sheer frequency. It's something that is almost impossible to resist, something that gets repeated a lot feels truer. It feels more believable, and they really work on that.
Audience member: One of the great points in the wonderful book, Influence, by Robert Cialdini, is that once we take a public stand it's very difficult for us to change our minds.
I was just watching an interview with Steve Jobs last night in which he said, essentially, "I don't care about being right or wrong. I care about success. I'm willing to change my mind every five minutes when I find that there's information that I didn't have, no matter how strong the stand I took was, or how aggressive or even rude I was about that point. If I find that I was wrong I'll change my mind immediately."
I wanted to hear what you think about the process of changing your mind, and how we might encourage that inside our company.
Kahneman: I think what you point out is really one of the major difficulties in people thinking, and probably in companies and institutions; that there is some stigma attached to changing your mind.
Now, I happen to be very extreme on this dimension. I change my mind all the time, and I change my mind in research all the time. That drives my collaborators -- also, I like to collaborate so I work with people -- and I drive my collaborators crazy. I change my mind.
I keep telling them... and also I am not very respectful of their ideas, either. I keep telling them, "Look. I treat my ideas as badly as I treat yours. This is part of the process."
I think encouraging people to change their minds is a very, very good thing for an organization to do. That is, rewarding it. That we want people who can "think again."
One of the things that I find astonishing -- I now work in consulting, so it's very much on top of my mind -- you mention something to people in the business world; you suggest they should do X. Then they do X. Then two days later, I don't think they should do X. I've found a flaw in it. I think they should do X-prime or Y.
You can feel that this is really alien to them, and can they trust me if I change my own mind?
Recognizing that the ability to change your mind is just part of good thinking... that improvements in thinking are incremental. You don't find a flaw and fix it. You find a flaw and fix it, and then you find another flaw in the fixed thing. That's the way it works.
Recognizing that this is the process is very difficult, and I think very useful. Thanks for the question, by the way. I'd never heard that one before.
Audience member: In thinking about how we can apply your kind of framework to our decision-making in day-to-day life, in what domains do we stand to benefit most from System 1 thinking, and in what domains do we stand to benefit the most from System 2 thinking?
Kahneman: I think you need System 2 thinking, and you need statistics, when you're dealing with a world where there is a signal but it's faint relative to noise. That is where intuitions are worst, I think. In a world where it's not completely chaotic -- and I think the financial world is probably like that.
There are domains where there are skills that people can acquire. My guess would be -- I'm sure that's not what you do -- but that high-speed trading is probably something that people can get good at. It's a skill, like driving. You get a sense for what's going on.
I don't think you can get a sense for where the market is going. What you can get is the illusion that you have that sense, so being critical and asking, "Is it possible that we really can trust our intuitions on this? Do we have the goods? Do we have the evidence to support the proposition that intuition can be trusted here?"
Intuition can be trusted for physicians. I'll bring that example. There are domains, for a given physician; there are diagnoses that he can recognize. That doesn't mean that he can trust his intuitions, or her intuitions, about everything.
You have to know when you have the skills, and you have to know when you are guessing, which is quite difficult to do, actually.
Morgan: Who should win the Nobel Prize this year?
Kahneman: I have a perennial candidate. I want Richard Thaler to win because I invited him to Stockholm. He has to return that invitation, and it had better be in my lifetime.
He is not only my candidate. I think he's a good candidate.
Morgan: Thank you very much.
 
Interview 8. The Guardian ("Magic wand? Overconfidence", 2015):

Daniel Kahneman is the very definition of unassuming: a small, softly spoken man in his 80s, his face and manners mild, his demeanour that of a cautious observer rather than someone who calls the shots. We meet in a quiet spot off the lobby of a London hotel. Even then I have trouble catching every word; his accent hovers between French and Israeli and his delivery is quiet, imbued with a slightly strained patience, helpful but cautious.
And yet this is a man whose experimental findings have shifted our understanding of thought on its axis – someone described by Steven Pinker as “the world’s most influential living psychologist”. With his long-time collaborator Amos Tversky, who died in 1996, he delineated the biases that warp our judgment, from figuring out if we can trust a prospective babysitter to buying and selling shares. In 2002 he was awarded the Nobel prize in economics, a testament to the boundary-busting nature of his research.
His 2011 book, Thinking, Fast and Slow, a primer on a career’s worth of psychological inquiry, won the US National Academy of Sciences book award, and the enthusiastic approval of his peers. It tells the story of “two systems” of thought, one automatic and intuitive, the realm of systematic biases, the other conscious and deliberative. It is a challenging work, clearly written but stuffed even so with difficult problems and counter-intuitive explanations. Despite that, it has sold millions of copies around the world. Nassim Nicholas Taleb, professor of risk engineering and author of The Black Swan, places it “in the same league as The Wealth of Nations by Adam Smith and The Interpretation of Dreams by Sigmund Freud”.
What’s fascinating is that Kahneman’s work explicitly swims against the current of human thought. Not even he believes that the various flaws that bedevil decision-making can be successfully corrected. The most damaging of these is overconfidence: the kind of optimism that leads governments to believe that wars are quickly winnable and capital projects will come in on budget despite statistics predicting exactly the opposite. It is the bias he says he would most like to eliminate if he had a magic wand. But it “is built so deeply into the structure of the mind that you couldn’t change it without changing many other things”.
The same applies to our habit of predicting stereotypical outcomes at the expense of what’s known about the world. When told of a student, Tom, who has a preference for neat and tidy systems and a penchant for sci-fi, most of us guess that he’s studying computer sciences and not a humanities subject. This is despite the fact that the group studying the latter is far larger. “Think of it this way. A form of stereotyping is involved in understanding the world. So I have a stereotype of a table, I have a stereotype of chairs. Now when you start having stereotypes of social groups, it’s the human mind at work. It’s not a different mind. It’s what you need to get around in the world.” You can slow down and become aware of this, Kahneman believes, but the underlying mechanism isn’t going to change.
That tendency to stereotype social groups has affected Kahneman’s own life, in dramatic fashion. Born in Tel Aviv, to Lithuanian Jewish parents, he spent his early years in France. They lived there comfortably until the German invasion. His father, who worked for a company owned by L’Oreal, was arrested during an antisemitic roundup and taken to the internment camp at Drancy. “I remember visiting,” Kahneman tells me. “I was seven. You couldn’t get in of course, but there were lots of people at the windows – men and lots of women and children. And there was a French policeman and I still have that image of him telling us that they’re hungry in there, they’re eating vegetable peelings.” Thankfully, his father was so popular with his employers that after six weeks they arranged for him to return home, the occasion for another vivid memory. “My mother knew that her husband would be released and she and I – we were living in Neuilly, just outside the main part of Paris – went out shopping. We came back, and my father was there, wearing his best suit. He weighed 45 kilos. He was just skin and bones, but he hadn’t eaten: he was waiting for us. There was considerable dignity in that.”
As the occupation wore on the family was nevertheless forced to flee to Juan-les-Pins on the Côte d’Azur. But after the allies landed in north Africa the Germans took over the south, initiating a “very dark period”. Kahneman began to pray for his life. “I knew that God was extremely busy, so I wasn’t going to demand too much. But I was asking for one day at a time. That’s what it felt like. It felt like being hunted. We had the mentality of rabbits.” Moving from one village to another, making their way to the centre of France, they ended up living in a converted chicken coop. It was there that Kahneman’s father, who was diabetic, suffered a stroke and died, just six weeks before D-day. Another image sticks in his mind. “It was very, very cold in winter, and I remember my mother in full mourning with a veil and with an axe in her hand, breaking wood.” Still, he denies that the experience was traumatic. “It’s nothing compared with other Jewish stories. I was never really hungry, I never saw real violence. There was a lot of resilience.”
Soon afterwards, his life changed completely. France was liberated, and then, in 1946, the family moved to Palestine. Kahneman had been an intellectual child and he thrived in his new home, ending up some years later with a bachelor’s degree in psychology, conducting personality tests for prospective army officers.
As an Israeli, there at the very birth of the nation, Kahneman has had a front-row seat in one of the most vivid theatres of human misunderstanding. His work has much to say about prejudice, the inability to fully recognise alternative points of view and our strong aversion to losses, which considerably outweighs the satisfaction we get from gains. Can he explain why, in this area, it’s been so hard to achieve a meeting of minds?
“I’m far on the left of the spectrum in Israeli politics and always have been,” he says. “I hated the notion of occupation since the very beginning. My first memories from after the 67 war are travelling with my children in the occupied territories. There were awnings over groceries stores with Hebrew lettering advertising Osem noodles. I couldn’t bear it. I thought that was dreadful because I remembered German lettering in France. I have very strong feelings about Israel as an occupier.”
Despite this, Kahneman has found it impossible to envisage a settlement that will satisfy both sides. “I don’t believe in the power of rational argument in this context,” he says, with an air of resignation. He mentions one occasion when he was visited at his university by a Palestinian academic after 67. They were getting on famously. But then “we tried to negotiate peace, and we failed, essentially on the right of return, which although obviously a legitimate demand among the Palestinians, means the destruction of Israel. So people who don’t want Israel destroyed cannot accept the right of return, even though they might understand that it has legitimacy behind it.”
In general, Kahneman is downbeat about the capacity of his brand of psychology to effect change in the world. I imagine he would simply argue he’s a realist about human nature. And, indeed, studies showing that “skilled” analysts are hopeless at predicting the price of shares have yet to translate into mass sackings or even reduced bonuses on Wall Street or in the City. The same goes for evidence that the influence of a high-quality CEO on the performance of a company is barely greater than chance.
But there are more modest ways his insights can help us avoid making mistakes. He advises, for example, that meetings start with participants writing down their ideas about the issue at hand before anyone speaks. That way, the halo effect – whereby the concerns raised first and most assertively dominate the discussion – can be mitigated, and a range of views considered. Then there is the concept of adversarial collaboration, an attempt to do away with pointless academic feuding. Though he doesn’t like to think in terms of leaving a legacy, it’s one thing he says he hopes to be remembered for. In the early 2000s Kahneman sought out a leading opponent of his view that so-called expert judgments were frequently flawed. Gary Klein’s research focused on the ability of professionals such as firefighters to make intuitive but highly skilled judgments in difficult circumstances. “We spent five or six years trying to figure out the boundary, where he’s right, where I am right. And that was a very satisfying experience. We wrote a paper entitled ‘A Failure to Disagree’”.
Kahneman’s finely tuned ability to detect the biases in the thinking of others hasn’t, of course, released him from the cage of his own nature. He is a pessimist, “a worrier”, “not a jolly person”. But, despite this, he says, “I’m quite capable of great enjoyment, and I’ve had a great life.” His friendships – notably with Tversky, his academic soulmate, and behavioural economist Richard Thaler, have been long and fruitful. He has been married since 1978 to the perceptual psychologist Anne Treisman, and has two children. When I ask about them, he explains, matter of factly, that his son is schizophrenic. “He would have been a very brilliant economist.” His daughter is now “successful in hi-tech”.
Despite his sadness over his son, and all the other inevitable trials of life, it’s possible to regard Kahneman as a living, breathing counterargument to his theory of pervasive overconfidence. Who, after all, would have looked at the Jewish boy in the chicken coop in occupied France and predicted his survival, let alone his many accomplishments? Or the transition from respected academic to intellectual superstar? Yet popular recognition, which has come late in his career, was never his primary aim. “I had limited ambitions, I didn’t aspire to great success. I was very hardworking, but I didn’t expect to be a famous psychologist.”
The next problem on his list is “noise”, or random variability: the fact that different people in the same situation make very different judgments. Random error is a very different phenomenon from the systematic biases he’s been studying for several decades. It’s the kind of error you can’t reliably predict. Noise, he says, applies to people approving loans, to underwriters, to radiologists. One worker might be more optimistic than another, say, and it becomes difficult to ensure uniformity. “Mood is noxious. Noise is costly to organisations, which are essentially factories for making decisions. If another underwriter had seen that case he would put a different premium on it …” It’s even worse, presumably, in the case of a radiologist examining a scan for signs of cancer. Kahneman is interested in looking at how to increase the consistency of operations – not the same, he explains, as controlling biases. It sounds like a new and fascinating chapter. And when he decides to write it, one thing is now certain – he can count on millions of readers. 
Interview 9. Behavioral Exchange Conference (BX2015):

Richard: Probably the first thing I should say about Daniel Kahneman is that Daniel is in New York so we have a very special an absolutely foolproof cannot possibly go wrong live link-up provided courtesy of Cisco so down this link up Richard will be interviewing Danny Daniel Kahneman is of course best work for his best known for his work with Amos Tversky the late Amos Tversky for which he won the Nobel Memorial Prize in Economics in 2002 he's also very widely known for his popular psychology book I mean that in the sense of it sold a lot rather than that dumbed they field down which was thinking fast and slow those of you paying attention to what Daniel is doing will know he's written and published very very widely not just in fields that we would associate with behavioral economics and he's also been involved in trying to improve standards replication in psychology so a very important influential individual both in economics and of course in his own field of psychology so it is my great pleasure to welcome Daniel Kahneman to the screen and Richard Taylor to the stage I can see you Danny can you see me yeah okay yeah yeah you look very smoky grace oh thank you thank you thank you I as you know I don't put a tie on for just anybody so I appreciate that yeah thank you thank you yeah so let me start with this you and Amos had one of the most successful academic collaborations in all of science and much of your other work is joint we have lots of aspiring young academics here and aspiring people in all kinds of fields any advice what makes a good collaboration out how have you pulled it off or is it just luck2.
Daniel: There's a lot of luck you know you've got to like the people you're collaborating with it really doesn't work otherwise and they've got to like you and and that's now you miss out you know I'm telling you but I've just confessed to liking you and I'm sorry because in our interaction I should be but that's it I mean you you have to enjoy working that way it's it's a slow way to work certainly it's slow for my collaborators and they can all they can all guarantee that it's a slow way to work it can be very frustrating but if you're doing the social interaction then it's is pretty wonderful and then in some truly magical cases and I think Amos and I had that magic and to some extent even you and I had a bit of magic then then the two are simply superior to either one alone and it can be because they have complementary skills or because they have complementary knowledge or it can be because they have complementary characters and are able to eat them you know that were the case for Amos and me I think each of us brought out the best in the other and Amos couldn't understand the very vague things I commonly say better than I did and that was certainly one of the big things that that made our work possible yeah you certainly seemed to be having more fun with Amos than when you were writing your book well that's not a big thing to say no that's that's yeah that was acutely miserable when I wrote the book and it was a very lonely experience so yeah you've been doing some private sector consulting work on noise reduction which does not seem to have affected the noise level in restaurants so you must be working on something else good could you tell us a bit about what that is and let's start with that2....
Daniel: Sure you know there are many organizations in which you have lots of people essentially doing very similar jobs or making similar kinds of decisions on behalf of the organization so you can have people approving loans I mean now there's a lot of robots approving loans but you also have people approving on you can have people picking stocks you can have you can have financial advisers making decisions about who they will which client they would see I mean they're just thousands of examples and when I would define as noise is that when you have two people making similar decisions or essentially the same decision on behalf of the organization if they don't make the same decision that's noise and we already know from psychological research that there is a lot of noise I mean people if there is internal noise people are not when you show them the same information twice even if it's an x-ray by the way people are very likely to give you different answers turns out my sense is this problem is completely ignored in organizations so I can't describe my client but but the client with whom we worked has a lot of people making very similar decisions with fairly high states for for themselves for the organizations and for their clients and I asked them the question if you have two people facing exactly the same problem and it's a numerical problem they're making decisions that involves quantities when you think the variability will be relative to the mean what's the average difference that you expect between two randomly people facing the same problem and oddly enough you get five to ten percent as an answer in many contexts and since the blue in that organization we could try because we could create materials show the same materials with 40 people and actually measure what is the average distance between two individual it's about 40% and we replicated that more than once it didn't come as a surprise to me because I knew the psychological literature it came as a complete surprise to the organization and that is very interesting I mean how come you get people making decision they respect each other there is what psychologists call false consensus everyone assumes that other good people would make exactly the same decision they do very rarely do two people independently make the same decision so have noise and turned other noise I don't not invariably but in every example that I've thought about no it is actually there costly so I'm interested in noise it's it's a problem that hasn't been recognized people think of bias you know most of my life I studied wise but then but noise has interesting characteristics it's it's easier actually to control noise than to control bias because you can control noise without knowing the correct answer and that's what I engaged so how do you distinguish between noise which is bad and diversity of opinion which is good3....
Richard: Well the point about diversity of opinion is that it's overt and something comes out of it and it's and you have I mean evolutionary noise is a very wonderful thing you know you get many so longer there is a selection process that selects the better over the worse but so you have that in diversity presumably people are solving the same problem and they know when it's all and diversity can help in some problems and many problems there those are the helps noise is silent actually mean it's an absurd thing to say that noise in silent people don't know that it exists so they don't correct for it so yes sir you're referring to a situation where you have lots of people doing the same thing independently absolutely and coming up with very different answers as opposed to collaborating least Wester then this morning mentioned that psychologists have been trying to disabuse people of the idea of doing interviews for 50 years or so with with little success what is there anything from your project that might help make interviews less noisy4....
Daniel: Well yes I mean actually there is you know there is a general strategy for dealing with noise and what it involved is breaking up problems into elements dealing with with the elements according to a reasonably straightforward and agreed-upon technique and then combining them according to a rule so there are interview system that worked like that but they devised you know my thinking about this I devised an interview system like that for the Israeli army since six years ago and and it's based on taking the various aspects that you want to look at and dealing with in sequentially and as independently as possible and scoring each of them and that reduces noise so adding structure adding structure that concise summary makes me feel that I'm rambling I could have said I cured you of rambling 30 years ago I know I know you know you haven't you haven't rambled since that's good so what do you what have you learned from this experience in terms of dealing with large organizations so how do you get buy-in how I mean you're telling them things that they initially resist how do you get from here to there because we have you probably eight nine hundred people here some of whom are trying to influence governments and you know you get some result and then somebody says you know you're just some psychologist what the hell do you know how do you get past that5.
Richard: Well I mean especially if you don't Nobel Prize.
Daniel: I think I think every consultant should have one because it actually does make things a lot easier yes that's so there's an unfair advantage right there but you know who said anything about getting there I mean you know getting from here it's it's quite chancy whether or not you have influence someone's my the best ideas I've had I've gotten absolutely nowhere somebody must be and that's a chance event must be interested in in doing that it's very important not to step on you know if the change you want to introduce will cause somebody to lose status and he's in a position to block you then you'll get blocked and I mean there is no guarantee on those things the government's might be easier I suppose but I'm not sure they are and dealing with things that don't defend any money and that don't violate the procedure that people already follow in ways that that would cause someone to lose status or prestige or power that this is related to it another point I know you feel strongly about which is that in designing any kind of policy we need to worry about who the losers are going to be you want to elaborate on that a little bit oh yeah I you know I believe it loss of that's but I what I believe is that when you are introducing change in most situations when you are introducing change change doesn't leave social arrangements neutral there'll be winners and there will be losers and there is I think a basic rule the losers the potential losers fight a lot harder than the potential winners and when you look at reforms reforms typically and being more expensive than anticipated and usually buy a lot and I think it's that that mechanism is it work as an interesting finding in the study of the endowment issue and one of the more interesting ones that I think is by a friend dragnet agents don't seem to have an endowment effect whether they don't anticipate the kind of loss aversion that their clients will fear reformers are like agents leaders are like agents they don't anticipate loss of virtue they think the final state will be good it's all wonderful in fact then create winners and create losers they'll have to compensate the losers for their loss and it will end up being more effective and sometimes it will fail and all of that I think because of the existence of losers so that would be even the first piece of advice that I give to anyone interested in bringing change to any organization who are the losers going to be and what are they going to be able to do to you well but it's it's difficult to know how you make them whole5....
Richard: I remember a problem you and I tried to solve about your stepdaughter leaving high school a year early where my very stupid advice got you know where it was to buy hundred Jaguar yeah a car of her choice was well you can't always you know make them whole but sometimes you can and and here the basic idea is one that is also at the foundation of nurtures and it's the cool tipping idea figure out what is going to hurt what are people actually going to lose what are they why when is preventing them from already doing what you want them to do and sometimes if you just think about reducing their resistance finding ways to compensate them finding ways to alleviate the loss you can reduce the resistance very substantially but you have to be aware of it it's not always going to be possible but in many situations that actually is especially when you're dealing with issues of status prestige power there are ways of arranging things so that you can minimize the hood so the this morning in my talk I was saying that nudge and behavioral insights have largely rested on the work of Kurt Lewin and Bob Chiellini who's here and you and Amos and that there are more psychologists and social scientists out in the world and that we should broaden our horizons are there parts of psychology that you think deserved more attention from practitioners that are ripe for practical implications I'm not sure I mean I you know I hadn't I hadn't prepared for that so I haven't thought there are many things that that we could do that the people are already in that field and operating in that space could do that they're not doing so there are whole areas of potential application of you know what is called with many people call behavior economics and I call applied social psychology most of the time there are many areas where we could do think that we're not doing it in MoMA yeah I guess what I mean it couldn't work either way it could be that we try to recruit psychologists who don't normally think of playing in the policy domain or it could be reading those psychologists and realizing that they have insights that could could be used in in any of the you know reducing crime or well you know obesity or what whatever problem we're trying to nudge6....
Daniel: Yeah I mean clearly there are experts in in a lot of in the love of areas and but my guess is that people are interested in crime reduction are in some ways already active in that space so it's a matter of bringing them of reaching out to them and bringing them to you and creating that association so I'm not I'm not making it clear what up well what I'm saying is are the are those of us who are busy nudging missing branches of pure psychology that I mean if I surprised you with this so I mean I mean the answer is I'm sure there are my god but you get but you don't have one at the top of your head health and you have something I do have an answer to another question oh well I might get to it either one you know don't ya okay here's one that you said you were willing to talk about you know I couldn't make this so easy to give all the questions in advance this was a question that someone on the team suggested which is do you worry and how worried should have this crowd be by the recent replication study well I think psychologists should be very worried about it I think you know they I think as it happens this fraud has less reason to worry then than most psychologists and the probe has less reason to worry because because experimentation is built into the DNA of that approach and and so long as that is kept that you you do everything in control randomized controlled experiments and and not before after mostly but but actually randomized control then you you guarantee your own replication and so you I don't I think psychology should be worried psychologists should be worried but this particular crowd has less reason to worry than most meaning that if something works someone else will try it and so it will get replicated and it's yes not at every trial that that the nudge unit runs will replicate if it's done again well that's an interesting that's an interesting issue because you're absolutely right that's the experimentation doesn't guarantee replication that failures of replication are failures to replicate experiments and but the point is you know if you have randomly selected your crowd from a relevant environment and you have done it appropriately the chances that it will replicate in that environment and with7....
Richard: That population are really quite high if you want to do it in another context what you learn from the replication issue is that changes in context that we don't expect will make a difference are likely to make a difference so I would say whenever you really move any significant step away from the experiment redo the experiment in your new context so I think you also agreed to answer the following question which is how should young scholars think about choosing topics of research not not what should they study because I know you're not gonna give advice about that well I'm not going to give advice about choosing a topic study I mean you know it's sort of going to sound completely trivial don't study anything that is not fun for you to study I mean really don't do that don't ask yourself whether what you're doing is likely to be interesting once you have done it so it should be fun to do it should the answer that you expect to get so that you hope to get should be interesting and and you should know and that's the hardest thing you should know how long to persevere when things are not going well not too long if it isn't going well and you have tried a couple of times give up and get another idea and if you can't get another idea do something else I mean I don't do research I think you sure I yeah ignore sunk costs is good advice I think you share my view that many people spend too much reading time reading the literature and sort of end up doing tweaks on tweaks or is that just that I'm lazy which we know you think I am and this is not published fuck it you mean I wrote it in my book that you claim that I'm lazy yes that's so it that's right that's it is a published fact but but beyond my laziness I mean I'm always telling my students to be less about the literature and more about life I mean do you agree with that advice or you know I I think it's gonna be taken too far but but by and large of course I agree with that advice but when you're in the business when you're in the real world you're not in general applying the latest result in you know from psychological science you are you are applying ideas that have been around that have been pre-tested I and and I'm interested in the discipline I always was in fact8....
Daniel: I was teaching that seminar in Jerusalem than 40 years ago it's in applying psychology it's not applied psychology it's applying ideas that are out there typically big ideas like the quote Levine's ideas that's that's what you do and and so for that I agree the literature is likely to be somewhat less relevant although you know they're an interesting thing that are happening these days that people can bring them can bring to your can bring to other people's attention that might be relevant by and large most of the good applied work applies ideas that have existed for a long time but I I know I've heard you say that the what ends up getting called Applied Psychology is not a part of psychology that has been held in high esteem and is the work of units like this helping or is that an irreconcilable problem I mean in the first place it's a geographic problem and if you've heard me say that Applied Psychology has had a very different standing in the UK and in the US and in the UK applications had always been intellectually respectable much more so than in the u.s. so the unit for Applied Psychology was you know when are the intellectual centers of psychology in in Britain you know 40 years ago thirty years ago and maybe still it in the United States the word applied had a sort of inferior connotation it it lost that temporarily during World War two so major talent flowed into applied work and you got magnificent result that to me the cognitive psychology came on him out of that eventually and many other good things in psychology came from people encountering the real world but by and large the status of Applied Psychology is not high in the United States not nearly as high as it is I think in the UK and it's not an accident that what you're seeing including you know the unit that is organizing this Simula it is not it's not an accident that grew up in London I'm not sure I agree with about that but I think it's largely an accident but but now we can argue about that later here's the question from our friend Steven Pinker who's who's here which is should de biasing be part of the curriculum so should should we be explicitly trying to teach people to overcome to the biases that we talked about9....
Daniel: I think it would be good to have in the curriculum something that makes people recognize when they should slow down and reflect them when they're doing run or what they are about to decide we can't reflect all the time and I think teaching about biases is usually not very effective at all but introducing a language to talk about biases educating gossip as I've said that I think could be useful and and helping people recognize situations where it is important for them to do the right thing and where they are likely they follow their nature to do the wrong thing teaching people to recognize that is important and today I would because of my interest in noise I think that the the recipe for and the prescription for better decision making for better judgement better organized a structured way of thinking is not oriented to particular biases structure in itself can be a good thing and that's not the same as device what was the question that I forgot to ask you thank you well you're not being thinking about what is the next thing that behavior economics should you that's what you didn't want to answer okay you're good answer that yeah because it's not a matter of recruiting other people it's I think there is an awful lot of decision-making that is going on within firms and in governments and and much of it is really a very poor quality it's evolved it hasn't been designed and designing procedures for making better decisions that is a very large field I have called it something the human engineering of decisions just seeing an organization as a factory that produces decisions and then asking what Quality Control can we apply how can we improve the production process for making decisions this I think is a huge and unexplored field and with the increasing prestige of behavioral economics and the willingness to experiment getting into that is I think that is a very big challenge that's where I was in a way resisting you know bringing in new people I would say there is a lot of work for the existing problem because that is not very different from what the existing probably being trained to think about well when we when we try to impose structure though we're gonna run into your another version of your losers problem as you know I've been working10....
Richard: With one of the National Football League teams and trying the trying to get the football people to make smarter decisions is really hard like impossible and and they strongly resist having somebody else make that for them they think that's you know picking players and deciding whether to go for it on fourth down is not something someone my size should be advising you know of course you're right you're going to encounter this and by the way there are situations in which they're right I mean so I've interacted enough with Gary Klein you know my my friend and intellectual adversary to know that the issue of when you do want to trust situation and when you want to control into motion that's not trivial I don't want to eliminate intuition form from decision-making what I would like to do with intuition is delay I would like people to consider a problem before they have an intuition about it they're not after they have an intuition about them now with respect to the amount of opposition that you can expect you can expect a lot of it but that may be because you're impatient I mean you have to think in terms of you know how long how long will it take you to become sort of a famous member of the establishment president of the American Economic Association you didn't start out seemingly going that way took it 25 years and long Moneyball Moneyball has had an impact it didn't have an immediate impact but it had a substantial impact and I think this kind of thinking is potentially promising I think and could it could take off and don't give up even even with the bow players and football teams okay so the following questions you can't blame me for what is your most underappreciated paper and why I know which one you think I don't appreciate it enough but that's true but other people do so that doesn't count Dale isn't here so we won't we don't need to mention it you know I really don't have the feeling that I've been treated badly by the community I don't carry you know that kind of wish for recognition of an ignored paper there are lots of papers of mine that by the way and if it's something that happens with papers that are well-known that some of the best bits in the paper that are well-known are ignored you know people11....
Daniel: Select from your papers and they select what they want and that's not always what I would like this for example of my work I would say take non regressive prediction and base rate neglect that Amos and I put in the same paper not by accident probably I mean my favorite is none number aggressive prediction Amos Amos is favorite clearly was base rate neglect the feel mistaken base rate neglect Nam regressive prediction is still pretty esoteric ideas for many people base rate neglect is much more common that kind of things arbitrary selections from things you have done of course there is a lot of that but you know nobody had the right to be bitter about you know okay here's a here's another question what does the potential and limits of using nudges to increase social capital in developing countries yeah I told you I didn't write this question Danny good all right so here's a different question have you have you soured on your goal your admirable goal about adversarial collaboration are you as pessimistic about that as you are about most things it didn't go very well you know I have that idea that people who have you know the bait should agree to settle things by experimenting by working together there haven't been many takers but interestingly enough the replication crisis is giving a new opportunity for a kind of adversarial collaboration and I've been pushing you know that's that's one of the main things that I've been interested in in achieving and I haven't really but but some things are thinking are happening is that when people replicate somebody else's work they should in effect invite the original author into a collaboration the original author should be involved the original author should criticize the replication the idea that you can that you can replicate somebody's work and then send them the results in the mail for their comment I think that's non collegial I think it is awful behavior and my impression is that the field is going to move that way that replications are going to be collaborative and so that's another version of adversarial collaboration and I have nothing to do with it but I think this is we do yeah so my impression of this recent project is that it was non adversarial in the sense12....
Richard: That the lead authors just commissioned sort of independent parties to to try to replicate a study and and they they were told to consult with the original authors and make sure they get their details right and they did I mean if that were the first question I asked because it was not in the original science paper so I wrote Brian Nosek and I asked him what did the authors do and did the authors change their mind you know other 50% within replicated servants and then people I presented some cases and the answer is by and large that they did collaborate I mean the the Replicators tried honestly to get through and the fact that they were replicating recent work was very helpful and the authors by and large played by the rules the author's probably didn't say them on so you know you you have a finding somebody else fails to replicate it and all of a sudden you get you know those extra 50 and IQ points that you see why it was obvious that there was something wrong with their replication this apparently happened you do yeah one of my favorite condiment Tversky sentences which I ran across recently involves a long term non collaborative adversarial relation you've had over the years and the sentence is that a critique of a caricature can only be a caricature of a critique yeah the the term was refutation but yes it's I'm terribly embarrassed about that one that particular sentence that the refutation of a caricature is a caricature of refutation I was very proud of the symptoms except I found that that used it it's a very good sentence I used it twice without being aware it's in to publication of two separate publications one of them less well-known okay I think I've run out of questions you want to answer and we together are preventing everyone here from consuming alcohol these people I will say it's been nice talking to you Thank You Danny well thank you very much to Daniel and thank you also to Richard Taylor handled with aplomb I think exemplifying the idea of adversarial collaboration there actually you exemplified the idea of adversarial collaboration that interview was perfect in the interview yeah exactly exactly well it helps if you're friends now do13....
Richard: You want to stay on the stage you'll get off the stage I don't mind whatever you're okay thank you always good to check Richard I've kind arm well make sure you're happy one final thing I'm not here to borrow I've had a wonderful day and I hope you would all like to join me in showing your appreciation for the staff of a hotel and above all for the staff who organized behavioral exchanges been absolutely wonderful thank you you
 
Interview 9. On Being with Krista Tippett (2017):

Krista Tippett, host:The classic economic theory embedded in western democracies holds an assumption that human beings will almost always behave rationally in the end and make logical choices that will keep our society balanced on the whole. Daniel Kahneman is the psychologist who won the Nobel Prize in Economics for showing that this is simply not true. There’s something sobering, but also helpfully grounding, in speaking with this brilliant and humane scholar who explains why none of us is an equation that computes. As surely as we breathe, we will contradict ourselves and confound each other. And this reality check illuminates so many of our present tangles.
[music: “Seven League Boots” by Zoë Keating]
Daniel Kahneman:When I ask you about something that you believe in — whether you believe or don’t believe in climate change, or whether you believe in some political position or other — as soon as I raise the question why, you have answers. Reasons come to your mind. But the reasons may have very little to do with the real causes of your beliefs. And we take the reasons that people give for their actions and beliefs, and our own reasons for our actions and beliefs, much too seriously.
Tippett:I’m Krista Tippett, and this is On Being.
[music: “Seven League Boots” by Zoë Keating]
Daniel Kahneman’s book Thinking, Fast and Slow brought his groundbreaking ideas, which he pioneered with his late friend and fellow psychologist Amos Tversky, into mainstream culture — and now he’s about to release a new book. He was born in Tel Aviv but spent his childhood in Paris, where he and his family became caught up in Nazi-occupied France. He is a self-described and well-documented constant worrier, and his continuous questioning of himself and others is also a source of his creativity, warmth, and humility. I experienced this when he first sat down — a little late — for our 2017 interview, with the very reasonable excuse of New York City traffic.
Daniel Kahneman:Hi, Krista. This is Danny. I apologize. I’m normally — I’m pathologically punctual, so this really shouldn’t be happening.
Tippett:[laughs] I believe you. I believe you.
Kahneman:Good.
Tippett:And not to worry. I’m glad we have been able to make this happen, and it’s really an honor to sit down with you.
Kahneman:Come on.
Tippett:[laughs] It’s true. But I won’t embarrass you anymore.
Kahneman:Yeah, thank you.
Tippett:Well, I think we can begin. I have a question I always ask whoever I’m speaking with, which is about the religious or spiritual background of one’s childhood. When you talk about how you became a psychologist — here’s something. Someplace, you wrote: “I was discovering I was more interested in what made people believe in God than I was in whether God existed, and I was more curious about the origins of people’s peculiar convictions about right and wrong than I was about ethics.” I found that really interesting.
Kahneman:Yeah, I couldn’t say it better. [laughs]
Tippett:[laughs] And I have to say, I’m also very intrigued about how you talk about — your mother was a very intelligent gossip and that that, also, was a way that you came to this experience, this sense that people are endlessly complicated and interesting.
Kahneman:My mother was really a very strong influence on me, through — really through gossip, I think. I mean, there was a lot of intelligent conversation about people, and people seemed to be surprising and interesting; interesting to talk about. In fact, it was politics or people, were the subjects that I was exposed to — or Germans.
Tippett:Right, and that background of your family was steeped in that drama of the Holocaust. I mean, you even have told quite a few stories about discovering the many sides to every person, in interactions that your family had with Germans before the liberation.
Kahneman:The main story I’ve been telling, which was in Paris — actually, in Neuilly, which is close to Paris — and that was 1941. I was seven. The Jews were wearing a yellow star, and a curfew had been declared for 6 o’clock, I think, for Jews. I’d gone to play with a friend, and I was late. So I turned my sweater inside out, and I walked home. And very close to home — actually, I went back to that place last year, out of curiosity, to match it against my memories — I saw, on that street, a German facing me, coming towards me, and the street was otherwise deserted. And that German was wearing a black uniform, and that was the uniform of the SS, and I knew enough to know that they were the worst of the worst. And then he beckoned me and picked me up. And I remember being quite afraid that he would see, inside my sweater, that I was wearing a yellow star. And then he hugged me very tight, and he put me down and took out his wallet, showed me a picture of a little boy, and gave me some money. And we went our separate ways. That was an impressive story, for me.
Tippett:I like to consider all kinds of questions of our time, with a long view of time. And starting with the Enlightenment, with this particular intensity, we wanted to insist that we are rational, logical creatures. It’s fascinating for us to be talking about all the things that happened — and there was much more, especially in the mid-20th century, which bespoke our irrationality. And yet, even this idea of rationality, and many of our disciplines, formed around that presumption — certainly, economics.
Kahneman:Well, the concept of rationality is a technical, mathematical concept. It’s a logic. And it is actually completely not possible for a finite human mind to be rational or to obey the axioms of rationality. You’d have to know too much. The difficulty of being consistent in all your beliefs is impossible. And if you are not consistent in all your beliefs, you can be trapped in an inconsistency, and then you’re not rational. So the concept of rationality, the technical concept of rationality, is psychologically nonsense. And I don’t think we ever claimed to have demonstrated that people are irrational. I really don’t like that label.
Tippett:Well, that’s interesting, because that word is really thrown around in how people write about you. But would you say — it seems to me that what you did, in social-scientific terms, is you articulated cognitive rules — not for human irrationality, but perhaps for, let’s say, this reality that we do contradict ourselves, that we are complicated creatures.
Kahneman:Well, actually, the cognitive rules are, to a large extent, simplifying rules. They’re shortcuts. Our examples were sort of amusing and clever, and they impressed people because they were highly quotable. They could be summarized in one-liners. So we earned that label of being prophets of irrationality by doing psychology in an amusing way.
Tippett:I guess what I’m pointing at is — as a non-economist, as a citizen, I think that the economy, and that cultural and economic events, especially around 2008, made it very clear — although everybody doesn’t stop to analyze it this way, but made it very clear that we weren’t dealing with a merely rational part of our collective life together. So that behavioral economics had a resonance, if anybody was interested to pay attention to that, in the larger culture.
Kahneman:That’s interesting, because I would say, my view of 2008 is that it didn’t demonstrate irrationality. The bankers, they were acting as rational economic agents, in their own self-interest. What 2008 did, in the eyes of the public and, I think, in the eyes of many economists — it reduced the hubris of the economics profession. It was a failure to predict. The failure to predict it is what, I think rightly, impressed many people about the limitations of economics.
[music: “Birds” by Lambert]
Tippett:In his 2011 book Thinking, Fast and Slow, Daniel Kahneman brought a core idea from academic psychology into mainstream cultural dialogue: the notion that human behavior at any given moment is an interplay between two forms or systems of thinking. The so-called System One thinking is fast, intuitive, and completely unreflected — things we do automatically or have learned so that we do them, as it feels, without thinking; for example, walking, talking, reacting emotionally, knowing the answer to two plus two, driving a car.
System Two is the brain’s slower, more deliberative and analytical mode. It doesn’t do two plus two, but it picks up 17 times 24. It gets involved in difficult life decisions, in self-control, and sometimes, in checking and correcting intuition. The main thing about System One, Daniel Kahneman says, is that it can’t be turned off. The main thing about System Two, even though we might imagine it to be the “real,” conscious us, is that it’s lazy. It’s very capable of endorsing and rationalizing what our fast thinking is telling us to do and say.
I’m Krista Tippett, and this is On Being. Before he wrote Thinking, Fast and Slow, Daniel Kahneman won the Nobel Prize in economics for helping create the field of behavioral economics.
[music: “Birds” by Lambert]
You note that there’s something quite miraculous about how so much of what we do becomes automatic, but that this effortful thinking, this ability to be deliberative, is more rare, but we pay more attention when we do it, and we think we do it more often, in our imaginations.
Kahneman:Well, it’s the only thing we know. That is, effort and attention are very closely related to consciousness; so what you’re conscious of, what you’re aware of. And with System 2, when  you multiply 17 by 24 in your head, or even not in your head, you’re operating in sequence. And you are aware of the sequence, so you are aware of your thinking.
But in System 1, you’re not aware of the thinking. This is one of the definitions of intuition: It is that it’s knowing something without knowing why you know it. And I have no doubt — you know, most of my work has been to question intuition, but some people have it. And drivers have it. All of us have it, in many social situations. So we become skilled, and when we are skilled, what used to be effortful and System 2 becomes automatic and System 1.
Tippett:Right, what used to be slow becomes fast.
I have felt like, as we move through this century — it was hard to argue after 2008 that economic behavior, and also the discipline of economics, is entirely logical. And I think it’s impossible to argue that about our political lives, as well, globally, now. And I think, also, our lives with technology privilege fast thinking and reacting. I’m just so curious about how you inhabit this moment, with the scientific perspective that you have.
Kahneman:Well, that was a big question.
Tippett:I know.
Kahneman:There is a lot to say about it. In the first place, I’d like to observe that the term “behavioral economics,” as it is used today, the kinds of things that behavioral economists are supposed to do, that’s really social psychology. It’s principles about how to affect behavior. And it is remarkable, and some people find it sad, that social psychology had to disguise itself as economics, before it had an impact on the culture.
Tippett:To be taken seriously.
Kahneman:And that’s because economics has a better brand than psychology. So that’s one thing, one remark I wanted to make.
A completely different one, which occurs to me because you mentioned politics, is that one of the important realizations that come from thinking of the world in terms of System 1 and System 2 is that our beliefs do not come from where we think they came. And let me elaborate on that sentence. When I ask you about something that you believe in — whether you believe or don’t believe in climate change, or whether you believe in some political position or other — as soon as I raise the question why, you have answers. Reasons come to your mind. But the way that I would see this is that the reasons may have very little to do with the real causes of your beliefs.
So the real cause of your belief in a political position, whether conservative or radical left, the real causes are rooted in your personal history. They’re rooted in who are the people that you trusted and what they seemed to believe in, and it has very little to do with the reasons that come to your mind, why your position is correct and the position of the other side is nonsensical. And we take the reasons that people give for their actions and beliefs, and our own reasons for our actions and beliefs, much too seriously.
Tippett:Right, and we duel with them, and we’re not actually talking about —
Kahneman:Yeah, and it’s a game, because even if you did destroy the arguments that people raise for their beliefs, it wouldn’t change their beliefs. They would just find other arguments.
Tippett:You still have the same human drama.
Kahneman:So that’s a perspective which is saddening, in some ways, but it’s about what happens in the world of ideas and in the world of politics — that we have a lot of illusions about the role of reasons — and I mean “reasons,” plural — about the role of reasons in our beliefs and decisions. It’s smaller than we think.
Tippett:Yes, and something that comes up a lot in your work and as people write about you is, one of the things you are arguing, on the basis of what I would say is your deep, profoundly reality-based approach to us, is that if we accepted that there’s a lot that’s incomprehensible and unreasonable, that we would be surprised less of the time. One feature of the present, I feel, politically and on other levels, is we have a complicated dynamic that has been before us for a while and been deepening, and yet, I feel that people are constantly surprised by it, over and over again.
Kahneman:Well, my perspective on this is that we’re really not surprised nearly often enough, because one of the things that really happens: as soon as an event occurs, we have a story. That’s automatic. That System 1 generates stories. It looks for causes, it looks for stories, and it generates its tentative stories that, if endorsed by System 2, become beliefs and opinions.
But the speed at which we find explanations for things that happened makes it difficult for us to learn the deep truth. And the deep truth is that the world is much more uncertain than we feel it is. We see a version of the world that is simplified and just a lot simpler and a lot more certain than the world really is. So that’s the way I would talk about it.
And notice, in our conversation, you are using the word “rational” much more often than I, because when people use the word “rational,” I think, what they mean by this is that there is a good reason for what you believe and what you do. If there is a good reason for it, you believe in what you do, then, you are rational. But if we accept that in general, our more important beliefs are not rooted in arguments, that there is no good reason for why we have this religion or that religion, or this politics or that politics; it’s just something that happened to us — that changes the nature. We shouldn’t be looking for rationality so much, because by using the word, we seem to expect it to happen. And I think that’s just not the way the mind works.
Tippett:Yeah, I appreciate you pointing that out, too, because actually, I also feel like the word “rational” carries a sense of judgment; that I would say what is rational, and somebody else would say what is rational. And I don’t actually know that it’s a word I use — I mean, I think I would use the word “logical.” And one of the things I’ve been saying a lot to people in conversations in this last political year is, we’re not logical creatures. And being mad at the other side for not being logical is just not a good use of your rational brain. I don’t know. There, I used the word again.
Kahneman:It is not, because you do not appear rational to them. And the fact that arguments that feel irrefutable come to our mind so easily doesn’t mean that those arguments are the real cause of our beliefs and doesn’t mean much of anything about the validity of the argument. The way that the mind works, very frequently, is that we start from a decision, or we start from a belief, and then the stories that explain it come to our mind. And the sequence that we have, when we think about thinking — that arguments come first and conclusions come later — that sequence is often reversed: conclusions come first, and rationalizations come later.
Tippett:But isn’t it interesting that the discipline — at least, the idealized discipline of politics or political science — the way we think you have a debate, and then somehow the best idea will appear right to everyone — [laughs] and that’s not, in fact, the way — as you’re saying, that’s not even the way our brains work.
Kahneman:Absolutely. I mean, certainly what is happening in the United States, in the last six months, is — it’s really a testimony to that sort of process. You have people on the left, possibly the majority of the country, certainly the people that Donald Trump calls “elites,” and they cannot believe that behaviors that appear to them to be crazy have absolutely no effect among a group of his supporters. You read The New York Times, and you feel that everybody who writes there cannot make their peace with the fact that the support is stable, in spite of things that strike them as —
Tippett:Right, that’s what I mean — they’re always surprised by the same thing, over and over and over again, shocked.
Kahneman:Absolutely. “Why don’t they change their mind?” And the reason they don’t change their mind is that facts don’t matter, or they matter much less than people think. And people on both sides believe that there are facts that support them; but those beliefs should not be taken too seriously.
Tippett:I doubt that you read the newspaper every morning and are continually surprised by this. So how do you think people who want to step back, who want to activate the deliberative part of our capacity — do you have any very practical thoughts towards that?
Kahneman:Well, what is disappearing, or seems to be disappearing, is a culture of debates between diverse opinions. Whether there is anything that can be done about it, I would say there is something that can be done, but it’s not —
Tippett:Good. [laughs]
Kahneman:Nothing deep can be done, I think. What can be done is superficial; can be very, very useful. So teaching statistics to the young would be useful. Teaching economics to the young would be useful. Teaching self-critical thinking— or, better yet, how to criticize other people, because this is more pleasant and more interesting — those things can be done. You could educate intelligence analysts. You could educate people who feed information to decision makers, to some extent, to improve their product. But those are very marginal improvements. When it comes to the big issues, I’m not very optimistic.
Tippett:[laughs] OK.
[music: “Chimera” by Podington Bear]
Tippett:After a short break, more with psychologist Daniel Kahneman.
[music: “Chimera” by Podington Bear]
I’m Krista Tippett, and this is On Being — today, my conversation with psychologist and Nobel laureate Daniel Kahneman. He helps explain an unnerving reality that is increasingly out on the surface of our life together: as surely as we breathe, we all contradict ourselves and confound others.  Many have loved his book Thinking, Fast and Slow, and he’s just releasing a new book he’s co-authored, titled Noise: A Flaw in Human Judgement.
Well, let’s talk about some of the ways you help us understand ourselves. You’ve talked about the “experiencing self” and the “remembering self.” So these are some of the dynamics that go into the contradictory way we process reality. So describe what you’re talking about there.
Kahneman:Well, to describe this, I’ll describe an experiment, which — we did it, and it was quite influential in my own thinking. So this is what you do: you invite people to participate in an experiment, and the subject of the experiment is pain, so they know that. And you ask them to stick their hand in cold water for a while, until they’re told to take it out. In one condition, you hold your hand in cold water for 60 seconds. In another condition, you hold your hand in cold water for 60 seconds and then, without any break, for 30 additional seconds, but during the last 30 seconds of your experience, the temperature of the water is raised by 1 degree Celsius, about 2 degrees Fahrenheit. And then you ask them, which of the two experiences you had, with your right hand or with your left hand, would you like to repeat? And they pick the longer one. Not “they” but a significant majority of people pick the longer one.
Now, that’s absurd, because the longer one contains the 60 seconds of pain that the short experience contains, plus 30 additional seconds of diminishing pain. So it’s more pain, the 90 seconds, and yet, people don’t actually store their experience in that way. They form an impression of the experience they had, and in that impression, there are two moments that play a significant role, and that’s the peak of your pain, and the pain at the end of the episode.
Tippett:Right, how it ended.
Kahneman:And how it ends, it ends better for the 90-seconds hand than for the 60-seconds hand. And that’s the thing that people want to repeat. And associated with it is something that is really crazy, but it’s a fact — we call it “duration neglect.” That is, people in those kinds of situations are radically insensitive to how long the experience lasts. We have done that with actual medical experiences.
Tippett:So this translates into real life crises.
Kahneman:Oh, yeah, it’s been tested with people who are having their kidney stones broken up or with patients having a colonoscopy, so it’s for real. People who have had 20 minutes of pain can say that they had a better experience than people who had five minutes of pain, if the 20 minutes ended well.
Tippett:Well, to me, the classic example of that is childbirth. [laughs]
Kahneman:That’s right. Well, childbirth is a bit complicated. In childbirth, there is duration neglect in memory, when you just remember that it was long, but your evaluation of the experience is very much colored by the fact that, for most women, it ends well.
Tippett:Right, how it ended— you have this new life.
Kahneman:How it ended, yeah. That’s why women have more than one child.
Tippett:[laughs] Exactly. And you correlate this dialectic in us, between the experiencing self and the remembering self, as part of this ongoing way the past makes more sense in hindsight than it perhaps actually did, and also that we don’t really recall it; that the sense we give it isn’t necessarily logical. And that gives us this illusion, as we move through the world, that the world in general makes sense, even when it didn’t make sense and hasn’t ever made sense.
Kahneman:Well, you’re going a bit far here, further than I would. In one sense, well-being is something that you experience every second of your life: You are more or less happy. You are in a better or worse mood, and you can recall that continuously. And that’s the well-being of the experiencing self.
But then there is another way of measuring well-being, which is to stop people and to ask them to think about their life and to say whether their life is good or bad. It’s completely different. That’s the well-being of the remembering self. It’s an act of memory and construction, and the two are quite different.
Tippett:Does one of these, the experiencing self or the remembering self, always trump the other? Or is that a different dynamic in any given life?
Kahneman:No, that’s the interesting part, I think. When I started out in this line of research, I started out as a strong believer that the reality of life is what the experiencing self is. It’s what happens as you live. And I thought that’s vastly more important than what people think about their life, which, after all, is a construction. And I went about defending the experienced well-being as the more important one.
And eventually, I had to change my mind. And I had to change my mind and to conclude that there is no way you can ignore remembering self, or life evaluation, because what people want is not the well-being of their experiencing self. What people want is more closely associated with the remembering self. It’s, they want to have good memories. They want to have good opinions of themselves. They want to have a good story about their life.
Tippett:One thing you’ve also said is that if you had a magic wand, overconfidence is the thing you would banish. Would you explain that?
Kahneman:Well, and I did say that, but I’m not sure I was right. But what I meant to say was that when you look globally at people’s actions, overconfidence is endemic. I mean, we have too much confidence in our beliefs. And overconfidence really is associated with a failure of imagination. When you cannot imagine an alternative to your belief, you are convinced that your belief is true. That’s overconfidence. And overconfidence — whenever there is a war, there were overconfident generals. You can look at failures, and overconfidence had something to do with them.
On the other hand, overconfidence, and overconfident optimism, is the engine of capitalism. Entrepreneurs are overconfident. They think they’re going to be successful. People who open restaurants in New York think they’ll succeed, otherwise they wouldn’t do it. But at least two-thirds of them have to give up within a few years — more than two-thirds, probably.
Tippett:Well, and too, what’s also baked into that is, we reward overconfidence. We celebrate it.
Kahneman:Absolutely, we want people to be overconfident. We want our leaders to be overconfident.
Tippett:I want to just ask you, just run through a few phrases that you use, which also just feel very informative to me — this idea of the availability heuristic, “What you see is all there is” — that we are really, really not aware of the information that we don’t have.
Kahneman:Yeah. I mean, that’s a very difficult principle to grasp, this idea that, actually, what I don’t know matters enormously, and what I can’t see matters enormously. And there are so many manifestations of this. For example, something that I’m very interested in these days is how much people — even experts, professional experts — disagree in their view of specific cases. In fact, the differences are huge. They are much larger than people anticipate. And this is because it’s very difficult for us to imagine how anyone could see the world in a way that’s different from the way we see it. The interpretation of the world imposes itself on us, and the idea that there are other ways of seeing it, that there are alternatives, that there are things that you do not see, and they’re important — that is impossible to bring to mind, effectively.
Tippett:So we create a story. We have a sense of what is real that is just always based on impartial understanding, but we then naturally believe in it, and it feels more whole than it is?
Kahneman:Yeah, I think you got it. At least, you got “it” — you got my thinking about it. I think that, mostly, we go through life with the impression that we see the world as it is. And mostly, we don’t have much doubt.
Now, I’m going to tell you a story that you can either keep or drop, depending on who your audience is. It will take me a minute, but it makes a point. My wife and I, we had dinner with a couple of friends, some years ago, and we came back, and we talked. We went to bed, and we talked about our experience. And my wife said, of the man with whom we’d had dinner, “He is sexy.” And then, immediately after that, she said something that struck me as completely bizarre. I mean, in fact, it is bizarre. She said, “He doesn’t undress the maid himself.” And I turned to her, and I said, “What on earth are you saying? What do you mean, ‘He doesn’t undress the maid himself’?” Well, what she actually had said was, “He doesn’t underestimate himself,” and I heard as “He doesn’t undress the maid himself.”
Tippett:I see. [laughs] I see.
Kahneman:Now, this illustrates how the mind works, and it illustrates how ready you are to produce some interpretations, rather than others. But one of the striking aspects of this story was that it didn’t occur to me, at the time, that, because it was such an unlikely thing for her to have said, she hadn’t said it. That did not occur to me, because I heard it. I “knew” what she had said. The only question was why she had said such a crazy thing. And our mind works like that a lot of the time.
[music: “An Inappropriate Valentine’s Day Gift” by Lullatone]
Tippett:I’m Krista Tippett, and this is On Being, today with psychologist and Nobel Laureate Daniel Kahneman, a founder of behavioral economics.
[music: “An Inappropriate Valentine’s Day Gift” by Lullatone]
Tippett:You mentioned the word “consciousness” very early on in our conversation, about how connected all these systems, and this thinking about fast and slow thinking, and intuition — it’s all somehow connected with consciousness, which we are circling around in a new way, in many of our disciplines, but also, I think, as aware as ever before that we don’t really know what it is. But I’m curious about how you think about consciousness; how you’ve come to think about consciousness.
Kahneman:My take on consciousness is different from that of most of my colleagues. Many people think that the question of what consciousness is is the cardinal question. I mean, philosophers think that. Computer scientists think that, and they ask the question of whether artificial intelligence is going to be conscious or not. And for the life of me, I can’t get excited about this question, because when people are raising the issue of whether a robot will be conscious or not, I ask them, how on earth will you know? How will you know whether the robot is actually conscious or is just pretending to be conscious? And if there is no way of knowing, I don’t find it very exciting. But I must be wrong, because so many brilliant people are fascinated by this question. But for some reason, I’ve never understood their fascination for it.
Tippett:You’re very cautious about the application of what you understand to how we might change the world. But I’m very much drawn to some ways you’ve talked about the virtue of — not changing your mind, but thinking again, as perhaps something that’s more achievable for us. Do you know what I mean, that distinction? Can you just talk about what that distinction is for you?
Kahneman:When you’re thinking, the context — I tend to be very concrete in my thinking, so for me, for example, a good question is, how would you improve the thinking of analysts at the CIA, say. What would it mean to improve their thinking, and how would you do it? And I’m not inclined to believe that you can train people to de-bias themselves. I think that’s difficult. But I think it’s probably much easier, or, at least, it could be feasible, to train people to detect biases in other people’s thinking, because when you are thinking for yourself, you are too busy making the mistake to recognize that you are making a mistake. An observer with less stake in the thinking and less involved in the process of generating the mistake may be more likely to discover it. So developing critical thinking — not in the sense of criticizing yourself, but in the sense of criticizing other people; real criticism — may be a good way to go. At least, that’s the way I would be inclined to go at the moment.
Tippett:But I think that what you mean when you say that is so utterly different from the way we criticize each other in political life or in cultural life now. I think there’s so much nuance to what you’re saying that might not immediately occur with those words.
Kahneman:Yeah, I mean, there are various ways of criticizing somebody’s position or somebody’s beliefs. I was talking about a specific type of critique, and it’s a critique that is based on understanding of the biases to which thinking is prone and the conditions under which those biases are most likely to occur. And there is rich knowledge in this, but in the 40 years since Amos Tversky and I wrote about this, in all of those years, not a lot has been achieved in de-biasing. There isn’t much. There are some people who have claimed that they can do it, but have they really changed the way intuition works, or have they really enabled people to find the correct solutions to problems in completely new contexts, which is the proper test? I’m a skeptic.
Tippett:I agree with you, and I do feel like the one thing that may have changed in recent years is just that we see that bias is present; that that reality is more undeniable on the surface of our life together, not that we necessarily know what to do with that reality.
Kahneman:You bring to mind something that I’m very concerned with, these days. In fact, I’m sort of, in a desultory way, I’m trying to write a book about it with a colleague. And this is the idea that we very much overuse the term “bias.” When I started my career, you mentioned the word “error,” and the association would be “random” or “motivated” or “Freudian” error. Fifty, sixty years ago, that’s how people thought about error. Now you mention error, people are very likely to say, “What’s the bias that caused it?”
But in fact, it need not be a bias. A lot of error is random, and there is a radical underestimation of the amount of random error in people’s thinking, and I would like to restore the balance because I think our work, Tversky’s and mine, was in a sense too influential. It led people to exaggerate the importance of bias in human affairs and in human thinking, but there are many other ways in which people go wrong, than biases.
Tippett:And I suppose you’re suggesting, also, that if we took that in, that just that distinction would make us just that much — that “random” is not always motivated and malicious. Do you feel like the word “bias” is so much more charged, and that it charges things on top of …
Kahneman:Certainly, that’s the case, but also, the fascinating thing about random error, what I call noise, is that it’s invisible; that we’re not aware of it. We studied an insurance company, and we found that underwriters really didn’t agree among themselves, to I would say almost a catastrophic degree, in what premium they should assess — I mean, to the point they would disagree so much that you wondered why the company bothered to use underwriters. They should be almost entirely interchangeable. And they differ, and their difference is noise. And this is a problem which reduces the accuracy and, actually, reduces the bottom line of the organization. That problem is invisible to the organization. Nobody knew it existed, until we pointed it out. That’s my passion, these days.
Tippett:This capacity we have to think again, to do better thinking, but very incrementally — you have, in a couple of places in our conversation, mentioned a place where you had changed your thinking. And I’m curious about that, and perhaps you’ve been speaking to that now, but how your thinking is evolving, even as we speak; and within that this interest you had, early in life, about, I think, your own way of coming in at the question of the human condition. Is there evolution in the way you think about that, reflect on that?
Kahneman:Well, you know, I have been shifting positions all my life. I like changing my mind, and I look for ways of changing my mind. And this is what I’m doing now, in questioning the importance of biases. But as I said, I don’t believe — I’m certainly less smart than I was when I was younger. I’m in my 80s, so — but it’s not only that. I haven’t become more sensitive to biases. I really haven’t improved my thinking in any way, I think. And if I have, it’s accumulating experience. It’s not by learning better ways to think.
Tippett:[laughs] Well, where is your thinking evolving now? Is there anything you’re in the midst of changing your mind about as we speak?
Kahneman:Yeah, I’m really in the midst of that noise project. I am involved in a project about improving reasoning, which I interpret as improving the ability to criticize other people’s thinking. And so those are the two main projects I’m involved with at the moment. I do other things, but those are the main two.
Tippett:Well, I think especially that latter, creating some tools and even some reflection around reasoning, in that way, is certainly much needed. So I’m very glad that you are in the world, thinking and offering these ideas up to us, and it’s been a pleasure speaking with you. Thank you so much for making the time.
Kahneman:Thank you very much. You’re a penetrating interviewer. It was a pleasure.
Tippett:Thank you.
Kahneman:Thank you.
Tippett:Bye-bye.

 
Interview 10. Conversations with Tyler (2018):

TYLER COWEN: Thank you for coming, Danny.
You’ve worked on so many topics. Let me start with the issue of happiness. If you have an experience, it seems that how happy you are at the end of the experience depends on the end of the experience and how good was the peak, or how bad was the bottom.
Given that result, should we aim to deliberately structure our experiences so they give us more happiness?
DANIEL KAHNEMAN: Well, if you want good memories, good endings are really important.
[laughter]
KAHNEMAN: The question is how important good memories are relative to the experience itself. But no question, ends are very important. They’re particularly important in the context of goal striving. That is, whether you achieve a goal or don’t achieve a goal colors the whole experience of trying to get it, to get to it. So ends are very important for memories.
COWEN: Do people structure their vacations to meet the standard, or there’s a kind of market failure? If they listen to you, they would have better vacations.
KAHNEMAN: I’m not at all sure. My guess is that people are conscious that they don’t want the peak to be too far from the end. That’s my guess.
COWEN: And why does duration of pain seem to matter so little for how we evaluate painful experiences?
KAHNEMAN: If you were asking what are the evolutionary value, then the duration of pain is really not very important. What’s important is the intensity because the intensity is a measure of the severity of threat. The duration is really something else. It’s very striking, but it’s completely insignificant. In many situations, it’s completely insignificant, but a striking result.
COWEN: You also have a paper on happiness with Alan Krueger, using what you call the Day Reconstruction Method — how much people enjoy different experiences. One result from that paper is how much people enjoy spending time with their friends. If that’s so much more enjoyable at the margin, why don’t people do more of it?
KAHNEMAN: Altogether, I don’t think that people maximize happiness in that sense. And that’s one of the reasons that I actually left the field of happiness, in that I was very interested in maximizing experience, but this doesn’t seem to be what people want to do. They actually want to maximize their satisfaction with themselves and with their lives. And that leads in completely different directions than the maximization of happiness.
COWEN: Do you think that telling people you’ll be happier a particular way changes their behavior much? Or they still stick to maximizing a sense of satisfaction with their lives?
KAHNEMAN: No idea. I haven’t tried. There is a lot of work these days in trying to make people happier and trying to coach people. In the UK, in particular, there is — I wouldn’t call it an industry, but it’s sponsored by government. My friend, Lord Laird, has started a movement that promotes happiness. There’s a great deal of that happening.
I don’t know how successful it is because the criterion for evaluation — it’s very difficult to conduct evaluations on those things because people who know they’re being subjected to interventions cannot really answer those questions honestly, even if they try. So the way to test whether things are successful would to be to ask a person’s friends, has he become or she become happier? And that hasn’t been done.
COWEN: And that people want to maximize their overall sense of how their life has gone — do you think that is ultimately Darwinian roots? Why is that the equilibrium? Happiness feels good, right?
KAHNEMAN: Yeah, happiness feels good in the moment. But it’s in the moment. What you’re left with are your memories. And that’s a very striking thing — that memories stay with you, and the reality of life is gone in an instant. So memory has a disproportionate weight because it’s with us. It stays with us. It’s the only thing we get to keep.
COWEN: If you think of your own life, have you maximized happiness or the overall sense of how your life has gone?
KAHNEMAN: Neither.
[laughter]
COWEN: Neither. Citations?
KAHNEMAN: No.
On bias
COWEN: If you miss a flight due to a traffic jam outside your control, would you rather be two hours late or just one minute late?
KAHNEMAN: Oh, I’m like everybody else. I’d rather be two hours late.
COWEN: And you think even knowing about this doesn’t change that. You can’t talk yourself out of the bias?
KAHNEMAN: You can talk yourself out of some biases, I think. I wouldn’t generalize on that, but it would take . . . I could possibly talk myself out of that one by really repeating to myself how stupid it is. But it would take a lot of work. It’s not that you can decide once and for all, “I will not be subject to that bias.” Doesn’t work that way.
COWEN: Do you think we overinvest or underinvest in memories, overall?
KAHNEMAN: We certainly invest heavily, heavily in memories. Vacations for many people are investment in the formation and maintenance of memories. There is a lot of investment. Whether it’s too much or too little, it probably depends a lot on people’s amount of consumption of memory that people engage in.
I, for one, am certainly biased. But I do not consume my memories a lot. And I almost never go back to photographs, not deliberately. If I stumble on something, it will move me. But the idea of going back to relive a vacation — that’s not what I do, so I have little empathy for this.
COWEN: If we think about, say, sports, they’re a form of bias, right? Most people root for a home team, or they root for their country in the Olympics. Music, arguably, is a form of bias. There’s soundtrack music — it affects how you view the movie, even though it’s not changing any facts. To what extent should we think of bias as the main thing that gives our lives an overall structure, just as a musical soundtrack is what gives structure to a movie?
KAHNEMAN: That’s a tendentious way of labeling things, to call them biases. I wouldn’t call the effect of music a biasing effect. It completes the experience. And what were your other examples?
COWEN: Well, sports. You’re consuming bias, right? You don’t actually think your team is better.
KAHNEMAN: No, but you identify. There are emotions over which you have very little control. It’s a fact that you feel pride when your team wins. In fact, you feel pride if a stranger who lives on your street gets a prize. That tendency to identify with what’s around us, and with things that we are connected to, is very powerful. We derive a lot of emotion from it. I wouldn’t call that a bias because you can call any emotion a bias.
COWEN: There’s a well-known article by John List where he argues, if you study how experts trade assets, that a lot of what are called biases go away and become quite small. What’s your reaction to his research?
KAHNEMAN: It’s beautiful research. I’m convinced it’s right. And indeed, you don’t have to go as far as he does to find cases in which people act fairly rationally. People act fairly rationally in routine transactions. So if there is a thing that’s loss aversion, that it plays a large role, and that’s less research in novices. They get attached to things, and then they don’t want to sell them.
And they get over it, over time. In routine transactions, when I go and I spend some money to get shoes, I feel no loss aversion for the money. And certainly, the person who sells me the shoes feels no loss aversion for the shoes. It’s a routine transaction, and it’s a whole domain in which loss aversion doesn’t apply.
On noise
COWEN: Much of your last book is about bias, of course. And much of your next book will be about noise. If you think of actual mistakes in human decision-making, how do you now see the relative weight of bias versus noise?
KAHNEMAN: I would say this. First of all, let me explain what I mean by noise. I mean, just randomness. And it’s true within individuals, but it’s especially true among individuals who are supposed to be interchangeable in, say, organizations. Can I spend three minutes to explain that?
COWEN: Of course, sure.
KAHNEMAN: I’ll tell you where the experiment from which my current fascination with noise arose. I was working with an insurance company, and we did a very standard experiment. They constructed cases, very routine, standard cases. Expensive cases — we’re not talking of insuring cars. We’re talking of insuring financial firms for risk of fraud.
So you have people who are specialists in this. This is what they do. Cases were constructed completely realistically, the kind of thing that people encounter every day. You have 50 people reading a case and putting a dollar value on it.
I could ask you, and I asked the executives in the firm, and it’s a number that just about everybody agrees. Suppose you take two people at random, two underwriters at random. You average the premium they set, you take the difference between them, and you divide the difference by the average.
By what percentage do people differ? Well, would you expect people to differ? And there is a common answer that you find, when I just talk to people and ask them, or the executives had the same answer. It’s somewhere around 10 percent. That’s what people expect to see in a well-run firm.
Now, what we found was 50 percent, 5–0, which, by the way, means that those underwriters were absolutely wasting their time, in the sense of assessing risk. So that’s noise, and you find variability across individuals, which is not supposed to exist.
And you find variability within individuals, depending morning, afternoon, hot, cold. A lot of things influence the way that people make judgments: whether they are full, or whether they’ve had lunch or haven’t had lunch affects the judges, and things like that.
Now, it’s hard to say what there is more of, noise or bias. But one thing is very certain — that bias has been overestimated at the expense of noise. Virtually all the literature and a lot of public conversation is about biases. But in fact, noise is, I think, extremely important, very prevalent.
There is an interesting fact — that noise and bias are independent sources of error, so that reducing either of them improves overall accuracy. There is room for . . . and the procedures by which you would reduce bias and reduce noise are not the same. So that’s what I’m fascinated by these days.
COWEN: Do you think of low intelligence as yet a third independent source of error? Or is that somehow subsumed in bias and noise?
KAHNEMAN: You mean plain stupidity?
[laughter]
COWEN: In some cases.
KAHNEMAN: Yeah. It wouldn’t really be necessarily the same as either bias or noise. Getting inadequate information, or not getting adequate information when it’s available, is a stupid thing to do, and a very common thing. It’s not exactly a bias, and it’s not necessarily . . . It would contribute more to noise than to bias, by the way, by and large. When people collect too little information or are swayed by the first thing that comes to mind, you get noise rather than bias.
COWEN: Do you see the wisdom of crowds as a way of addressing noise in business firms? So you take all the auditors, and you somehow construct a weighted average?
KAHNEMAN: The wisdom of the crowds will work, and pooling opinions will work when errors are independent, that is, when everybody is inclined to make the same mistake, which is then a bias.
COWEN: Right.
KAHNEMAN: Then having multiple individuals engaged in it, they share their biases, you’ll get the bias. It’s going to be worsened, and everybody will have much higher confidence in their biased views because other people share them. So wisdom of the crowd works under quite specified conditions.
With respect to the underwriters, I would expect, certainly, that if you took 12 underwriters assessing the same risk, you would eliminate the noise. You would be left with bias, but you would eliminate one source of error, and the question is just price. Google, for example, when it hires people, they have a minimum of four individuals making independent assessments of each candidate. And that reduces the standard deviation of error at least by a factor of two.
COWEN: So is the business world, in general, adjusting for noise right now? Or only some highly successful firms?
KAHNEMAN: I don’t know enough about that. All I do know is that, when we pointed out the results, the bewildering results of the experiment on underwriters, and there was another unit — people who assess the size of claims. Again, actually, it’s more than 50 percent. Like 58 percent. The thing that was the most striking was that nobody in the organization had any idea that this was going on. It took people completely by surprise.
My guess now, that wherever people exercise judgment, there is noise. And, as a first rule, there is more noise than people expect, and there’s more noise than they can imagine because it’s very difficult to imagine that people have a very different opinion from yours when your opinion is right, which it is.
[laughter]
KAHNEMAN: So that’s the way it works.
COWEN: If you’re called in by a CEO to give advice — and I think sometimes you are — how can I reduce the noise in my decisions, the decisions of the CEO, when there’s not a simple way to average? The firm doesn’t have a dozen CEOs. What’s your advice?
KAHNEMAN: My advice is divide and conquer. That is, there is one thing that we know that improves the quality of judgment, I think. And this is to delay intuition. I think there is in the audience a friend of mine, Gary Klein, who is violently opposed to what I’m saying, as are many others. But I’m here.
[laughter]
KAHNEMAN: So I think delaying intuition is a very good idea. Delaying intuition until the facts are in, at hand, and looking at dimensions of the problem separately and independently is a better use of information.

The problem with intuition is that it forms very quickly, so that you need to have special procedures in place to control it except in those rare cases — and Gary Klein and others have demonstrated that — where you have intuitive expertise. That’s true for athletes — they respond intuitively. It’s true for chess masters. It’s true for firefighters, captains, as Gary Klein has shown. So that’s intuitive expertise.
I don’t think CEOs encounter many problems where they have intuitive expertise. They haven’t had the opportunity to acquire it, so they better slow down.
COWEN: And just take more time on each decision.
KAHNEMAN: Break the decision up. It’s not so much a matter of time because you don’t want people to get paralyzed by analysis. But it’s a matter of planning how you’re going to make the decision, and making it in stages, and not acting without an intuitive certainty that you are doing the right thing. But just delay it until all the information is available.
COWEN: And does noise play any useful roles, either in businesses or in broader society? Or is it just a cost we would like to minimize?
KAHNEMAN: There is one condition under which noise is very useful. If there is a selection process, evolution works on noise. You have random variation and then selection. But when there is no selection, noise is just a cost.
COWEN: But say it were always transparent who would be the winners and who would be the losers from a given decision. Wouldn’t we be too emotional, too polarized, engaging in too much rent-seeking? And having an ambiguity as to cause and effect is, in part, what allows us to get along with each other?
KAHNEMAN: You are sort of making a lot of assumptions I’m not used to in this question. You seem to assume that there is something very competitive that could be alleviated.
COWEN: But there’s the old saying, say, from the Soviet Union, that meritocracy is very hard to live under. That if you really know how many people are better than you are, which, say, a chess player might, there’s something psychologically oppressive to being downgraded. Whereas noise, you can be overconfident more easily, and we all know overconfidence —
KAHNEMAN: You don’t need noise for that. Bias will do it for you. And there is a lot of bias in that direction. People clearly overestimate what they can do and how good they are. And that’s a blessing, undoubtedly.
COWEN: Are there groups of people you feel are less subject to biases? There’s some papers, for instance, showing that autistics — they have weaker framing effects, smaller endowment effects, maybe because top-down processing works in a different way. Do you have an opinion on that literature?
KAHNEMAN: No, I don’t know it well enough.
COWEN: If you think of the literature on what are called cognitive disabilities — ADHD — do you think of that as bias or somehow in a different logical category? Or . . . ?
KAHNEMAN: I don’t think it’s a bias, no. I think it’s an attention deficit. It means that people have difficulty controlling their attention, focusing on what they want to focus on, and staying focused. That’s neither bias nor noise.
Bias and noise do not cover the universe. There are other categories.
COWEN: If you think about the issue of, when people think about the world, they find some kind of transactions repugnant. Sometimes they just don’t like to sell what they have. Other times, they seem to object to markets, say, in kidneys or kidney transplants. Do you view that as bias? Or where does that come from?
KAHNEMAN: In the sense that this is a norm, and there are things that we’re trained or socialized to find disgusting, to find repugnant. So there are repugnant transactions. And you have to treat them as you treat every other moral feeling.
We have lots of moral feelings, things that we find unacceptable without any ability to really explain why they are unacceptable. There is such a thing as moral emotion. There is such a thing as indignation, as moral disgust. And that’s what we’re talking about here.
COWEN: So you’re pessimistic about the ability of psychologists to develop structural explanations of where feelings of repugnance come from.
KAHNEMAN: Well, in some cases, we know, and you can do that associatively. It really depends on the social disrupture that is imposed by a given culture. To give you a sense of the way that works, there is psychologist Paul Rozin, who has done some brilliant experiments on that.
In one of the experiments, he has people, and they have a glass of orange juice, and they have a sticker. They’re asked to write on that sticker “cyanide” and to stick it on the juice and then to drink the juice. And they don’t want to.
[laughter]
KAHNEMAN: This is something — it’s an emotion over which people have no control, and our socialization has created those emotions in us. We’re conditioned to have them under some conditions. Other cultures are disgusted by other things.
COWEN: Philip Tetlock has argued that, if we set up long-run tournaments with forecasting, and we measure results, and we test teams against each other, that we can, in the longer run, reduce, I think, both the noise and bias. Do you agree? And do you think there are factors he’s overlooking in how his tournaments are set up?
KAHNEMAN: Phil Tetlock is another friend, but he’s also a hero. I think this is beautiful research. I think it’s proved beyond a shadow of a doubt that when you have people making forecasts for the medium term — up to six months, say, in many situations — you can help people thinking carefully without any training, who do better than CIA analysts.
That’s fundamentally what he has shown, and he really knows why, or he knows how they do it. And the tricks are very simple. If you made a list of intelligent ways to go at problems, that’s what people do. They view the problem as an instance of a category, and then they switch to looking at the problem from the inside. Essentially, they adopt different points of view.
It’s not the same thing as what I was saying earlier about breaking up a problem into dimensions and averaging. There’s no averaging, but there is looking at a problem from multiple dimensions and collecting a lot of information. And that’s basically what creates superforecasters.
COWEN: So if you’re picking the Daniel Kahneman superforecasting team, what qualities are you looking for in individuals?
KAHNEMAN: Phil Tetlock really has a comprehensive list, which I’m not going to remember.
COWEN: But at the margin, how would you modify, given —
KAHNEMAN: They will be intelligent, they will be numerate, they’ll be open-minded, they’ll be curious, interested in learning, eager to train their mind.
COWEN: But is there a bias left in how Tetlockians pick their teams?
KAHNEMAN: He picks the teams by results, so what he has, he has people competing in making probabilistic forecasts of strategic or economic events in the medium and short term. And some people are more accurate than others. After a year of that, you select the top 2 percent and you call them superforecasters.
That gives them a very good feeling, to be labeled superforecasters. And they do not regress to the mean; that is, the second year they’re just about as good as the first year. That’s the basic finding.
COWEN: If you’re picking doctors, where maybe results are hard to measure in some cases, what do you look for when selecting doctors, in broad terms?
KAHNEMAN: I will do the conventional thing. I will ask about their reputation because that’s the best measure we have. If it’s a surgeon that I’m looking for, then there are real indices, the main one being the number of times he’s performed the operation in question. That you know is what you’ve got to examine because people really do get better over time, so measuring how much practice they’ve had. And the practice is fairly specific on different operations. I think I would know how to pick a surgeon.
COWEN: There’s a good deal of evidence that people in businesses are overconfident, but do you think they’re more overconfident than they should be?
KAHNEMAN: Overconfidence has many virtues. In the first place, it’s nice, it’s pleasant to be overconfident, especially if you’re an optimist. Optimism is valuable, much more than overconfidence. Overconfidence is sort of a side effect.
But to exaggerate the odds of success is a very useful thing for people. It will make them more appealing to others, they will get more resources, and they will take risks. It’s not necessarily good for them. The expected utility of taking risks in the economy is probably moderately negative. But for society as a whole to have a lot of optimists taking risks — that’s what makes for economic progress, so I call that the engine of capitalism, really, that sort of optimism.
COWEN: There’s a collaboration between a human being and a machine, and occasionally the human being overrides the machine. Do you feel the human beings in those situations are, on average, either too overconfident or too optimistic?
KAHNEMAN: Well, there are certain criteria that you would want to apply before you put a machine to work. You want to validate that. But once you have a machine making decisions, the conditions under which it’s a good idea for humans to override them are really well known and well understood. And it’s not that when you get a feeling that the machine is wrong, that’s not enough.
I’ll give you an example where it would be okay to override a machine. Suppose you have a computer that approves loans, and then you’re the banker, and you see that the person who was approved for a loan has just been arrested for fraud. Then you will override the machine. That’s about the conditions under which it’s worth it. Otherwise, there’ve been many experiments, and when people override formulas, by and large, they do worse than if they hadn’t.
COWEN: Do you side with the analysts, such as Martin Ford, who see really a very large number of jobs being potentially automatable with artificial intelligence, machine learning? Or will we always need the human beings to work with the machines?
KAHNEMAN: That we will need human beings is, I think, an illusion. Take chess for example. Kasparov was beaten 20 years ago, and he went on for a while — and it was true for a while — saying the teams of chess players with grand masters — of programs with grand masters would be stronger than either. And it was true for a while. It is true no longer. The programs do not need the grand masters.
You know how it happened, and it’s likely to happen in many other fields. It’s happening in dermatology. The diagnosis is now better done by programs than by people, and they are not going to need the person very often. That is, to have a person intervene, with the right to intervene, they will sometimes correct mistakes. But they will more often, I think, introduce mistakes. So when you have a well-running program, leave it alone.
COWEN: So we as professors won’t need to grade exams anymore, and I don’t just mean multiple choice. You run machine learning on papers, you find what correlates with a good paper, you put the paper through the program.
KAHNEMAN: Look, the point is, there is so much noise in essay grading that it’s quite easy to imagine a program that would look at various indices and that would do better than hurried and tired professors.
COWEN: If you consider people working in psychology or maybe economics or just social sciences, do you think people persist with their professional and research projects too long or not long enough? Where’s the bias?
KAHNEMAN: My guess is too long, but it’s a personal bias.
COWEN: Because of sunk costs.
KAHNEMAN: Because of sunk costs. I think sunk cost is really the enemy when you’re doing research, innovative research. You’re to recognize that something isn’t working and just move on. And there are different views on that, but my sense is that this is the direction of the bias, yeah, sunk costs.
COWEN: Michael Nielsen is a scientist, and he works at Y Combinator. He tweeted today, “If it weren’t for sunk costs and my respect for them, I wouldn’t ever get anything done.” What do you think?
[laughter]
KAHNEMAN: I mean, you know sunk costs.
COWEN: It keeps you at things, right?
KAHNEMAN: Yeah, it keeps you at things.
COWEN: You stay loyal to your friends. You become more trustworthy.
KAHNEMAN: When we talk about sunk costs, we talk about something else. It is not true that growing attachment to things that you’re familiar with and that you like and love and increasingly trust — that’s not sunk costs. That’s something else.
Sunk cost is a fairly specific thing. It is that you’re putting a different value on a move or an investment that you make because of investment that you have already made than you would if you were looking at that de novo.
Sunk costs, by and large, I think, are a negative. We know that when you get a new CEO in place in organizations, the new CEO has one big advantage. He’s got no sunk costs with respect to poor ideas that the exiting CEO had and couldn’t let go of.
COWEN: If you had a perfectly rational, pure Bayesian, would anyone else trust that person?
KAHNEMAN: Well . . . would he be nice?
[laughter]
COWEN: I don’t think so.
KAHNEMAN: That’s what would matter. If you could get me a nice Bayesian, that could be fine.
[laughter]
On psychologists
COWEN: Some questions about psychologists outside of what you’ve worked on, but maybe related — Freud. What do you think of Freud’s body of work? And has it influenced you at all?
If I think of Freud’s two principles of mental functioning, right? The notion of pleasure principle, reality principle — it’s a little bit like Thinking, Fast and Slow in some ways, with big differences.
KAHNEMAN: Well, all dichotomies are alike in some ways.
[laughter]
KAHNEMAN: And yeah, there are similarities.
Oddly enough, there is one aspect of Freudian work that I think did influence me. For some reason, when I was a graduate student . . . It’s too long a story, but I was exposed to chapter 7 in The Interpretation of Dreams, and I spent a summer studying chapter 7 in The Interpretation of Dreams. In chapter 7, there is, basically, a theory of attention. And 25 years later, I published a theory of attention. When it was done, I realized that it resembled chapter 7 quite a bit. So, yes.
COWEN: Personality psychology and five-factor personality theory — is that, for you, a useful way of thinking about human beings?
KAHNEMAN: Well, it’s a proven way . . . It’s sort of boring.
[laughter]
KAHNEMAN: And I mean that seriously. This five-factor thing — it’s about 20 years old, and it dominates personality psychology because it works.
COWEN: But it’s boring.
KAHNEMAN: It used to be more exciting, to have more complicated mechanisms, but you have something that seems to work.
COWEN: What did you draw from Herbert Simon?
KAHNEMAN: Directly, nothing. Indirectly, a lot. And retrospectively, a lot. What I mean by indirectly is that the air I breathe was influenced by Herbert Simon. He had the notion of heuristics. It was in the language, and it affected me. Of course, it affected the whole zeitgeist; it affected the whole culture.
And retrospectively, when I learned Simon . . . but that was after I was in field and after I made some contributions to the field. I discovered that I was following in his footsteps. But that’s not what I had been doing originally. I hadn’t viewed myself . . . and in fact, I wasn’t following in his footsteps. Retrospectively, you find, “Oh yeah, this is what I did,” in the historical perspective.
COWEN: And also from classical psychology, either Jung or Piaget — did you draw anything from them? Or is that just a foreign stream?
KAHNEMAN: Yeah, that’s completely foreign.
COWEN: Completely foreign. If you think about your early work on vision and on Israeli bus drivers, how did your later work on biases and thinking fast, thinking slow come out of your very earliest papers?
KAHNEMAN: It didn’t. It was a completely separate thing. I worked originally on a concept for quite a few years, on the notion of effort, mental effort. And when I started work on heuristics and biases with Amos Tversky, that wasn’t on our mind, and it had very little effect.
When I wrote Thinking, Fast and Slow — like 10 years ago — when I was doing that, then it turned out that I put together all my life’s work, and the early work did get into Thinking, Fast and Slow. But it had no effect on my work with Amos Tversky.
COWEN: But the idea of attention-switching costs — so Israeli bus drivers, it takes time for them to switch attention from one event to another. Is that not an underlying micro foundation of your, say, 1980s papers on bias?
KAHNEMAN: No.
COWEN: That people aren’t switching their attention to the new problem?
KAHNEMAN: No.
COWEN: No.
[laughter]
KAHNEMAN: It’s not. We didn’t think of it. That really happens a great deal, and quite often, it happens in a different way. It happens when somebody’s insulted because you didn’t cite him. He looks at your work, and he says, “That’s just the same as what I’ve said before.” And in some way, it may be true. There may be some resemblance. It may be true, and yet you were completely uninfluenced by that.
And it’s the same thing. I was uninfluenced by my earlier work, I think.
COWEN: Now your basic distinction between System 1 and System 2, thinking fast and thinking slow — to the extent that particular results do not replicate, do you view that as undercutting the System 1 versus System 2 distinction? Or is that immune to the degree of replicability?
KAHNEMAN: There were whole sets of results that I published in Thinking, Fast and Slow that I wish I hadn’t published because they’re not reliable.
Whether it undercuts . . . The idea of two systems is really anchored in a basic sort of fact of experience, that the process by which you get 2 plus 2 is fundamentally different from the way that you get 17 by 24. One of them happens automatically, associatively, quickly. You have no control. The other demands effort and is slow and so on. That’s immune to replication.
COWEN: But if there’s a bias in individuals and noise, why should we trust our experience about this apparent sense of having two methods? Is it three? Is it four?
KAHNEMAN: Well, in the first place, those are extremes. It doesn’t mean that there aren’t others. It doesn’t mean that there is not a continuum. But there is at least a continuum to be explored of those two extremes. Of that I’m quite confident.

COWEN: Do you think that working outside of your native language in any ways influenced your ideas on psychology? It makes you more aware of thinking fast versus thinking slow? Or not?
KAHNEMAN: It’s something I used to think about in the context . . . I’m from Israel, and it was thinking whether there was something in common to Israeli intellectuals operating in a second language. And I thought that, in a way, it can be an advantage to operate in a second language, that there are certain things . . . that you can think about the thing itself, not through the words.
COWEN: It’s like lower sunk costs in a way.
KAHNEMAN: I don’t know exactly how to explain it, but I thought that this was not a loss for me, to do psychology in a second language.
COWEN: Do you have thoughts on the potential cognitive advantages of bilingualism or trilingualism?
KAHNEMAN: It’s an empirical matter. It’s not a matter of thinking. And I don’t know enough. It appears to be advantageous, but I don’t know the literature.
COWEN: If we think of therapists, psychiatrists, internists who are trying somehow to fix, improve, or cure people — are they underinvesting in a knowledge of what might be called behavioral economics or your work on psychology? Should they be using more of it? Is that their bias?
KAHNEMAN: I have an opinion on that, and I think it is supported by evidence. But there is one line of therapy that clearly works, and it’s evidence based, and it’s supported time and again. And that is one style, and it’s cognitive behavioral therapy. That works, and we know it does.
Other things work — some of them do, some of them don’t, and it primarily seems to depend on the personality of the therapist and on the interaction between the personality of the therapist and the personality of the patient. Whereas cognitive behavioral therapy is a technique, and it’s a technique that works. That’s a fact, and the rest is a lot of bias.
COWEN: A society such as Argentina that relies so heavily on psychoanalysis — as a psychologist, do you see that as bias? Is it a placebo? Is there a placebo effect in psychoanalysis?
KAHNEMAN: You seem to attribute . . . You seem to think that I think of bias all the time.
[laughter]
COWEN: I can’t imagine why. That’s my bias.
KAHNEMAN: It’s like thinking of sex all the time. I really don’t think of bias that much. But if you want to apply it, then clearly there is a lot of psychoanalysis in Argentina, and there’s no indication that it makes them more sane.
[laughter]
COWEN: If you were to express, what is the question about gender and your own work that interests you the most? Maybe you’ve never done it, but what would that be?
KAHNEMAN: I have really never been interested in anything to do with gender, so I have never studied or looked at differences between gender in the kind of research we did. I’ve never been very interested in individual differences and not in gender either, so I don’t know.
COWEN: So it’s the means really that interest you the most.
KAHNEMAN: Yeah, it’s the means and it’s some extremes. But it’s not cutting and dicing into categories.
COWEN: But being an Israeli . . . and surely you’ve traveled to many, many countries, at the very least Sweden, among others. There are papers on cross-cultural differences in bargaining or in decision biases. How much stock do you put in those results?
KAHNEMAN: I think there’s no question that there are cultural differences. For one thing, for example, there are major cultural differences in the attitude to optimists, to optimism. In quite a few European countries, optimism is considered rather foolish. It’s for children.
COWEN: Idiots smile in Russia, right?
KAHNEMAN: And in the United States, optimism is clearly a desirable trait. And similarly, there are differences on whether risk taking is considered a good thing or a bad thing. So there are certainly cultural differences.
COWEN: Do you think of those in functionalist terms? Some people might argue, “Well, Israelis, they have a tendency to speak directly because they’ve had a lot of crisis situations, where you can’t beat around the bush. You need to say what you think.” Or we don’t know?
KAHNEMAN: I don’t like those kinds of explanations. They look facile to me.
COWEN: Right now in psychology, in your own work, what are the open questions you’re most interested in?
KAHNEMAN: Like everybody else, I think, like many others, there are two exciting developments now that one would want to know about. One would want to know how the brain works, want to know more about how the brain works than we do, and would want to know about artificial intelligence, and if, when, and how it will become more human-like in what it can do.
COWEN: And you’re optimistic on that front?
KAHNEMAN: I’m optimistic on virtually nothing.
[laughter]
KAHNEMAN: But that AI is developing faster than anybody could have anticipated — no question. And if it continues to develop at that rate, meaning a lot faster than we expect, then things are going to happen relatively quickly.
COWEN: What do you think are the main obstacles? Some people in Silicon Valley will argue AI is stuck at a kind of local optimum. Driverless cars — although they’re ahead of the pace we thought 10 years ago, they may be behind the pace we thought 2 years ago. There’s always a problem with emergency situations, the policeman waving you on. The last 1 percent maybe is very, very difficult.
KAHNEMAN: Yeah. But I can’t evaluate that. That’s a technical problem — how long it will take to get the cleanup, the last 1 percent. The questions that are of interest as a psychologist is, when can you simulate common sense? There is the really serious question that people raise about computers, whether they know what they’re talking about, whether they understand what they’re talking about.
Without sense or whims, and without the perceptual apparatus that we have and the ability to cause things by acting on the world, they can’t be exactly like us. But that sense of understanding . . . nobody actually today would, I think, claim that even the most sophisticated programs have it.
COWEN: Do you think we’ve learned anything general about common sense by having some artificial intelligence?
KAHNEMAN: What we have learned is that our basic ideas about what’s difficult and what’s easy, what’s going to be simple and what’s going . . . have undergone a series of revolutionary changes.
We used to think that perception would be easy, and thinking would be difficult. It turns out that thinking was relatively easy and perception was difficult. Now, there are ways of handling perceptual problems, and so thinking is difficult again. And it’s a very interesting developing thing.
COWEN: Moving the chess piece is often harder than figuring out the best move for the program.
Looking back on your collaboration with Amos Tversky, which has been written about widely, of course — there’s the famous Michael Lewis book. But what is there about that collaboration or about Amos that you feel one could read everything that’s out there but still has been underappreciated or undervalued?
KAHNEMAN: So much has been written that I couldn’t point out anything that people have completely ignored.
Actually, the thing that, when I think about him, it was the mental energy, just the joy of thinking and the mental energy. And that made him very charismatic. And he was also very funny, and being funny is a major asset in social life. And it turned out to be a major asset in our work because our work, our joint work, had a touch of irony to it. The fact that we were laughing continuously as we were doing the work was very important to the nature of what we did.
COWEN: And that stimulates discovery? It breaks down sunk cost bias? Or what does it do in formal terms?
KAHNEMAN: What it does is, it makes you look for funny things about . . . for us, what it did for us — I can’t generalize. For us, we were examining our own thinking, and finding stupid things in our own thinking, and finding that delightful and very funny. So we were very lucky in our choice of topic in many ways. Our choice of topic lent itself to a lot of things that are virtually impossible in other fields.
COWEN: Your current collaborators on the noise book — how would you describe that collaboration? And tell us who they are.
KAHNEMAN: One of them is Cass Sunstein, who is a very famous jurist and also known for writing three or four books a year. He writes very easily, and I write with difficulty, so it’s not an accident that we teamed up.
The other collaborator is a brilliant Frenchman that you haven’t heard of. He was, for 25 years, at McKinsey, and he became a director at McKinsey. Then he got bored with that, and he got a PhD. He teaches, and he is just extraordinary. So I’m very lucky.
COWEN: And what will the main theme of that book be?
KAHNEMAN: It will be that noise is an underestimated problem, and it will be that there is something deep about two ways of thinking that I was working on in Thinking, Fast and Slow, which I called statistical versus causal.
Noise is clearly a statistical way of looking at things, and bias is inherently causal — so the interplay of those forms of thinking. Then the idea that if you want to reduce noise, we have a pretty good idea of what you should do in order to induce greater uniformity and to overcome the vulnerability of people to all sorts of irrelevant influences.
COWEN: And when will that book be out?
KAHNEMAN: Who knows?
[laughter]
KAHNEMAN: It was supposed to be out in the fall of 2020. I think our publishers just remembered that there is going to be a presidential election at that time and that probably a lot of more interesting books are going to be appearing. So that postponed it to spring 2021.
COWEN: We now have some time for questions. But Daniel Kahneman, thank you very much.
Q&A
COWEN: There are mics on each side. I will call on you, and please, questions only. This is our chance to hear from Danny Kahneman. If you start making a long speech or statement, I will cut you off.
I also have questions from the iPad. So please get in line if you would like. To start with the questions here. First question: could prediction markets reduce both bias and noise?
KAHNEMAN: Well, noise certainly, but then averaging does it. And whether prediction markets consistently beat averaging is, I think, not yet fully established.
Bias, no — if there is a general bias, unless the people who are unbiased also know that they are unbiased, unless they have a way of being sure, so that they can invest more than others and move the price toward the correct answer. But without that, without this asymmetry of knowledge, if there is a bias, it won’t be reduced. Noise will be reduced.
COWEN: First question over here.
AUDIENCE MEMBER: Good evening. I have two questions, but they’re short. My first question is, you briefly talked about moral emotions. Do you see any benefit to shame? Because I’ve read conflicting theories there. So the moral emotion of shame and your thoughts.
And two, what is the impact of counterfactual thinking on happiness in your study?
KAHNEMAN: About shame, I really have no idea. It’s there. Should one wish that it weren’t? It’s probably a force that induces better behavior in lots of people who would not be controlled in other ways. So I don’t know how important or how useful it is. It’s painful to the people who feel it, and it might be useful to others who might be affected by bad behavior.
As for counterfactuals and happiness, I think that what you referred to — there are counterfactual emotions. Regret is a counterfactual emotion. Guilt is a counterfactual emotion. You can ask in the sense that they are driven by something that didn’t happen, that could have happened but didn’t.
Some of these emotions seem to be completely superfluous, like regret. And I think people, by and large, would be better off without regret. But notice what regret is. Regret is what happens the next morning. And if we didn’t have it, then who knows what we might do.
[laughter]
COWEN: Next question over here.
AUDIENCE MEMBER: Yes, sir. On this topic of delaying intuition — and I’m delighted that Mr. Klein is in the audience because I spent over a decade myself as an intuitive expert and found myself mostly using recognition-primed decision-making.
I’m curious how much you think availability bias, confirmation bias, et cetera, was still affecting my recognition-primed decision-making. And is recognition-primed decision-making still useful? Or is it just the best option in a temporally constrained environment?
KAHNEMAN: I think, obviously, recognition-primed decision-making is going to be wonderful if people really can recognize things accurately. If they can diagnose the situation accurately and do it quickly and act intuitively on that basis, then of course it’s beneficial. And there are conditions under which this applies.
Gary Klein and I became friends over a period of six years when we were trying to find out, what are the boundaries? I’m sort of a critic of intuition, and he is very much in favor of intuition, of expert intuition. And we were trying to find out, what are the boundaries? Because it’s clear that sometimes intuition is wonderful and sometimes it’s awful.
We ended up with a fairly obvious set of conclusions about what it is. You’re going to have Gary Klein–type intuition, expert intuition, if you have a regular world. That’s condition number one. There are regularities that you can pick up. And if you have a lot of experience and if the feedback is rapid and unequivocal.
If you have those three conditions, which are true for chess players — and they’re true for spouses recognizing the emotion of their spouse on the telephone, to give you a completely different example — then intuition will develop and it will be perfect. If those conditions do not develop, I don’t think we can trust people who say that they’re experts.
COWEN: Another iPad question. Tech entrepreneur Daniel Gross suggested that growing up in Israel was a forcing function for the tech sector. How much was Israel a forcing function for your thinking?
KAHNEMAN: I don’t really completely understand the term forcing function in this context. I know that Israel afforded many opportunities when I was growing up, and it probably still does. I grew up very early in the history of Israel, when the state was small and everyone could make a difference. And you really could make a difference. I was, as a lieutenant in the army, age 21 or 22 — I made a difference. I created an interviewing system for the whole army.
Those kinds of experiences — that you can do things that seemed impossible or unlikely — that is certainly very liberating and encouraging and induces creativity.
I think some of that is actually present now that the state is bigger and more established. I was telling you earlier how my grandson is in the Israeli army — the kinds of experiences that he has as a sergeant. He feels very free in an intelligence unit. He feels that he can use his mind and that he can speak his mind, and it’s going to be wonderful for his future.
COWEN: Next question over here.
AUDIENCE MEMBER: You mentioned earlier that you view many things in the world through a basic lens of pessimism. But if you were going to challenge yourself to identify something going on in the world now or in the near term about which to be optimistic, if not for yourself, for your grandchildren, say, or very young people, what should they be optimistic about?
KAHNEMAN: I’m going to pass.
[laughter]
COWEN: Over here.
AUDIENCE MEMBER: I’m curious about what beliefs you currently hold that you think in the next five to ten years might be proven incorrect, and alternatively, the same question of social science broadly.
KAHNEMAN: If I knew how I would change my mind, I would have changed my mind. My guess is that there will be completely different frameworks, there will be different ways of thinking. It’s not going to be this or that detail.
This is what happens to ideas or to frameworks. They, at some point, become irrelevant. And I know that this is going to happen to everything that I believe. Give it a few decades — it’s going to be irrelevant. I wish I could peer into the future and know what comes next, but I can’t.
COWEN: From the iPad, why did the replication crisis take so long to arrive in social psychology?
KAHNEMAN: Well, I would question that. It didn’t take very long. The replication crisis was studied first in medicine, where there were provocative claims by Stanford. I don’t know . . . he’s not a statistician, is he? There were provocative claims that most published research in medicine are false, and it started there.

Then psychology came very soon after. In fact, psychology was considered to have been quite rapid in adopting it. There was a crisis, and many results were questioned, I think correctly. There were aggressors, and there were defenders, and both sides, I think, behaved, quite often, quite badly.
It’s amazing — within a decade, psychology has changed. Many areas of psychology have changed, and it clearly is a better science than it was 10 years ago because of the replication crisis.
COWEN: Next question.
AUDIENCE MEMBER: I have two questions. The first one is the one that you just answered, not exactly the same. What do you think about our replication crisis in psychology that has happened here recently? And the second one is psychologist Martin Seligman, who is also working on happiness for years — he believed there are several dimensions that consist happiness. Do you share the same opinion or not?
COWEN: The second question was Martin Seligman, his work on happiness, that there are several dimensions of happiness. Do you share his opinion or not? And the first was just more on the replication crisis.
KAHNEMAN: Yeah. No.
[laughter]
COWEN: Next question over here.
AUDIENCE MEMBER: I have a question about bounded rationality over time. With the rise of the internet, the rise of more readily available information — so many prices, things you can see on Amazon — all this price discrimination and differentiation across products has grown with that. Do you think that people’s biases are improving or getting worse over time as more information, for example, over the past 20, 30 years, has become more readily available?
KAHNEMAN: To the extent that you think of biases as representing human nature in a broad cultural context, it hasn’t changed over the last 30 years. Human nature hasn’t changed.
In certain domains, it’s much easier to be rational when you can look things up, when you can search on the computer instead of going out and searching, as you had to when I was a young person. Then, of course, you can achieve more rational results than you could. But whether it has changed anything significant, I doubt it.
And what is very striking over the last few years is that it’s not only information that is readily available. Misinformation is also readily available. So the net effect . . . It used to be very clear that this is all to the good, but what we’re seeing in the last few years is that there is a very heavy cost to the availability and the ease of expression that transmits itself over the internet.
COWEN: Next question.
AUDIENCE MEMBER: I’m aware that I suffer from biases, and I try to hold myself to account and think better. I’m resistant to that, of course, because I always want to think that whatever thought I’m having at the moment is the exception, and I’m thinking it for good reasons. But I fight against that.
When I try to persuade somebody else to listen to one of my opinions with an open mind, is there some particular technique that you would recommend for persuading other people to do better with their own biases? Because, of course, they’re even more resistant to that than I am when I challenge myself.
[laughter]
KAHNEMAN: It’s a game one primarily plays with one’s spouse, and it doesn’t work, I think, by and large.
[laughter]
COWEN: Related question from the iPad: how can we use behavioral economics to reduce political polarization?
KAHNEMAN: It’s not that I have an answer and I’m suppressing it. Here is a topic where I am optimistic, but I have no idea. I don’t have an answer.
But I think the kind of thinking that is going on, where you’re trying to look at practical manipulations — the word manipulation is a bad word, but I intend it as a good thing — when you look at the practical moves that can make a difference in the way that people think, that way of thinking should be effective in improving the quality of life and improving the quality . . .
How polarization can be reduced is too big a problem for me and, I think, currently for behavioral economics.
COWEN: Next question.
AUDIENCE MEMBER: On a practical note, my high school psychology students ask how they can best use your research to make choices about college and career.
KAHNEMAN: My research adds absolutely nothing to this. There are sensible ways of choosing colleges, and I think they’re well known. You have to collect a lot of information, and you have to ask yourself what the student really wants and where he or she will really fit. There are obvious ways of doing this. I have nothing to add, I think.
COWEN: But say you have a student who has a gut feeling that he or she ought to go to some college for a reason he or she cannot articulate. Are you telling us they should dismiss that feeling and defer to the algorithm?
KAHNEMAN: I would try to probe and understand, where does that feeling come from? Are you asking me as a parent, say?
COWEN: Yeah, sure.
KAHNEMAN: I would really probe. I would feel free. If that’s a very expensive college . . .
[laughter]
. . . I think I would feel free to probe, where does that strong wish come from? And can we discuss it?
COWEN: Next question. On this side.
AUDIENCE MEMBER: Many behavioral economists use the notion of rationality in neoclassical economics as a normative benchmark, and you have said that you don’t think that’s necessarily a good normative benchmark. Instead, something like reasonableness is a better way to think about those things. Could you say more about how we might identify, or define and identify, this reasonableness?
KAHNEMAN: The rational-agent models are built on the notion of consistency being the one guiding principle. Your beliefs and your preferences have to be internally consistent. Nobody can tell you what to believe, nobody can tell you what you want. The only thing we know is that you ought to be consistent. Otherwise you’re not rational. As a normative principle — that consistency is the only normative principle — that strikes me as pretty odd.
There are other things that seem to matter. There is human nature, and human nature is not consistent. We are context dependent, so our emotions are context dependent. We ought to have normative theories that are adapted to who we are as people, as humans.
And the idea of consistency — it’s completely infeasible for a finite mind, and we have finite minds. So on that ground alone, it would be questionable as the principle for a normative model. But in addition, one would want a normative theory that takes into account human nature, which the principle of consistency doesn’t.
COWEN: Last question.
AUDIENCE MEMBER: You talked a little bit about cultural differences. I was just wondering, do you think that there are some cultural aspects that are costly and some that are really good? And do you think that something like increased migration or open borders would dissolve these cultural differences and push toward a more optimal equilibrium?
KAHNEMAN: Way beyond what I can talk about responsibly. That migration automatically causes cultural amalgamation — that’s questionable. I have no idea how to answer your question.
COWEN: Thank you very much. It’s been a great honor to have you.
 
Interview 12. The Knowledge Project #68 (2019):
The Knowledge Project: Interview with Daniel Kahneman
PARRISH: Hello and welcome. I'm Shane Parrish and this is the Knowledge Project podcast, exploring the ideas, methods and mental models that help you master the best of what other people have already figured out. Today, I'm speaking with Daniel Kahneman, emeritus professor of psychology at Princeton, who received the Nobel Prize in economics in 2002 for the work he did on decision making with Amos Tversky. Danny is the most influential living psychologist, a true legend in his field, and this conversation was a great honor. Publicly, he's probably best known for his book, Thinking Fast and Slow, and his work on drawing attention to our cognitive biases.
[Intro and sponsor message omitted]
PARRISH: Danny, so happy to get a chance to talk to you.
KAHNEMAN: Well, I'm happy to have you here.
PARRISH: What was your childhood like? What were you like as a child?
KAHNEMAN: Oh, my God. That was a long time ago. I was an only child, as you might expect. I suppose I was... I thought I'd be a professor when I was like three or four years old because people told me it would be because I probably spoke with long words and stuff like that. So and then the rest of my childhood, I mean, I was five when World War Two began. So and that was a Jew in France. So I've had a difficult childhood. But from that point on. But I was so lucky. I was a nerdy trial. I was quite inept physically. Very fortunately for me, when I finally moved to Israel at age 12, they held me up a grade and that was all right. But that's what I was like.
PARRISH: If there are any particular lessons or memories that stand out for you, there are two of them that they speak about.
KAHNEMAN: So one is that I was a psychologist very early on. It was very clear. I wrote an essay before I was 11, I remember where because it was during a German counterattack. It was during that period we were in Paris and I wrote an essay about faith and religion. And it was very pompous. I had a little book that was titled "What I Write About, What I Think" something like that.
But the essay started with another pompous thing that I quoted Pascal. My sister had passed through exams and I had read... studied some Pascal and I had read it. And Pascal had said that faith is God made sensible to the heart. And, you know, a little me, I said, how true. That's what I said, and then but then I said, but faith is really hard to get. You don't sense God all the time.
So that's what religious pomp is for - cathedrals, organ music - they give you and I call that ersatz faith, sort of substitute faith because it's a similar feeling. It's got to do with God. And that's what you must do with that. That's a psychologist. So it's clear that, you know, that was my calling. And so that's one significant memory of my childhood.
PARRISH: Born to be a psychologist?
KAHNEMAN: I think so. I think so. I mean, I, you know, it's always had that point of view. Later as a teenager, it was, you know, interested in all the philosophical issues like, you know, does God exist and what's good and bad and stuff like that, then why should we obey, you know, serious questions. But I discovered that actually I was less interested in the question of whether or not God exists than in why do people believe that he exists.
That I thought was interesting and I wasn't particularly interested in the question of what's good or bad, but I was really interested in what makes people angry and indignant. So, you know, I've had the psychological point of view since then, since my childhood.
PARRISH: Was there anybody who sort of influenced you to go on to study this? I mean, it's one thing to have these dreams as like a twelve, thirteen, fourteen year old boy. It's another to turn this into, you know, probably the most eminent career that's ever happened for a psychologist.
KAHNEMAN: No, not the most eminent career, you know. And I wasn't sure actually that I would do psychology when I took a vocational exam to tell me what I was good at. And psychology and economics turned out. But, you know, that was unexpected. I was and then I took psychology as an undergraduate and mathematics at which I was not particularly good. So and no, it's not that I knew at the time that, you know, that calling to be a psychologist then occurred to me. I thought, you know, I thought I'd be a professor in one thing or another. I mean, I thought I'd be an academic, but not psychology specifically.
PARRISH: You worked with Amos Tversky for a long time. Are there any particular stories that you remember about working with him that bring a smile to your face?
KAHNEMAN: Almost everything about working with him brings a smile to my face. You know, he was a very unusual person. Most people who knew him thought that he was the smartest person they ever met. And in fact, a famous psychologist, Nick Nesbitt, said that it's sort of an intelligence test. When you said that when you're with him, how long does it take you to figure out that he is smarter than you are and the first to figure that out the smarter you are.
So he was super bright and very, very funny. He joked a lot. He laughed a lot at his own jokes. And that was infectious. When I was with him, I was very funny too - more than half the laughter I've had in my lifetime, I've had during the 10 years I worked with him.
PARRISH: You have an interesting distinction between happiness and satisfaction. Can you walk us through that?
KAHNEMAN: Yeah, sure. I mean, the word happiness is so ambiguous and it means so many things to many people. But one sensible interpretation of it is that it's got to do with your emotions, with how you feel, with the emotional tone of your life, whether it's a happy life, you know, it's pleasant to be you. Satisfaction has a completely different thing. I mean, life satisfaction is how you feel about your life when you think about your life.
And most of the time you don't think about your life. You just live. But, you know, sometimes you sort of do, and that's when you determine how satisfied you are. That's life satisfaction, not satisfaction.
PARRISH: How to rebalance the two? Or how would you think about them? Should we be happy when we're younger, more satisfied when we're older?
KAHNEMAN: That thought had never occurred to me when I began to work on that. So I started out thinking that happiness and that sense of how you feel when you live, that that was reality and that life satisfaction was just stories that people tell themselves. And the important thing was to be happy in real time. But later, when we did more research, it turned out that the circumstances that make people happy and the circumstances that make them satisfied with their life are not the same.
So happiness is mostly social. It's, you know, it's being with people you love who love you back. That's that's a lot of what happiness is. Life satisfaction is much more conventional - it's to be successful. And, you know, so it's money, education, prestige, that sort of thing is what satisfaction is about. So those are two very different things. I thought that satisfaction is irrelevant. You know, that's how I began.
And we have a research program where we were trying to, you know, to show that this is the case. But then after a few years, I realized that what people really want in their life is they don't seem to care about how happy they'll be. They seem to want to be satisfied with their life. They seem to want to have a good story about their life. And then I was in the position of saying that to define wellbeing in a way that people didn't seem to care particularly about.
So that was not a tenable position. So I dropped back into saying that I had no idea how to deal with it.
PARRISH: Was this a result of the research you did? Some research that was I think it said above seventy thousand. You don't become happier, but do you become more satisfied?
KAHNEMAN: No. The research I did with Angus Deaton at Princeton, famous economist, we showed that in terms of happiness, in terms of emotional toll positive and negative, having a lot of money doesn't make you happier, but being poor makes you miserable. So above the threshold that was like seventy thousand dollars approximately in the US, then extra money didn't make you emotionally happier. But with life satisfaction, it was a different story. With life satisfaction that doesn't satiate - it's always good to have more because basically I think money is a proxy for success and it's a proxy for subjective success in many cases.
PARRISH: So it's not necessarily about spending it or doing something, but just about just getting it.
KAHNEMAN: I mean, you know, you look at all those people, all those billionaires working their heads off and they're clearly not doing this because they need more money. They're trying to get more money because that would be an indication that they're good at what they do. I think mostly it's a proxy.
PARRISH: Either of those variables correlate to longer life?
KAHNEMAN: Happiness or satisfaction? Both, apparently. But, you know, it's hard to separate. I haven't been following, you know, shortly after that I decided I don't know what well-being was. I sort of stopped doing research on this. So I haven't been following. But I think there's clear evidence that being effectively happy is really good for you. And you do live longer and better.
And so life satisfaction works in the same direction, whether it's separable, which of them, you know, is more important, I don't know.
PARRISH: I want to switch gears a little bit and talk about behavior and I'd love your insight or expansion upon the idea of we can change behavior and how do we go about changing our behavior?
KAHNEMAN: Well, you know, I'm not sure I buy the premise. I think changing behavior is extremely difficult. There are a few tips and, you know, few guidelines about how to do that. But anybody who is very optimistic about changing behavior is just... it's hard to change. Other people's behavior is very hard to change your own.
PARRISH: No simple...
KAHNEMAN: This is what marriage is all about. Right. Among other things. Other people when, you know, married people try to change each other's behavior. A lot of satisfaction not on their way to a good marriage.
I think we'd all be happier with lower expectations. I mean, and even if you have expectations, don't try to change because, you know, it's very unlikely to work in a significant way.
PARRISH: I can think of the common ways that we would sort of go about behavior change and it would be, you know, making good behaviors more easy or negative behaviors harder.
KAHNEMAN: That's the main, the main. You know, when you want to influence somebody's behavior. That's a very big influence. I've always thought that this is the best psychological idea ever. You know, so far as I'm concerned. But it's that when you want somebody to move from A to B in terms of their behavior, you can think of it that there are two ways of doing it. You can push them or you can ask the question, why aren't they doing B already?
Which is an unusual question that you want. So then when you ask why, why not? Why aren't they doing B they ought to? I think they ought to. Then you get a list of restraining forces. That was Kurt Lewin, the psychologist and that's my guru and that's my hero. And what he spoke of was restraining forces. I mean, so there are reasons why they're not where you want them to be. So he spoke of behavior as an equilibrium, the forces of pushing you one way forces that are pushing you the other way.
So how loud you speak, how fast you drive? It's easy to think of it as an equilibrium. And what we tend to do when we want to move people from A to B is we push them. We add to the driving forces and Lewin's insight was that this is not what you should do, you should actually work on the restraining forces and try to make them weaker. And that's a beautiful point. And he showed he had that image that, you know, I've had since I was an undergraduate.
And I'm not sure actually whether it was his image or something that I drew from reading him. But it's like you have the plank and it's being held by two sets of springs. You know, you wanted to move one direction and so you could add another string that would push it that way. Or you could remove one of the springs that are holding it back. And the interesting thing, and that's the striking outcome is when it moves, if it moves because of the driving force you've added to the driving force, then at equilibrium it will be in a higher state of tension than it was originally.
That is because you've compressed a spring and it's pushing back harder. But if you remove a restraining force at equilibrium, there would be less tension in the system. I must have been 20 years old. I thought that's just so beautiful.
PARRISH: What do you wish that everybody knew about psychology? That you don't think that they do? If that was class one, what's class two?
KAHNEMAN: Class two, which is the development from class one? You know, it's the same idea. Extend that. Behaviors don't necessarily reflect the personality, but behaviors have a lot to do with the situation. And so if people behave in strange ways, look at the situation there and what are the pressures in the situation that make them this way.
So there is a bias that the social psychologists... social psychologists call the fundamental attribution error. And that means that when you see people acting in some way, you think that it's because of their personality that they do. It may not be the case. It's quite likely that the situation is making them do. I'd like people to know that motivation is complex and that people do good things for a mixture of good and bad reasons, and they do bad things through a mixture of good and bad reasons.
And I think that if there is a point to educating people in psychology is to make them less judgmental, just have more empathy and more patience. And being judgmental doesn't get you anywhere.
PARRISH: When you talk about a situation one of the things that comes to mind is it's so easy for us to give our friends advice, but if we were in that situation, we might not necessarily see it. Why is that the case? Why is it so much easier to give other people advice?
KAHNEMAN: I mean, feelings get in the way of clear thinking. There is a phenomenon that we call the endowment effect, which is that I ask for more money to sell you my sandwich than I'd pay to get it. I mean, that's essentially the endowment effect and our explanation of it. There are many explanations, but the story I like to tell about it is that it's more painful to give something up than to get something. But there is an interesting result that if you have an agent making decisions on somebody's behalf, that agent doesn't have loss aversion so they buy and sell at the same price, which is the economically rational thing to do.
Where this goes into policy and governments and really important things that governments are like agents for people who think about the good of society and agents. They take the economic view. They take the view of what things will be like at the end. They don't figure out that there are some people are going to be losing because of the reform that they make. And it turns out that you can really expect losers, potential losers, to fight a lot harder than potential winners. And that's the reason that reforms so frequently fail and that when they succeed, they're almost always way more expensive than anticipated. They are more expensive because they have to compensate the losers.
And that frequently is not anticipated. So that's an example of a story about that incorporates behavior change and the difference between perspectives, between being, you know, in the situation, feeling the pain of giving up a sandwich and not feeling the pain of giving up the sandwich.
PARRISH: That would have huge public policy sort of implications too. Right. That we don't tend to think about or discuss. That's really interesting. I know there... I'm going to come back to sort of Situational Decision-Making based on sort of like what we see is all there is. And we have these feelings that we can't sort of disassociate. Well, how does the environment play a role like the physical environment in sort of what we decide or does it?
KAHNEMAN: I mean, you know, there are so sort of obvious things that we know people are hot and bothered, distracted, and there is a lot of noise and so on. And they don't think this well, that we know that's not even... there are puzzles. I mean, many people think and work a lot better in cafes, you know, where there is actually ambient noise and activity around them and it helps them concentrate. But also there's a very simple story of the environment.
But certainly you can make the environment tough enough so that people won't be able to think properly. That's feasible.
PARRISH: Are there things that we could do to, I guess, push the environment to be more conducive to clear thinking, the physical environment in this case?
KAHNEMAN: Oh, there are sorts of odd findings. You know, the colour of the room, some colours are better than others. You would expect that. Some colours are more calming than others. So you wouldn't want to be in a red room making decisions. You like making decisions. But, you know, those are extreme and minor effects.
PARRISH: I want to come to intuition and noise later. Is there anything else that stands out that gets in the way of clear thinking that we can sort of bring to the surface now?
KAHNEMAN: Well, you know, what gets in the way of clear thinking that we have... we have intuitive views of almost everything. So as soon as you present a problem to me, you know, I have some ready made answer and that gets in the way of clear thinking, those ready-made answers, and we can't help but have them. So that's one thing that gets in the way. Emotions get in the way. I would say that independent clear thinking is, to a first approximation, impossible. I mean in the sense that, you know, we believe in things most of the time, not because we have good reasons to believe them.
If you ask me for reasons, I'll explain to you and I'll always find a reason. But the reasons are not the causes of our beliefs. We have beliefs because mostly we believe in some people and we trust them and we adopt their beliefs so we don't reach our beliefs independently. Clear thinking is something, you know, unless you are a scientist doing something like that.
PARRISH: But even then, it's probably a very narrow and...
KAHNEMAN: That's very narrow. And there is a fair amount of emotion, even among scientists as well, that gets in the way of clear thinking, you know, commitments to your previous views, being insulted that somebody thinks he's smarter than you. I mean, lots of things get in the way even when you're a scientist. So I think there is less clear thinking than people like to think.
PARRISH: Is there anything that we can do at the belief formation stage? Like it sounds almost as though when you say that we're reading a newspaper, we read this op ed and it's well constructed and fits with our view of the world. Therefore, we adopt that opinion and we forget the context that we didn't learn it through our own experience or reflection. We learned it sort of from somebody else. So we don't know when it's sort of likely to work or not work, but we just proffer that as our opinion is there...
KAHNEMAN: That's how I believe in climate change. You know, I believe in the people who tell me there is climate change and the people who don't believe in climate change, they believe in other people.
PARRISH: So but similarly, there's like fake news and all this other stuff that we have the same reaction to you, you know...
KAHNEMAN: But you're much more likely to believe fake news on my side than the fake news on the other side. I mean, it's true that there is the huge degradation in public discourse in the recent 10, 15 years in the United States. I mean, there used to be an idea that facts matter.
PARRISH: What would be your hypotheses as to why that that is playing out without getting into politics? Because I don't want to talk politics. But why is that?
KAHNEMAN: Well, I mean, it's hard to... it's hard to answer that question without without politics, because the general political polarization, I think, had a very big effect. And the fact that people can choose the sources of information.
PARRISH: Let's switch gears a little bit and talk about intuition. I think one of the things that strikes me the most about some of the work that you've done is the cases where we're likely to trust our intuition and when we're not.
And so if I'm... correct me if I'm getting this wrong. So it's sort of like a stable environment, repeated attempts and rapid feedback. It strikes me that most decisions made in organizations do not fit that environment. And yet we're making a lot of these decisions on judgment or experience. What are the ways that we can sort of make better decisions with that in the context?
KAHNEMAN: Well, in the first place, I think, you know, you shouldn't expect too much. I talk to lower expectations. You should have low expectations about improving the systems. I mean, there is one basic rule is slow down, especially if you if you have the immediate conviction, slow down. There are procedures. You know, there are ways of reaching better, better decisions, but reaching better judgments. And we can talk about them.
I would love to... if you really want to improve the quality of decision making, use algorithms wherever you can. If you can replace judgments by by rules and algorithms, they'll do better. There are big social costs to trusting, allowing algorithms to make decisions. But the decisions are likely to be better. So that's what if you can't use the algorithms, then you slow yourself down. And then there are things that you can do for certain types of problems and different types of problems.
So one class of problems - forecasting problems. My friend, Phil Tetlock, has that book, Super Forecasters, where he identifies people who are good at forecasting the future, but they do... what that makes them good and and tries to train people and they can improve. So that's one classic problem.
I'm into another kind of problem, judgment problems, where basically you're considering options or you're evaluating the situation and you're trying to give it a score. There, there is advice, I think, on how to do it. For me, it goes back to something I did in the Israeli army when I was like 22 years old. So that's a long time ago. Like 63 years ago, I was a psychologist in the Israeli army and I was assigned the job of setting up an interviewing system for the army.
That was ridiculous that, you know, this was the beginning of the state of Israel. So people were improvising all over the place. I had a B.A. and I think I was the best trained psychologist in the army... my boss was a chemist. Brilliant. But anyway, and the existing system was one where people would interview and try to form an intuitive global image of how well that recruit would do as a combat soldier. That was the objective of the interview.
And because I had read a book, I mean, I took a different tack and the different tack was I identified six traits that I sort of made up. And I had them ask questions and evaluate each of these traits independently and score it and write down the score, then go on to the next trait. And they had to do it for all six traits. That was that's all I asked them to do. And the interviewers who... who were younger than I am, the recruits, but very, very smart, selected for being good.
And they were furious with me and they were furious with me because they wanted to exercise their intuition. And I said, remember that one of them said, you are turning us into robots. So I compromised with them. And I said, OK, could you do it my way? And I told them, you try to be reliable, not valid. You know, I'm in charge of validity, you be reliable, which was pretty arrogant, but that's that's how I presented it.
But then when you're done, close your eyes and just put down a number of how good a soldier is that person likely to be. And when we validated the results of the interview, it was a big improvement over what had gone on before. But the other surprise was that the final intuitive judgments... it was good, it was as good as the average of the six traits and not the same, it added information. So actually we ended up with a score that was half was determined by the specific ratings and the intuition was half the weight.
And that, by the way, stayed in the Israeli army for well over 50 years. I don't know whether I think it probably some version of it is still in force. But around 15 years ago, I visited my old base and the commanding officer of the research unit was telling me how they run the interview. And then she said, and then we tell them, close your eyes. So that that had stayed for 50 years, not just the close your eyes. And that whole idea is now the basis of the book that I'm writing.
So I actually have the same idea, really, that when you are making decisions, you should think of options as if they were candidates. So you should break it up into dimensions, evaluate each dimension separately, then look at the profile. And the key is delay your intuition. Don't try to form an intuition quickly, which is what we normally do. Focus on the separate points. And then when you have the whole profile, then you can have an intuition and it's going to be better because people form intuitions too quickly and the rapid intuitions are not particularly good.
So if you delay intuition until you have more information, it's going to be better.
PARRISH: I'm curious how we delay intuition...
KAHNEMAN: Your intuition, by focusing on the separate problems. So our advice is that if you have, you know, the board of directors making decisions about an investment, we tell them to do it that way, take the separate dimensions and really think about each dimension separately and independently. And don't allow... and if I'm the chair don't allow people to give the final judgment.
So we wait until we cover the whole profile. I mean, if you find a deal breaker, then you stop. But if you haven't found a deal breaker, wait to the end and look at the profile and then your decision is almost certainly going to be better.
PARRISH: Does that include weighting the different aspects of the problem differently or do you highlight that in advance? Or do you just...
KAHNEMAN: I mean, it... it makes you see the trade offs more clearly. Otherwise, when we don't follow that discipline, there is a way in which people form impressions very quickly, form an impression, and then you spend most of your time confirming it instead of collecting evidence. And so if accidentally your impression was in the wrong direction, you're going to confirm it. And you don't give yourself a chance to correct.
The independence is key, because otherwise, when you don't take those precautions, it's like having a bunch of witnesses to some crime and allowing those witnesses to talk to each other. They're going to be less valuable if you're interested in the truth than keeping them rigidly separate and collecting what they have to say.
PARRISH: What have you seen work in a repeatable way? It may be a particular organization or cross organizations to not only reliably surface disconfirming evidence, but then place a value on what is surfaced instead of being dismissive. Is there a framework for that? Is there?
KAHNEMAN: Well, there are many. You know them. There are many procedures like Red Team, Blue Team, Devil's Advocate. There have been, you know, many attempts. And in general, you know, if you are if you're the head of a group that makes decisions, one of your missions would be to protect the dissenters. Because they're very valuable and you should make it as painless to them as possible, because it's hard to dissent, it's painful and costly, so protecting dissenters is important.
PARRISH: I'm curious about the distinction between intuition and judgment. You had mentioned intuition and judgment, intuitive judgment. Can you walk me through some of, like, how those differ?
KAHNEMAN: It's a bit hard to separate. In judgment, this is what you do when you integrate a lot of information informally into a score of some kind. We speak, we being my co-authors in the book we're writing, we speak of judgment as measurements, but it's measurement where the measuring instrument is your mind.
But you do it informally. And because you do it informally, people are going to... are not necessarily going to agree. So wherever we say it's a matter for judgment, we're allowing for differences, for variability. Now, judgment can be more or less slow, more or less systematic. So at one end, you have your intuition where you allow the judgment to go very quickly and so on. And at the other end, you try to delay intuition.
But ultimately, if you're making it by judgment, you're going to have a judgment and it's going to be like an intuition and you're going to go with it. So there's more or less deliberate judgment, but intuition is always involved at one point or another.
PARRISH: You're sort of like listening to it or fending it off.
KAHNEMAN: Yeah, and our recommendation is turn it off.
PARRISH: Are there ways to judge the quality of somebody's judgment?
KAHNEMAN: Oh, sure. I mean, some of them would be unique to the actual scenario, but what are the sort of other ways that we could?
Well, I mean, you... you may require people to explain their judgments. And evaluating the quality of the explanation is, you know, whether it's logical, whether it uses the evidence, whether it uses all the evidence, whether it is strongly influenced by wishes. Whether the conclusion was reached before the judgment supposedly is made, you know, there are a lot of there are lots of ways for them to fail that can be recognized. So it's harder to recognize very good judgment, but it's easy to see, you know, what goes wrong.
And there were quite a few ways to go wrong.
PARRISH: And I think some of those ways are the cognitive biases like overconfidence and sort of using small or extrapolating from small sample sizes. And one of the interesting things that I've heard you say in interviews before, correct me if I'm I'm off here, is that you've studied cognitive biases effectively your whole life, and you're no better at avoiding them than anybody else.
KAHNEMAN: Yeah, certainly not much better. So what hope do the rest of us have? Not much. I mean, I never... you know, I I think, you know, the quality of people's judgment is affected by education, but in general, you know, more educated people make better judgments, I think. On average, but people deciding 'I'm going to make better judgments' - I don't think that's very hopeful. I'm much more hopeful about organizations because organizations think more slowly and they have procedures for thinking. And so you can control the procedures. Individual judgment is really hard to fix, not impossible.
PARRISH: One of the things that I see people do in response to cognitive biases and trying to account for them is to sort of make a list of them almost like a checklist and then go through that checklist and explain or rationalize why those things don't apply in this situation. It also strikes me that the more intelligent you are, the more stories you'd be able to conjure up about why why you're avoiding this.
KAHNEMAN: I really think that's not very helpful because there are so many biases and the biases work in different directions anyway. So sometimes you can recognize a situation as one in which, you know, you're likely to be wrong in a particular way. So that's like illusions. If you if you recognize a particular pattern of something that gives rise to visual illusion, then you don't trust your eyes. You know, you do something else. And the same thing happens when you recognize this is a situation where I'm likely to make an error.
So sometimes you can recognize the importance, for example, of what we've called an anchor. So you're going to negotiate a price with somebody. They start very high and that has an effect. So, you know, or you should know the person who moves first and the negotiation has an advantage. Because it's the first number that changes everybody's view of what is considered plausible to move things in that direction. That's that's a phenomenon. People can learn that and they can learn to resist it.
So when I was teaching negotiations, I would say if somebody does that to you, comes up with a number, that's absurd. I would say lose your temper, make a scene, say I will not start the conversation from that number. It's an absurd number. I don't want to talk about the rest of them. So that's something that they, you know, you can improve if you recognize.
I think people are aware of the fact that you shouldn't make a decision about road safety within a short interval of a terrible accident. And so you should allow things to settle down and cool down. There is a more subtle error and it's harder harder to fix, but the best prediction, the best guess is always less extreme than your impression. Intuitive prediction is, as we say, not regressive. It doesn't recognize the regression to the mean, but statistics is statistics and statistically, things are less extreme.
Should I give you my favorite example of a bias?
PARRISH: Yeah.
KAHNEMAN: I have been unable to think of a better one, but the story is about Julie. That's part of the story. That's her name. She is a graduating senior at university. And I'll tell you one fact about her that she read fluently when she was four. What's her GPA?
And the interesting thing here is that everybody has a number. As soon as I told you that fact, a number came to mind. Now we know where that number came from. We really... that's one of the few things that I'm reasonably sure I understand perfectly. And this is that when you hear she read fluently at age four, you get an impression of how precocious she was. That's impressive.
And you could put that in percentiles, you know, whether that put her on a percentile for sort of aptitude ability and it's high, it's not, you know, if you read fluently at age two and a half would be more extreme, but it falls pretty high. So said the 90th percentile. And then the GPA that comes to your mind is around the 90th percentile in the distribution of GPA. So you pick something. Your prediction is as extreme as your impression.
Mm hmm. And it's idiotic, statistically completely stupid, because clearly the age at which I learn to read is not all that diagnostic with respect to GPA. So it's better than nothing if you didn't know anything, you would predict the mean GPA, whatever they did, three point one, three point two. Now she's bright, so probably a little higher, but not three point seven. You don't want to. So that's cool. That's a bias.
That's not regressive prediction. And that's very hard to resist. Sometimes I'm able to resist it, but never when it's important. You know, when I'm really involved in something, I don't think about it. But sometimes I will recommend, oh, you know, that's a situation I should moderate my prediction. And if you're conscious of it, that's an example of one. You can sort of talk yourself.
PARRISH: Yeah, you can talk yourself into, although, you know, you usually will find a way to cheat and end up with your intuition. It's that's remarkable, you know, when you've been in academic life for a long time. So you've been in many situations where people discuss the job candidate and absurdities of that kind of very common. So somebody, a job candidate, gives a talk and people evaluate the talk and. Something happened, you know, at Berkeley when I was teaching there that somebody who was a very good dog in the bed who had teaching prizes.
KAHNEMAN: And yet what was said about him in the discussion, he can't teach. You know, we heard the talk. So that's a mistake. But the funny thing is you can point out to people that that's a mistake. They still don't want to hire him because they gave a lousy talk. So it's hard to resist. It's interesting.
PARRISH: And one of the I think one of the ways I probably got my job is using psychology in the interview, which is asking why I was there and then reinforcing those beliefs throughout the interview.
PARRISH: I want to come back just one second to the immediacy of sort of having a stimulus and then making a decision. So we use the example of roads and a tragic accident happens. And you're rethinking sort of policy or laws or on the roads. How much of that do you think is social pressure?
PARRISH: And I'm wondering if we could even extrapolate that a little more to we're taught to answer questions on a test right away. Right. So we see this question and we answer it. We're taught that we or maybe it's reinforced taught us probably the wrong word, that politicians need to have a response, an immediate response to and even if they know the best thing to do is like, OK, like what they said, I'll take some time. It's society writ large seems to demand it like the environment is not conducive.
KAHNEMAN: I think it's pretty clear that people prefer leaders who are intuitive and who are overconfident, leaders who deliberate too much are viewed with suspicion.
So I think Obama was at a certain disadvantage relative to George Bush, you know, because he was seen as more deliberate, it was all deliberate.
And then when you're very deliberate, you look as if you don't know what you're doing, but when you act with confidence.
So people want leaders who are intuitive, I think, by and large, provided they agree with them.
PARRISH: Let me just work my way back through some of these rabbit holes that we've gone down.
PARRISH: You taught negotiations. I'm curious what would be in your your sort of syllabus for negotiations that everybody should learn about negotiations when it comes to your work and psychology?
KAHNEMAN: Well, you know, that goes back to a theme that we started with. The essence of teaching negotiations is the negotiations is not about trying to convince the other guy. It's about trying to understand them. So, again, it's slowing yourself down. It's not doing what comes naturally because trying to convince them is applying pressure. Arguments, promises and threats are always applying pressure. And what you really want is understand, you know, what you can do to make it easy for them to move your way.
Very nonintuitive. That's a surprising thing. When you teach negotiation, it's not obvious. You know, we are we're taught to apply pressure and socialize that way.
PARRISH: You mentioned that there is procedures for thinking in organizations. Are there any that stand out in your mind that we could use to elevate thinking and if not elevate but give feedback on the quality of thinking to improve it?
KAHNEMAN: Well, I think one of the ideas that people like the most is one by Gary Klein and he calls the premortem. And that's that's universal when people really like that idea. And this is that when you are about to make a decision, a group.
Not quite, because if you've made it, it's too late, but they're approaching you. And then you get people in the room who can be the people who are making the decision. And you say suppose it's two years from now we made the decision that we're contemplating and it turned out to be a disaster. Now we have a page in front of you write the history of the disaster, and that's the premortem. And and it's beautiful as an idea.
It's beautiful because when people are coming close to a decision, it becomes difficult to raise doubts or to raise questions. People who are following the group down when the group is nearing a decision are perceived as really, you know, and really, you know this. They want to get rid of them. And the premortem legitimises that sort of dissent and that sort of. Not only legitimizes that, but rewards it, and so that's a very good idea.
I don't you know, I don't think that it's going to prevent people from making mistakes, big mistakes. But it could certainly it will allow people to identify possible loopholes to to things that they ought to do to make it safer. So that's a that's a good procedure. And there are many others. What comes to mind? What comes to mind is, is to make intelligence and the collection of information independent of the decision makers wishes. And you really want to protect the independence of the people collecting the evidence.
And I would add to the procedures, really, people don't like that if it were possible to implement it, I think would be good. And that's. Look, when you are going to be discussing the topic and it's known in advance and people in central material to think about the topic that you may want them to write down their decision, the decision they are in favor of before the discussion starts, that has many advantages. It's going to give you a broader diversity of points of view because people tend to converge very quickly in a in a group discussion and it forces people to be better prepared.
So it's except people don't want this. So I don't know whether it's even possible to implement. But clearly, if you could be a good idea.
PARRISH: What are the reasons people don't want to do much work it forces you to do rather than the signaling you can sort of get away with?
KAHNEMAN: Yeah. And then, you know, somebody who is going to prepare the case. And so I glanced at the material and then, you know, so a lot of meetings are tremendous to think for wasted time and improving the quality of meetings would be a big thing.
PARRISH: Do you have any insights on how to do that, keeping them short?
KAHNEMAN: You know, I'm not a professional at fixing meetings, so I have I have a few ideas, but not a complete view.
The the question of structuring the meetings to be discussing topics one at a time that I think is is really useful. I'll give you an example. I mean, it's something that I suggested when I was consulting, but for some reason, people didn't buy that suggestion. So you when an investment is being discussed, so by the investment firm, some staff people, if it's a big investment stuff, people will prepare a briefing book with chapters. Now, our recommendation would be that the staff should end each chapter with a score.
How does that chapter, taken on its own, independently of anything else, affect the likely decision? And then you could structure the meeting, the discussions and the meeting of the boards to discuss these schools. One of the things that has the effect that I was talking about earlier, making the decision, making the judgments about the dimensions we call them mediating assessments is all drawn to the mediating assessments. Come first and then you have the profile of them, and then you make a global judgment and you can structure it.
So if the staff has presented a score and you discuss in the board, do we accept the school, you're forcing people to have a look at the evidence and think about why they would accept or reject.
PARRISH: And then they feel like you have to construct an argument that might be less intuitive, etc..
KAHNEMAN: So, you know, there are ways of doing this, but if you're going to be too rigid about it, it won't work either.
PARRISH: So I'm curious what other advice you gave as a consultant that nobody followed?
KAHNEMAN: I mean, virtually all the advice we give, people don't follow. I mean, you know, I think that that's not you shouldn't you know, you're not going to be a consultant. If you expect your advice to be taken. You have to give the best advice you can.
PARRISH: What would be other examples of something you think could be widely applicable that you would advise you would have advised people and you just sort of like saw them drop the ball?
KAHNEMAN: Well, I mean, you know, I would advise people who make a lot of decisions to keep track their decisions and of how they turned out so that later you can come and and evaluate your procedures and and and see whether there is anything that is in common with those decisions that turned out well and then not so well and so on. People hate doing this.
PARRISH: Why do you think people hate doing it?
KAHNEMAN: Oh, because because retrospectively they may look foolish, some of them or all of them or in particular the leader.
So they really don't like it. I mean, there are exceptions, Ray Dalio and his firm where everything is Bridgewater.
PARRISH: Yeah, yeah. Bridgewater but in general, it makes...
KAHNEMAN: Having consulted with Bridgewater, they don't need me. But but in general, when I suggested that never went anywhere.
PARRISH: What are the variables that you would recommend people keep track of? Like what would your decision journal look like?
KAHNEMAN: Oh, you know, my my decision journal would be a mess. I don't know, putting myself as an example, but so obviously the outcome, but you've got to do that post after all.
But no, not you. You would want to say what were the main arguments, pro and con? What were the alternatives that were considered? And it doesn't have to be very detailed, but it should be enough so that you can come later and debrief yourself.
PARRISH: Should you have a calibration like what degree of confidence you are...
KAHNEMAN: That would be good. Then, you know, it would depend on something that you could evaluate.
PARRISH: It strikes me that decision journals and premortem are a way to identify people that are sort of perhaps suppressed by their manager, where you have somebody who's actually a better, better at exercising judgment than the person that is that they're working for. And this would be a pain free sort of way to calibrate that score over time and identify the quality of judgment in a consistent way. We are. And that strikes me as where a lot of money to an organization.
KAHNEMAN: Yeah, but they're also very costly. And you you will see that certainly anything that threatens the leader is not going to be adopted. And and leaders may not want something that threatened their subordinates, whether people are really very worried about embarrassment.
PARRISH: You're writing a book now on noise. Yeah. Tell me about Noise and Decision-Making. Can you explain the concept?
KAHNEMAN: Yeah, I can really explain it by saying what you know was the beginning of it, which was a consulting assignment in an insurance company where we had the idea of running a test to see whether people in a given role who were supposed to be interchangeable, agreed with each other. So, you know, when you come to an insurance company and an underwriter gives you a premium, the underwriter speaks for the company. And so it's you expect that any underwriters.
It doesn't matter which underwriter you get to for the premiums and the company has that expectation shouldn't make much difference. So we tested that and they constructed some cases. And then we have some like 50 underwriters each give a premium for the case with the same information.
PARRISH: Yeah, with a really very realistic...
KAHNEMAN: We didn't construct they constructed the case, so they conducted the experiment. But now the interesting question is how much variation do you expect there to be? So we asked the executives the following question supposedly to take two underwriters, random, by what percentage do they differ? You look at the difference between the premium divide, that by the average premium with no judge, and people expect 10 percent. By the way, it's not only the executives in that company.
For some reason, people expect 10 percent and it was roughly 50 percent, five zero. So that's you know, that's what made me curious about that. And the fact that the company was completely unaware that it had most, took them completely by surprise. So now we're writing a book because there's a lot of noise. So wherever there is judgment, there is noise and more of it than you think. So that's the pattern.
PARRISH: Are there procedures to reduce noise? And conversely, is noise? It strikes me that the variation would be good, but maybe only in an evolutionary concept.
KAHNEMAN: Well, we call that noise is useless variability. And variability can be very useful if you have a selection mechanism and some feedback. So evolution has built up variability, but of course it's useful. But noise among underwriter's is useless. There's nothing nothing gets learned. There's no feedback. It's just noise and it's costly. The first advice, of course, would be algorithms, as I said earlier. So algorithms are better than people in judgments. That's not intuitive, but it's really it's really true.
And and after that, then, you know, the procedure that I mentioned earlier for making decisions in an orderly way by breaking it up into assessments. And that's the best that we can do. And and there is one very important aspect that I haven't mentioned. But and this is training people in the scale is so there is one piece of advice that you'd have for underwriters that they should always compare the case to other cases. And if possible, if you can have them share the same frame of reference with other underwritings, we're going to cut down on the noise.
PARRISH: Oh, that's a clever idea, controlling the scale...
KAHNEMAN: And that exists in human resources, where performance evaluation, which is one of the scandals of modern commerce, how difficult it is, but performance evaluation, they have the thing that's called frame of reference training. Which is teaching people, you know, how to use the scale, there's a lot of variability in the scale and part of what the super forecasters do, they make judgments in probability units and they teach them to use the probability scale.
So learning the scale is a very important aspect of reducing noise.
PARRISH: I know we're we're coming up to the end of our time here. What have you changed your mind on in the past 10 years?
KAHNEMAN: Oh, lots. And I think that, yeah, there's been a replication process in psychology. And some of the stuff that I really believed in when I wrote Thinking Fast and slow, some of that evidence has been discredited. So I've had to change my mind.
PARRISH: What are the what's the some of the facts...
KAHNEMAN: This stuff priming and unconscious priming and so just hasn't held up and replication. And I believe that and I wrote it as if it were true because the evidence suggested it.
And in fact, I thought that you had to accept it because that was published evidence. And and I should have I blame myself for having been a bit gullible, that as I should have known, that you can publish things even if they're not true. But I just didn't think that through. So I changed my mind. I'm now much more cautious about spectacular findings. I mean, very recently of I think I have a theory about why psychologists are more social scientists generally are prone to exaggerate the to be overconfident about their hypotheses.
So I've done quite a bit of loanwords.
PARRISH: What's the theory on...
KAHNEMAN: The theory that one element of the theory is that all of these hypotheses are true? In what sense that you might find that there's a famous study that you mentioned wrinkles to people and then you measured the speed at which they walk and they walk more slowly. Turns out that hasn't held up in replication, which is very painful. It's one of the favourite studies. But actually, you know that if you mentioned Wrinkle and it's going to have any effect on the speed of walking, it's not making to me.
It's not going to make people faster. It has an influence to make them slower. So directionally, all these hypotheses are true. But what there is, is what people don't see is that the huge number of factors that determine the speed at which individuals walk and the differences in the speed of walking between individuals and that noise and people neglect noise. And then there is something else which is touches on both philosophy and psychology when you have intuitions about things, the clear intuitions and their strong intuitions.
Another thing so clear intuition is if I offer you a trip to Rome, a trip to Rome and an ice cream cone. You know what you prefer, it's easy, but it's very weak, of course, mean the amount of money you would pay to get a trip to Rome and a trip to Rome. And then I go nothing. But when you are a philosopher and I should add one thing, to see the clear intuitions, you have to be in this kind of situation that psychologists call within subject, that you have both you have both the with with the ice cream cone and without the ice cream, the.
So, you know, within subject situation, that's an easy problem in a between a separate situation, it's an impossible problem. But now if you're a philosopher, you're always within subject situation. And but people live in between subjects that you wish they live, you know, in one's condition. And the same thing is true for psychologists. So psychologists live in when they cook up their hypotheses, they're within a subject situation. But then they make guesses about what will happen between subjects and they're completely lost between clear intuitions and strong intuition.
We have no way of calibrating ourselves. So that makes us wildly overconfident about what we know and reluctant to accept that we may be wrong of.
PARRISH: That's a great place to end this conversation. Anything you...
[Outro omitted]

 
Interivew 13. People I (Mostly) Admire (Freakonomics, 2021):

Steven LEVITT: Danny, it’s so great to talk with you again. It’s been way too long and I miss you.
Danny KAHNEMAN: Mutual.
LEVITT: So it’s been roughly a decade since Thinking Fast and Slow was published. And even though that book turned out to be a massive bestseller, I still can’t believe you wrote another book because I remember it practically killed you writing the last one, wasn’t it torture?
KAHNEMAN: Well, Thinking Fast and Slow was worse than this one because it was a lonely endeavor. This time I worked very closely with one of my collaborators — Olivier Sibony, he is in Paris and we were on Zoom for an hour or two a day for the whole period. Because of Covid — the virus helped us a lot. Previously, we have been meeting once a month for several days and it turned out that Zoom was way more efficient.
LEVITT: One thing that I really admire about you, Danny, is that you are a lifelong learner. So, for instance, I would have fully expected that you would have learned from your last book, from Thinking Fast and Slow, that you needed co-authors and you went out and found co-authors. But much more seriously, what’s striking about your new book, which is called Noise, is that while it builds on your enormous lifelong academic accomplishments, many of the ideas are new and you’ve created these ideas in the last 10 years. And I find that to be really admirable, that you weren’t just rehashing your old work.
KAHNEMAN: Oh, I mean, Thinking Fast and Slow was such an experience that after that I had forgotten everything that was not in the book, so I really need a new thing. And Noise was quite new, actually.
LEVITT: So could you give us the three-minute version of Noise, just to give listeners a taste of what’s in the book?
KAHNEMAN: Sure. Noise is unreliability. And we speak of system-noise when there is a system such as the E.R. is a system, an insurance company that sets premiums is a system. And noise in that system is when individual people who are supposed to be interchangeable in terms of their roles actually give very different answers to the same problem. So you have a company and whoever interacts with the company is facing a lottery, which employee or which member of the organization you will interact with and that lottery is noise.
LEVITT: O.K., and so just to be totally clear, this is different from bias, this is orthogonal to bias.
KAHNEMAN: This is really the complement of bias. Yeah. And in terms of the standard way of measuring accuracy and measuring error, bias and noise are completely independent of each other and there is an equivalence between the amount of error that bias produces. Bias is really the average error, and noise is the variability of error, the standard deviation of errors.
LEVITT: So what you’re talking about is that when you interact with something, whether it’s a company, or the medical profession, or a grocery store, the goal would be that there’d be no bias and the same set of inputs should lead to the same output and the right output. If you do that, then that system is both without bias and without noise.
KAHNEMAN: Perfect, yes.
LEVITT: O.K., and so your book is about noise and noise is really the sort of ignored stepsister of bias. I was lucky enough, when we were partners together at a little firm called The Greatest Good, to have a front-row seat watching you begin to work out the ideas that eventually appeared in Noise. And I think the original inspiration came from some work you were doing for a large insurance company. Could you describe that work?
KAHNEMAN: Well, in that insurance company, the topic came up actually, do their underwriters operate in the same way? So we ran an experiment, we called those experiments “noise audits,” and the idea was they produced some cases, presented those cases to several dozen underwriters, and had each underwriter select a premium that was appropriate to that risk. What made the issue interesting was that I also asked the executives in that company, how much of a difference they expected. And the question was put as follows, supposedly two underwriters at random, you compute the average of the two premiums they set and you divide the difference by the average. So in percentages, how large do you expect the difference to be? Now, it turns out, there is a number that seems to come to everybody’s mind as a tolerable amount of noise, and that’s roughly 10 percent. Now the correct answer, in two units — at that insurance company was roughly 50 percent, five-zero. Five times larger than people had expected.
LEVITT: I think it’s easier maybe to think about payouts so if someone’s fallen and gotten hurt and now the insurance company has to make a payout. You’re saying you give two claims adjusters the exact same case, all the information about the circumstances, and if a fair value of a payout was $20,000 —
KAHNEMAN: I would expect the median difference between two claims adjusters would be about $10,000. So one of them would say 15 and the other will say 25.
LEVITT: And the executives expected the number to be between $1,000 and $2,000, not the $10,000 that it turned out to be. Yeah. O.K. And I have to admit, when you started this project, Danny, I also thought the numbers would be small, and I was even more pessimistic because I thought, well, even if the numbers are big, nothing’s going to happen. Firms always find a way to explain away results and say it was a fluke, it didn’t matter, and to ignore the kind of advice you were giving them, but I have to say this was very different in this case.
KAHNEMAN: Oh, well, they viewed it as their experiment, it was a challenge. They took it on. They created the materials. And they carried out that experiment to find out what they were doing, with our help. And because it was set up at their job, they really accepted the results.
LEVITT: By their own accounts, when they went back and tried to tally up the value of the work you had done, I seem to remember that they internally valued that at something like $2 billion. Am I not correct?
KAHNEMAN: They realized that noise was costing them probably over a billion dollars a year. The cost is large.
LEVITT: So we were part of a little firm called The Greatest Good that consulted with big companies and tried to help them. And honestly, I think you would probably agree, Danny, we weren’t very good at it in the sense that we didn’t actually get very many companies to change very much. But this was the one case in the, say, six or seven years we did this, where there was just massive change.
KAHNEMAN: Setting the wrong number for a claims adjuster is actually a risky thing for the company. You set it too high, you’re going to be too lax and you’ll pay too much. You set it too low, very likely there’ll be litigation, and so getting it right is really quite important. And when there is that amount of variability, that means that most of the time they don’t get it quite right. 
LEVITT: One of the things that I found really refreshing about that project was the solutions actually turned out to be relatively straightforward and intuitive. They could, with relatively little effort, completely change their decision process to get rid of a large chunk of the noise.
KAHNEMAN: They did implement some ideas, and indeed, the ways of cutting down on noise are pretty obvious. You want to have a process that will make people think in the same way and at the same time, you want that process not to be too bureaucratic because you don’t want people to fill forms.
LEVITT: One of the things that helps with what you call decision hygiene, which I think is a really good name for the process of thinking sensibly about outcomes, is that you want to break a problem down into small pieces, to not look at a big file and just blurt out a number, but rather to take a number of small steps that are pieces of the overall decision, independently, and put them together.
KAHNEMAN: Yeah. And that is very general about large judgement problems. The intuitive way of going about it is to assimilate a lot of information and then to trust your intuitive system to come up with a solution, and this is clearly not optimal. We know that people do better than that if they have a plan, if they break up the problem, if they evaluate each part of the problem separately and independently from the other parts, and if they postpone their intuition until they have enough information.
LEVITT: When I was a student at MIT, I took a one-day course on guesstimation. And the professor who taught it was from the sciences and, I guess, he had grown up on a farm and he and his brother each had to drive a tractor all day and they would get bored. So their job at the beginning of the morning was to come up with some number that the other one would have to guesstimate and they’d come back at lunchtime and see how close they had gotten to it. And he gave essentially the exact same advice you’re saying, which is you should divide the problem into as many independent pieces as possible. And he said when you tend to make a mistake on one of those little pieces, it’s often offset on another piece. So, for instance, if you try to imagine the total mass of all the trees that are growing on the planet, if you start by saying, “Well, how many trees are there? And then how much does each tree have of mass?” That the people who think of big trees tend to guess that there are fewer trees out there, but they have more mass per tree, and so those two pieces offset. The other thing that he said that isn’t mentioned by you is that as soon as you’ve gone through and gotten one set of estimates, he said stop and start over with a completely different approach to the problem. He said in guesstimating anything, you should never be off by an order of magnitude, even if you have no idea what the problem is, which turns out to be to be true that you literally can guesstimate anything if you use that process.
KAHNEMAN: That’s amazing. You know, it was the physicist Fermi, I think, was a master at this breaking up problems. And Philip Tetlock, who does super forecasting, teaches his super forecasters to Fermi-ize that is, to break up a problem and estimate the different parts. So, yeah, there is a procedure.
LEVITT: And another thing that seems quite important is if you’re going to have multiple people assessing a problem, the importance of them doing it independently rather than in discussion with one another, for instance.
KAHNEMAN: That is really vital, and this is something that people really do not like. In the book, we tell the story that we heard from Nathan Kuncel, a psychologist who was consulting with universities on the process of admitting students. And they were grading student’s essays, candidates. He noticed that one person would read the essay, put on a grade, pass it on to the colleague with a grade on the front page of the essay, and he said, “Look, I mean, this isn’t the optimal way of doing it. You should put the grade on the back of the essay, so the next person will not see it.” And they told him, “Oh, we used to do it that way, but there was so much disagreement.” Now, that is actually what happens with noise — people don’t want to detect that there is noise.
LEVITT: It’s a challenge in that the problem you’re trying to solve in the book, really is how do you get rid of noise? And yet if that’s not the objective of the system you’re working with, then it’s impossible to ever accomplish that objective. I mean, that’s something you’ve run into over and over, right? It’s so often typical economists decide what people should do before they actually talk to real people.
KAHNEMAN: Well, this is really what we’re hoping for in terms of the effect of the book. Is for people to become convinced that there is a problem that deserves looking at. And our advice is to measure the problem. Do a noise audit. Find out if in your organization there is as much noise as has been found in other organizations, and then try to estimate how costly it is. And actually one way of estimating it is by comparing it to bias, how costly a bias would be of the same magnitude and then maybe people recognize there is a problem and will want to do something about. 
LEVITT: So I really loved this book and being totally honest, I didn’t expect to. I think like many people, I carry this feeling inside of me that noise just isn’t that important. And ultimately, you convinced me in many of the settings — but I have one criticism of the book that I want to ask you about, because I think whether a noise matters or not depends critically on what the consequences are to the people who face noise. So, for instance, in the insurance example that you talked about, the insurance company loses when they’re too optimistic and they lose when they’re too pessimistic because there is an adversary who will sue them and litigate and so they don’t benefit from it. But one of your leading examples is about noise in the criminal justice system. And you make the correct observation that which judge you get matters a lot for your prison term, and it even matters maybe what time of day you see the judge or whether the judge’s favorite football team won or lost on the previous Sunday. .K.. But here’s what I would say, in a system where I’m supposed to get five years in prison and sometimes I get three and sometimes I get seven. Well, I’m just about as much happier when I get three years. I mean, I’m unhappy when I get seven. So if there’s no bias as a criminal, I wouldn’t care that much about noise. And I say, wouldn’t pay that much to shift a system that didn’t have noise. How do you respond to that? Do you see the difference in why I don’t like that example nearly as well as I like the example about insurance?
KAHNEMAN: Your attitude is unusual, I would say. For most people it would be an essential aspect of justice that similarly situated people will be treated identically, so that’s a principle of fairness. You want two people who have committed the same crime to get the same sentence, so you surprise me.
LEVITT: So I think people are confused. One, I think they’re thinking about bias, and so if they hear that one person got seven years and one got three, they’re very concerned that maybe it happened because the one who got seven was African-American, the one who got three was Caucasian, O.K. And obviously, that’s a huge, huge concern and pervades criminal justice. So I think that many people who are responding to the noise in the criminal justice system are actually fearful that the noise is something other than noise.
KAHNEMAN: Well, suppose that the sentencing system would go as follows, you get evaluated by a judge, he sets a sentence, and then a lottery is run, that adds or subtracts one or two years in prison from the sentence that the judge said. Would you think that, that system is desirable or acceptable or tolerable? I mean, life is unfair, but the justice system should not be unfair.
LEVITT: In this setting, bias is really worrisome. I think bias in criminal justice undermines our societal values. But noise — I mean, I’m just actually thinking about myself as, imagine myself being sentenced, how upset would I be if I knew that I would get two years longer because I was male or because I was over the age of 50? I would be furious about that. But if you said, hey, we’re going to give you either exactly five years or an average of some draw between three and seven? I don’t know — personally, I just wouldn’t care that much about that kind of noise.
KAHNEMAN: I think few people would take that bet, but I’ll say something else. Noise is produced by biases. That is the individual judge that you are encountering has a way of thinking that is different from the way of thinking of other judges, and in that sense, you can speak of each judge as biased in a particular way.
LEVITT: Maybe I’m being way too much an economist. Let me give you another example, so let’s say when I went to the store, there was a particular store, and instead of giving me back my exact change, they had a randomizing device where they either rounded up or they rounded down to the dollar, so that I never got back my right change. I always got more or less. But it was fair, they didn’t cheat me — like, it wouldn’t drive me away from that store. It wouldn’t bother me at all. Might be kind of fun to have that element of shopping. Like, I think that’s another case where, I think I view that as a little bit like the criminal justice system, where if I benefit as much from the good stuff as I’m hurt by the bad stuff, then I tend not to worry about noise.
KAHNEMAN: In your particular example, if the store does this regularly, then it’s a repetitive game and that’s completely different. But imagine a world in which some of the people will be selected completely at random, at red lights and either given a thousand dollars or be fined a thousand dollars for no reason whatsoever, you wouldn’t want such a world. My sense is that the sentiment that I represent is more common and that a noisy justice system where the sentence you get would be plus or minus four years is really intolerable, but, interestingly enough, it’s the system that judges like, they like the noisy system. When there was an effort to impose uniformity in sentencing, judges hated it. So, I don’t think I agree with you on the morality of it, but the fact is that we all live with that system which is extraordinarily noisy.
LEVITT: Yeah, I think another psychological reason why getting rid of noise is valuable, is that the people who get lucky, who get three years instead of seven years, they don’t actually appreciate that they got lucky. They think it was because they deserved it, and the people who get seven are furious, they’re outraged, they have newspaper articles written about them. And it has the sense of undermining how society functions. 

KAHNEMAN: Barbara, you’re making noises. Sorry about that. I think there was some banging in the kitchen.
LEVITT: So I would love to go back and talk a little bit about history, Danny. So you and Amos Tversky more or less created what became the field of behavioral economics from scratch in the 1970s. For those who aren’t familiar with behavioral economics, in your own words, what is that field?
KAHNEMAN: Well, we were important in a field that is called the psychological study of judgement and decision making. It became behavior economics when economists became interested in it. And now behavior economics is populated by economists who know some psychology and psychologists who have been teaching themselves some economics — mainly it’s really applied social science. And it’s the study of human characteristics, and in order to interact with humans, and this is what governments have to do, organizations have to do — we’ve got to understand them, and behavior economics is really an attempt to understand humans, so that you can interact with them better.
LEVITT: So old school economists also thought what they had were models of humans, but I think the old rational models of humans — the point that you and Amos, and later others have made is that those models are actually terrible predictors of how people behave in the real world.
KAHNEMAN: Well, yes. Really economics is a logic of decision making and then you have the assumption that people behave logically and people don’t. So when you do the psychology of how people actually make judgments and actually make decisions, they don’t follow logic. They’re not stupid and they’re not irrational, I hate the word irrationality. People are quite reasonable, but they are not logical. 
LEVITT: And I don’t think, Danny — I appreciated you enough when we were spending a lot of time together. I knew you were brilliant because I observed it, and I knew about behavioral economics, but it was only more recently that I really went back and I looked at the body of knowledge that you were creating in the 1970s, and you and Amos had a gift that I really cannot understand in that over and over and over, you figured out how to take an incredibly complex situation, to ask simple questions in which people would make very predictable mistakes and change the way academics and eventually the general public thought about the problem. How did you do it, over and over and over?
KAHNEMAN: Well, I mean, basically, we were studying ourselves. We were spending hours every day together and we were inventing problems where although we knew the correct answer, we would be tempted to give the wrong answer. And we were looking for problems for a single question that would tell a story, so that people who make that mistake — you know something about the way they think. Actually, it was that feature of our work, the fact that we had very simple questions that gave it some impact across disciplines, because I don’t think you could get economists interested in psychological experiments. But when it had the character of a riddle, then everybody finds riddles interesting.
LEVITT: Yeah. Essentially, you were academic storytellers in a way that’s very unusual.
KAHNEMAN: Yeah. I mean, we asked some people, how much would you pay — that was in the period where there was acid rain that was polluting the lakes, so, it’s about 40 years ago. This was in Canada and we asked people, how much would you pay to clean one lake from acid rain pollution? And we asked other people, how much would you pay to clean up all lakes in Ontario from acid rain pollution? And people gave roughly the same number. And that’s caused difficulties for some interpretations of people’s attitude to public goods.
LEVITT: So let me ask about that, Danny, because why in the world would you think to ask that question? Why did you think that people would be so bad at distinguishing between a single lake and an entire province? Because to me, that’s such a far-fetched result I couldn’t have imagined asking in the first place.
KAHNEMAN: Well, actually, it’s a fairly straightforward psychological prediction. Psychologists think that — we think in terms of prototypes. So when there is a category, we have a prototype in mind. And so the prototype for cleaning pollution is cleaning one lake. That’s the prototype, and you have an emotional reaction to the prototype. And when I tell you, “Think about cleaning all lakes in Ontario,” you make that into a prototype. So those two questions are much more similar than they appear. And if you’re a trained cognitive psychologist, that’s not a surprising result.
LEVITT: Well, it’s a good thing we have psychologists and economists, because an economist in a million years couldn’t have made that leap. So I see the huge influence of psychology on economics. Has economics likewise had an enormous impact on psychology?
KAHNEMAN: No.
LEVITT: Why do you think that is?
KAHNEMAN: Well, because economics depends on psychological assumptions. There are assumptions about who the economic agent is, and you need those assumptions in order to make economic predictions about markets’ work. So you need to make assumptions about people. Psychology does not depend on economic assumptions. So clearly, psychology is more of a foundation, a discipline for economics than vice versa. Where economists are clearly far better than psychologists is in their methods. And I think that there is some influence of economics on psychology in terms of rigor, but I think in the background, the way that economists do things has been quite important.
LEVITT: So, you know, there’s come to be a tremendous focus on using behavioral economics to create behavior change, to get either yourself to do something you don’t want to do or get someone else to do something they don’t want to do, whether it’s the U.K. Nudge Unit or Angela Duckworth and Katie Milkman have their Behavior Change for Good. I would say, I am approached by a company once a week that says, “Hey, we would like to use behavioral economics to try to make our customers, our clients, do something different.” But by and large, it seems to me empirically that the expectation about what behavioral economics can do for behavior change has outpaced the reality. Is that your view, as well?
KAHNEMAN: Absolutely. The successes of behavior economics are small, and typically what you can accomplish with behavioral economics is a small change that costs virtually nothing. Changing behavior is extremely difficult, and there are many optimists in psychology, but in behavioral economics, I think people are fairly reasonable about what they’re expecting and they are not expecting to be able to make big changes quickly.
LEVITT: Yeah, I really think it’s a corporate mindset. I think because of books like Thinking Fast and Slow, you’ve managed to convince lay people that behavioral economics is the most powerful tool one has ever encountered. I mean, persuasion is such a hard thing to do, but you’ve been very persuasive.
KAHNEMAN: I mean, you’re absolutely correct if you’re implying that we’ve been too persuasive. There are different particular areas where you get very substantial effects, but in many areas you want to achieve change and it’s extremely difficult. 
LEVITT: So the author, Michael Lewis, wrote a book published in 2016 called The Undoing Project, which is the story of your remarkable collaboration with Amos Tversky. Did you read the book?
KAHNEMAN: Of course.
LEVITT: How did it feel? It’s a very intimate book describing the, I would say, the surprisingly complex relationship that you and Tversky had.
KAHNEMAN: It’s a true story, and there is an element of fiction so that when somebody writes a story, you dramatize it. There is more contrast, there is more conflict. Especially, he made Amos and me more different than we were. I mean, I collaborated with this book willingly. It’s true, it was complex, it was the most significant relationship in my life and it changed my life completely, but there were some difficult times.
LEVITT: I know whenever I read a story written about me or when I’ve written about other people, there’s a tendency to react very strongly to small details that others wouldn’t notice. So, for instance, Dubner and I wrote about an economist who sold bagels and donuts, and we wrote a long, very flattering profile. And when it came out, he was outraged because Dubner had noted in the piece that as we drove down the highway, he was going 72 miles an hour. And he was furious, “I never drive more than 70 miles an hour.” When nobody else would care about that at all. Did you have any of those moments reading this book?
KAHNEMAN: Yes, of course.
LEVITT: Any you remember you want to talk about? Any particular things that really set you off?
KAHNEMAN: No.
LEVITT: I know, I don’t like to talk about the ones that embarrass me. Was it an easy decision to cooperate with Michael Lewis? I could imagine reservations.
KAHNEMAN: Well, no, it wasn’t easy. Barbara Tversky was Amos’s widow and she and I are living together now. So she was banging in the kitchen. And the basic story, which Michael describes, were that when we came to the United States, Amos got a disproportionate amount of credit for the work we did, and then he died in 1996. And from that time, I have gotten a disproportionate amount of credit for the work that we did, by a lot. And my understanding was that, you know, there had to be some redress, and I felt that I was duty bound, to tell the story in a way, you know, I didn’t control the story in detail, but it brought Amos back into the picture in a way that the Nobel Prize, that I had gotten alone because he was no longer alive, all of that had created distortion that needed correcting.
LEVITT: That’s interesting, I hadn’t thought about that, but I do think that it is a wonderful piece of history for people to understand. And for me, it was really eye opening. I mean, among other things, Danny, we spent so much time together and I had never done the math to think about the fact that you must have spent your youth as a Jew in Europe during World War II, and I feel incredibly bad about the fact that I never asked you about that. It must have been awful.
KAHNEMAN: You know, I survived. And relative to many others, I had an easy war. It wasn’t actually easy. But, I survived. And I don’t attribute anything of what I’ve done to the difficulties of my childhood.
LEVITT: I get the sense you don’t like to talk that much about the past and the difficulties, which is what’s interesting, that so much of it comes out in the Michael Lewis book.
KAHNEMAN: I mean, you know, the collaboration with Amos Tversky was a fascinating chapter in my life. You find the person who is not exactly a soul mate, a mind-mate, and with whom you have an enormous amount of fun and you are doing creative work and you know, you’re doing good work and you’re laughing all the time. It was an exceptional collaboration. It was the luckiest thing that ever happened to me, and I was happy to talk about. 
LEVITT: So I’m curious, why did you write Noise, Danny? I understand why you wrote Thinking Fast and Slow, because that was an unbelievable tome that really collect so much knowledge into one place that might have been hard for people to find otherwise. But you’re not as young as you used to be, you could have done so many things with your time. What drove you to want to create this book?
KAHNEMAN: Actually, you know, it was a collaborative effort. So Olivier Sibony and I and another friend, Dan Lovallo, we started out thinking about what could be done to prevent noise. And they were consulting for McKinsey. We met, we did something together, and the book really started from that. It started from the idea of how would you advise organizations to cut down on noise — and here my age played a role. If I had been younger, I would have started to study noise, I would have run experiments. But I was too old to do that. So the only thing we could do, really, was to write a book.
LEVITT: What motivates you, Danny? I’ve never really been sure.
KAHNEMAN: Curiosity, really. And what mistakes have I been making? That I’m very curious about. I like changing my mind and I have plenty of occasions to change them.
LEVITT: Why do you think you like to change your mind when virtually everyone else fights desperately to cling to what they believed yesterday?
KAHNEMAN: I mean, it’s interesting that for me, when I change my mind is the pure experience of having learned something. That’s when I’m sure that I’ve learned something. Yesterday, I was stupid and now I’ve seen the light. And so that’s the experience of changing one’s mind, and if you view it that way it’s quite pleasant.
LEVITT: So you’re 86-years-old, Danny, and still, obviously to anyone who is listening to this conversation, as sharp as you’ve ever been, do you have any advice for people who aspire to stay mentally fit as they age?
KAHNEMAN: You know, this is really a case of use it or lose it, and that was one of my reasons for wanting to write the book, was that it would use my mind. And it’s been very good for me. When you keep thinking you deteriorate more slowly.
LEVITT: So what, if anything, would you tell a young person that might help them to make choices that would lead to a life worth living?
KAHNEMAN: You have to follow what you are inclined to do, and you have to be willing, if you’re a scientist or if you’re a researcher, you have to be willing to discard ideas that don’t work. And if you find yourself very obstinately sticking to ideas that don’t work, you’re in the wrong profession. That’s one piece of advice that I would give, but otherwise I don’t believe in giving advice.

LEVITT: Wait, there was something that wasn’t in the book, Danny? I thought everything was in that book.
KAHNEMAN: Well, there were a few things, but certainly I cannot remember any of them. 
 
Interview 14. Masters in Business (Bloomberg, 2021):

RITHOLTZ: My extra special guest this week is Daniel Kahneman, he was awarded the 2002 Nobel Memorial Prize in Economic Sciences which he shared with Vernon Smith for his empirical findings, the work he did with Amos Tversky and what’s so fascinating about that Nobel Prize is that Danny is a psychologist, the work they did challenged the prevailing thoughts in economic theory by establishing a basis for common human errors.
His previous book “Thinking, Fast and Slow” was the bestseller of 2011 and won a variety of different awards including the National Academies Communication Award for best creative work, his latest book is just out, “Noise, a Flaw in Human Judgment” which Danny Kahneman wrote with Olivier Sibony and Cass Sunstein, Danny Kahneman, welcome back to Bloomberg.
DANNY KAHNEMAN, AUTHOR, NOISE A FLAW IN HUMAN JUDGMENT: I’m delighted to be here.
RITHOLTZ: You always say “Call me Danny” and I always feel awkward and I feel like I should call you Professor, but let me just get that right.
KAHNEMAN: I insist. Call me Danny.
RITHOLTZ: All right, Danny. So let’s start very basically, what is noise, how does it happen and where does it come from?
KAHNEMAN: Okay, well the term noise is an accepted term in statistics, we talk about statistical noise which is an ability and that is where it comes from, we talk about noise with measurement which is unreliability in measurement or measurements that should be identical to not vary (ph).
So that is the background in the use of it. As we use it specifically, we intend – we speak about judgment noise and this is the situation in which judgments should be identical, people or the same individual judging the same object a different time to different people judging the same object if they don’t agree and are expected to agree, we speak about judgment noise. And in general, people are expected to agree when they’re trying to be accurate.
So when you have a group of people trying to make the best guess about the quantity, it could be the sentence that somebody should get for a crime, it could be the value of the company, it could be the premium that somebody should be charged or it could be a diagnosis — a medical diagnosis.
In all these cases you might have several people looking at the same information making judgment, if they don’t agree, there is noise, and noise is the topic of the book we wrote.
RITHOLTZ: So it’s fascinating how we start to see noisy decision-making come up over and over again in the same fields and you just mentioned a few, medicine, criminal justice, finance, are there certain fields that are more susceptible to problems in expert judgment than others or is it just that the results of those sort of noisy decisions are so much more significant than other fields?
KAHNEMAN: Well, we used the word judgment when there is room for reasonable disagreement. That is, you know, we don’t use the word judgment for computation and when computation is appropriate, we wouldn’t be talking of noise, we would be talking of people making mistakes.
And we talk about noise when it’s a matter of judgment and so the existence of noise by itself is not a surprise, what is a surprise is amount of noise, it is just a lot more than would be expected., and here I think the best way to explain this is to tell you the story of how I started to work on noise that where the whole thing began.
So I was consulting in an insurance company seven or eight years ago and I had the idea of running today what we would call a noise audit that is underwrites to take one example we had several underwriters saw some realistic cases, the same cases, they were constructed by executives experts in underwriting so they were completely and you might have 50 underwriters looking at the same treatment.
Now nobody would expect the numbers to be exactly the same, but I ask executives if you take a pair of underwriters at random, by how much would you expect them to this in percentages and as you take the average of the pair, you take the difference, you divide the difference by the average, what percentage looks reasonable to you?
And their answer typically was 10% and we have by the way – we have surveyed hundreds of executives since then and 10 percent seems to be what we expect a reasonable difference to be which is tolerable when two people make judgments of the quantity.
Now, the correct answer among underwriters in that company was 55% more than five times as much as expected, that is the phenomenon, so we expect disagreement where judgment is involved, we just don’t expect that much disagreement.
And this basically was the observation that started us that path of writing a book because it turns out that your find astonishing amount of disagreement when you look for it and you find it wherever judgment is involved.
So engineers who make estimates on the basis of objective beta, they don’t have a problem of judgment but to the extent they do have a problem of judgment, you would expect a lot of noise. So that is the basic finding.
And wherever precision is important, wherever it is important to get to the right number, noise is the source of error…
RITHOLTZ: So let me…
KAHNEMAN: Some people overestimating and others underestimating, they are making errors.
RITHOLTZ: So let me roll back to that insurance company which you discussed in the book and there were two particular areas wherewith there were these broad disagreements, the first was when people were trying to estimate the risk involved with some insurance and so how you price that very much determines if you’re too expensive meaning you think it’s a high risk, you’re not going to win the business and if it’s too cheap relative to the risk, well you will win the business but it won’t be profitable, the cost will be higher and then on the other end in the appraisal of hey what are the damages here figuring out how much something should be covered by insurance, what the dollar amount is, and the same situation, you can’t be too stingy or you lose customers but you can’t be too generous where you give the house away, how significant a financial issue was this for the insurance company?
KAHNEMAN: Well, you know, it’s not easy to estimate that exactly but I can tell you the question that I ask some executives. I said suppose there is a correct number, say for the underwriters, and you have somebody who overestimates underwriting cost by 15%, how much would you expect that to cost the company?
And the same question for underestimating by 15% and in fact 15% on either side is much less noise than we had discovered, but people estimated on that basis that this could be in the hundreds of millions or billions of dollars, this is a very large company.
So, underwriters have a lot of important decisions to make, claims adjusters make important decisions, which are really consequential for the company, and areas or the magnitude that we observe are costly. The main reason that they may be less costly is that if error is present in all insurance company, if all insurance companies are noisy then some of the damage to each individual company will be reduced, but that’s the best that we can say.
RITHOLTZ: Well, one would imagine the insurance company that could reduce noise would find itself at a competitive advantage.
KAHNEMAN: Absolutely.
RITHOLTZ: There was something you had written that really stood out to me. There was an assumption when you have noisy systems and everything from criminal justice to medicine to insurance, that these errors tend to cancel out, but you found out that noisy systems have errors not only do they not cancel out, they tend to add up. Explain.
KAHNEMAN: Well, if you have two separate underwriters estimating the same risk and you average their ratings, then the average will be usually more precise than the individual judgments because errors in measuring the same object do cancel out, but errors when you’re responding to different objects do not cancel out.
So, if you overprice one policy and you underprice the — another policy, that doesn’t cancel out. You’ve made two mistakes. And, you know, it’s the same thing with two — these two judges if one defendant is punished too much and another defendant is punished too little. On average, you know, punishment was right, but who cares about the average? Two mistakes were made. So, there is some confusion because people think about canceling out, but that happens when people evaluate or judge or measure the same thing there, and — and errors do cancel out.
RITHOLTZ: I recall a book a couple of years ago called “The End of Average” that looked at that exact issue and said, you know, we — we tend to look at these averages as if anyone is experiencing an average, but what you’re really saying is, hey, if it averages out to be the right answer, it means you have a lot of wrong answers.
KAHNEMAN: That’s right. Averaging out to the right answer is not a guarantee, and that this is a nice example of the phenomenon we’re discussing in the book, the — the neglect of noise. People really tend to focus on bias, which is the average error, but you can have a zero bias and a very poor performance if you have a lot of overestimates and a lot of underestimates.
RITHOLTZ: Quite interesting. So, one of the things in the book that I was so taken by had to do with the Admissions Committee for university, and they used to have all the admission officers do a blind review and get together and trying to hash out who they thought would be a good fit for the school and who wouldn’t. But it led to a problem and they started having the first person who — who reviewed the application, put their review number on the corner like they would actually put their rating on the page and then hand it off to the second person. And you described this as “the illusion of agreements in organizations.” Tell us about that.
KAHNEMAN: Well, you know, this is an experience with any teacher has had, for example. When you are looking at a test booklet, the student has written several essays. If you score a test booklet, you score the first question, then the second, then the third, then in general, you’ll find that your grades adopt very, very much.
On the other hand, if you read the same test across all students and write the score at the back of the — of the booklet so that you don’t know when you read the second question with the first question was, you will often be shocked by the discrepancy between the first and the second.
There is a mechanism by which people, if you gave a good grade the first time, you are going to be inclined to give the benefit of the doubt to the student if there is any ambiguous answer, exactly the same thing happens in deliberations and in the example that we gave. And the Admissions Committee used to operate in what we consider the correct manner, and that is everybody would individually make their judgments and then they would reveal all judgments together and average them. But they change the system so that now people spoke in sequence.
And the question was asked, why do you do this? This is not optimum. And they say, “Well, we used to do it the other way. We used to have people prepare their judgments individually, but there was so much disagreement that we stopped.”
(LAUGHTER)
And that’s an example where people manage to avoid finding out how much noise there really is because when the — when people are allowed to influence each other or influence themselves, in the case of the teacher reading multiple booklets, when — when judgments are not independent, they are less effective statistically. You just have less information.
Think of the example in which the first person to talk is the CEO and then everybody agrees. Then the agreement of other people is not informative. In fact, you had one person making the judgment. That’s the extreme of abolishing — of eliminating the appearance of noise without eliminating the reality of them.
(COMMERCIAL BREAK)
RITHOLTZ: So, it sounds like groups and corporations, institutions, schools. They seem to amplify noise. Is that just the nature of bigger numbers of people working together that they’re going to create additional noise?
KAHNEMAN: No, not necessarily. What happens in a group if they made their judgments individually is not that noise is amplified, the true noise is revealed. So, suppose you had underwriters, suppose you had multiple underwriters judging routinely every — every risk, then the optimal procedure would be to have them making independent judgments and only then — then revealing the two judgment and averaging them. That’s clearly the optimal procedure.
RITHOLTZ: Sure.
KAHNEMAN: And — and the optimal procedure reveals noise and then — but uses it by averaging. But when a single individual makes a judgment, that judgment will be noisy. And when individuals are allowed to influence each other, then it’s more like a single judgment than it is like having multiple judgments to the same object.
RITHOLTZ: So you used the phrase “naive realism.” What — what does that mean relative to noise in groups?
KAHNEMAN: Well, what naïve realism means is — is a statement, which most of us — most of the time that we think we’re right. We think we have the right view of situations. We think we understand things correctly and showed we — we see the world as the world is. That’s naive realism.
And if I see the world as it is and — and all their friends and colleagues looking at the same world, and I like and respect them, then naturally I assume that they see the world as I do because I see it right. And if I respect them, they see it right as well. So that’s naive realism, and naive realism prevents us from becoming aware of the amount of noise that there is. We just assume noise away.
We saw that but very nicely among underwriters. You know, when you interview an underwriter, what happens to them? But how does an underwriter become expert in the absence of any feedback because they don’t — they don’t get any feedback from reality about their underwriting. And what happens is that they become increasingly confident and largely because they agree with themselves.
So when you agree with yourself a lot and you think you are right, and you make judgments with increasing speed and confidence so that makes you think that you’re even greater, that’s naive realism allowing massive noise to occur with everybody convinced that they are doing the right thing but, in fact, they may not be doing the right thing because if they were looking at the same problem, that would be different.
RITHOLTZ: Quite fascinating, so we become familiar with a particular area. That familiarity leads us to think that we’re developing an expertise. We tend to make more snap judgments. And without any sort of feedback loop, how can we possibly know that we’re right. And yet, that absence of feedback seems to strengthen people’s self-confidence. Do I have that right?
KAHNEMAN: That’s right. And think of a number of situations in which exactly there’s hope (ph) — there’s a judge who doesn’t have feedback as to whether a judgment was correct or not. They’ll judge. Sometimes there is feedback, but it’s asymmetric, so a bail judge may get feedback on somebody who was released and committed the crime. But a bail judge will never know if somebody was incarcerated, would have committed the crime. So, feedback is a massive problem and many professionals at the minimum feedback, and yet they become confident and they feel they’re experts. But in those cases, there is a high risk of noise.
RITHOLTZ: And a lot of that feedback seems to be only at the extreme. A — a bridge collapses there, a plane crashes, somebody dies. There’s someone out on bail commits a crime. What about all of the — for lack of a better word — near misses where there is a bad judgment. Something happens, it’s not quite as terrible as a — as an airplane crash, and it — it’s resolved before there’s damage, but it’s pretty clear the basic judgment was wrong. How does that affect a person’s future judgment?
KAHNEMAN: Well, in situations with their own near misses, there is an opportunity to learn. And in well-run — you know, well-run airlines and — and air traffic systems keep track very closely of near misses because those are their opportunities to learn without — without tragedies,
But in many situations, you get no feedback at all. And the idea of having senses in bridges that gives you a sensitive measurement of how much stress there is, that is fairly recent. They used to be very poor feedback of — on whether a bridge would collapse or not, and in many situations that professionals make judgment on, there’s no feedback at all.
RITHOLTZ: Quite interesting. So, let’s talk about this book, which was a collaboration. What was it like working with those two gentlemen versus “Thinking, Fast and Slow,” which I kind of get the sense was you sitting down and putting a lot of your previous work into a context for public consumption.
KAHNEMAN: Well, writing fast and slow was mostly a very lonely experience and writing with collaborators was really a pleasure. So, it was — it was a relief to be able to count on people to find mistakes to correct them. And — and a lot of the text was actually written by Olivier and by Cass. I had a lot to do with outlining and with critiquing and with rejecting drafts, but I was steered much of the things that I’m most afraid of in writing. So, it was a very good collaboration.
RITHOLTZ: That’s good.
KAHNEMAN: And, by the way, we benefited a lot from — from COVID because that forced us into quite an efficient way of collaborating. We used to visit. Olivier would come to New York from Paris, and I would visit Paris for a few days every month, and we had a very good time, but it wasn’t productive. Zooming one or two hours a day turned out to be a much better way of writing the book, and — and and this is what happened.
RITHOLTZ: It sounds like it was just a good excuse to get together in — in New York and Paris and have a little bit of fun.
KAHNEMAN: Well, I mean, you know, we didn’t think of it as a good excuse, but it turned out that we’d waste a lot of time in a fair amount of money.
RITHOLTZ: So, you — you mentioned you reviewed a lot of manuscript from Olivier and Cass and rejected stuff. You and Amos, very famously, would agonize over every sentence in all of your publications. You seem to have spent a lot of time writing meticulously and very thoughtfully. How has that evolved overtime? Is this a little easier to sort of be the orchestrator and the editor as opposed to, you know, just agonizingly putting down every single word?
KAHNEMAN: No, it isn’t. I mean, my — this is part of sort of my intellectual personality or character that I think most clearly when I find flaws in existing text, and I am not good at anticipating the flaws. So, I see a flaw and I correct it, and then there is new text, and then I discover a new flaw. And — and I tend to work that way, which is infuriating for my collaborators …
(LAUGHTER)
… and — and wish for a lot of time and effort, but that’s the way I am. On the other hand, I do tend to be very critical in most of the flaws that I find do exist, so it — it tends to lead to a good project in a very inefficient way.
RITHOLTZ: So, despite that perfectionism, you know, we all evolve overtime. As you were preparing “Noise,” did you find any of your previous writings or research that you either disagree with or see from a different perspective or light when you’re putting this book together?
KAHNEMAN: No, not really. I mean, in the book we actually relied on ideas from “Thinking, Fast and Slow,” but the book is really fundamentally different. “Thinking, Fast and Slow” was a book about individuals and about how — and it was a book about the average or a typical individual, and how the average or typical mind works.
No, this is about the individual differences, it’s about the way that the different people think differently. And so, this is a really different cut about thinking. It’s a different way of looking at thinking. So, we did use some of the material, but there — “Noise” is not the revision of “Thinking, Fast and Slow,” it is about a truly different topic that we didn’t even touch in “Thinking, Fast and Slow.”
RITHOLTZ: And clearly, it goes in a very different direction and it looks at some systems and some organizations that I don’t believe you touched on in “Thinking, Fast and Slow.”
KAHNEMAN: That’s right.
RITHOLTZ: It’s kind of interesting because we’ve already talked about medicine, and criminal justice, and finance. There was one section I was fascinated by where you discussed hiring and promotions and how — I don’t want to use the word “random,” but how much noise is in that system and how unreliable many organizations’ hiring processes are. Tell us a little bit about that.
KAHNEMAN: Well, it turns out that people like hiring, interviewing people and — and, for me, general image of the individual that they are thinking of hiring. And it turns out this is not a good way of doing it. A much better way of doing it is what is called a structured interview or a structured process where you accumulate information systematically about different characteristics of the person.
That is less pleasant. It’s — it’s less enjoyable, but much better. And better yet is having several — several people do the hiring, each of them forming an independent impression and then they discuss — then they average and then they discuss the average. And this is the procedure, for example, (inaudible). And it’s about state of the ark (ph), but many places are way short of state of the ark (ph).
I should add that state of the ark (ph) hiring doesn’t mean that you’re guaranteed a perfect fit. There is so much — there is so much luck in the world, there is so much uncertainty that the person that you hire may be very good, that they run into difficulties with — with the boss doesn’t like her or something like that. And by chance alone, you can get a lot of variety.
Chance, by the way, is not noise. Chance is something that happens in the real-world. Noise is differences among judgments.
So, hiring is, by and large, really very poorly done. And it’s very poorly done because it doesn’t control noise.
RITHOLTZ: Quite fascinating. So, the book goes over how noise affects judgment and how it introduces a variety of errors into our institutional decision-making process. What can we do to improve that process?
KAHNEMAN: Well, in the book, we — we introduce a concept that we call “decision hygiene”. And, you know, the word is not particularly appealing, but it’s intended to bring to mind the image of washing your hands.
And there is a contrast between debiasing (ph) and decision hygiene. Debiasing is like medication or like vaccination, it’s specific to a particular disease. When you wash your hands, you don’t know what germs you’re killing. And if you’re successful, you’ll never know.
So, decision hygiene is oriented to improving decision-making and avoiding errors, specifically, avoiding noise, but incidentally also avoiding bias without knowing precisely what biases you’re trying to control. And we have a variety of procedures that we think of as decision hygiene.
RITHOLTZ: Give us a few examples. What — what are some of the procedures if …
KAHNEMAN: Well, I will give you an example that has to do with decision-making. So, suppose you are making a decision and the first step everyone will tell you is you have to consider your options and have the best possible set of options.
But now you come to evaluate options, how do you do that? And here actually, our advice, we have a slogan. We say options are like candidates. You should think of options in the same way that the organizations are in — are advised to operate when they hire candidates. And we were talking about that earlier. Structure the thinking, break up the — each options, look at the various aspects of it, make — assess these aspects in a fact-based way, which is the equivalent of interviewing somebody about this aspects or character or — or experience. And then create a profile of old information you have about that option, and only then invoke intuition.
So, there’s a key principle of decision hygiene. It is not to avoid intuition all together, but to delay it because intuition is way more effective if it is preceded by a period in which it will accumulate information systematically. So that’s an example. I have many others, but …
(COMMERCIAL BREAK)
… (inaudible).
RITHOLTZ: And there were quite a few in the book. There were some things that really surprised me about that decision-making process, how people’s moods affect their decisions. Even the weather affects decision-making. We are essentially different people at different times.
KAHNEMAN: Oh, yes. That is — there are different sources of noise that we — we talk about, so there are three of them actually and that one of them is what we call within person noise, and that is that the individual is in indeed making different judgments depending on circumstances that they’re irrelevant. So, it’s true there is evidence that mood really affects the way that people think. People tend to be more creative when they’re in a good mood, but they tend to be also more gullible and they are more critical when they’re in a bad mood. So, mood affects the way we think and it also affects — we’re more prone to see good things when we’re in a good mood.
Mood is important. There is evidence that judges who pass sentences on criminals are more severe on hot days, and they are more severe if their football team lost the game last Sunday. So, there are a lot of irrelevant events or circumstances that influence our — our judgment. This is one of the three major sources of judgement.
Let’s get to the other two. What are the other two sources of …
KAHNEMAN: Well, one other, which is easy to think about — that’s very easy to think about it in terms of judges, some judges are more severe than others. So, their sentences, on average, are more severe than the sentences of other judges. That’s one aspect.
And the same is true by the web underwriters. Some underwriters write large premiums on average and other underwriters write small premiums, on average, so there are differences for that client.
But it turns out that the biggest source of noise — and that came as a surprise to us. The biggest source of noise are that people really don’t see the world in the same way. So, the different judges have different things in crimes and some things in criminals. So, they — somebody maybe particularly severe about repeat offenders. Somebody else might be extremely lenient, say, about white-collar crime, but really upset by violence.
And it turns out that there is — we call that a pattern noise that is each judge — each individual has a pattern of judgments, which are — this is different from the pattern of judgments of other people, and that is the major source of noise. And people were consistent in that way.
So, for example, suppose you’re a judge and somebody remind you of your daughter, whether that makes you more lenient or more severe, probably more lenient. Now on another day, that same person would also remind you of your daughter. So, this is not noisy within the individual, this is a characteristic of the individual, but no other judge shares it. And it turns out that this highly case-specific at distances and attitudes that are difficult to pin down, they are noise. Judges have personalities and judgments differ as much as personalities do.
RITHOLTZ: And then what is the third source of noise that you identified …
KAHNEMAN: Well …
RITHOLTZ: … in the book?
KAHNEMAN: That — those are — the three are differences in average level for a judge is severity; differences in taste, what we call pattern noise; and within subject — within person variability. We call that occasion noise because, on different occasions, you make different judgments. And it’s the sum of these three sources of noise that — that creates — that’s the noise that we observe.
RITHOLTZ: So …
KAHNEMAN: So, in a system, all three operates on any particular judgment.
RITHOLTZ: So, I’m going to ask the question I was thinking about a little differently based on what you just said. What fields seem to manage reducing noise better than others? And are there any fields that are so especially susceptible to noise?
KAHNEMAN: That’s a very good question to which I do not have a very good answer because, you know, in our work we — we found noise wherever we look for it. It mean our summary conclusion is wherever there is judgment, there is noise and more of it than you think. You know, this has — this has been our conclusion. So, we haven’t found places that control noise very efficiently.
The only way, by the way, to get rid of the noise — and that’s really quite important — is average judgments. Think multiple judgments of a case and average them. And this mechanically eliminates noise. If you have enough judgments, the average may be biased because averaging does nothing to reduce bias, but it eliminates noise. So that’s a sure fire away of eliminating noise of averaging multiple cases.
RITHOLTZ: Very interesting. Let me throw a curve ball at you. If you were designing a system to introduce noise, to short circuit human judgment, what would you create to make judgment less effective, noisier?
KAHNEMAN: I don’t think it would do things very differently from the way that they adapt in many institutions now. I would — I would let people make individual judgments without feedback. That’s — that’s all that’s needed. Make their individual decisions without feedback, which is a situation that’s very common, and that will create a lot of noise eventually.
And noise is reduced by a feedback. Sometimes it’s the feedback or other people, so case conferences can be arranged to some extent control noise. But, you know, you — you don’t have to try very hard to create a lot of noise. I think the existing organizations do very little to control noise.
RITHOLTZ: So, let’s talk a little bit about ways to control noise. And you describe a difference between rules and standards. Tell us about that.
KAHNEMAN: Well, standard is a way of — when you say, for example, that you — obscenity is something that you recognize, so there is a standard to avoid obscenity, but you do not define it. That’s a standard.
A rule is more precise than that, and it tells you specifically what you have to do. And rules, if followed, they are like computations. A computation is a — is a rule. And rules tend to eliminate noise. Standards sometimes reduce noise, but standards would not eliminate noise because they are vague.
RITHOLTZ: So — so the seven words you can’t say on television is a rule, but pornography, I know it when I see it is a standard. Is — is that the different?
KAHNEMAN: Precisely, precisely.
RITHOLTZ: Quite interesting. So — so given all of the work you’ve done over the years, all of your research, you seem to have continually identified flaws in cognition, flaws in — in human judgment. Has this affected the way you view other people? Do you — do you turn around and say, wow, these — the species is a terrible decision-making apparatus or is it something less comprehensive than that?
KAHNEMAN: No. I’ve — I’ve — actually for all my career, I’ve — I’ve been interested in intuition and intuitive thinking. And I’ve been interested and that’s a lecture I used to give for good many years — intuitions, marvels novels and flaws because intuitions is marvelous — intuition is marvelous, but it’s also flawed.
And it’s true that I have found it more interesting to study the flaws of intuition than its marvels. And there is a — a lot to do to correct the flaws of intuition. But to say that this is turning to a pessimist (ph) whether they dislike people because their minds are flawed, I think the minds are pretty marvelous, but they are certainly far from perfect.
RITHOLTZ: Right. So — so you’re focusing on the small bits that we get wrong, but overall, we manage to navigate through life pretty effectively.
KAHNEMAN: Well, we certainly manage to navigate through life. And, you know, it — it would be absurd to focus on the flaws of human beings when you see what they are capable of. On the other hand, if you want to do things better, then you’d better focus on the flaws rather than what is going well.
RITHOLTZ: You know, one of the things you said when we spoke last about “Thinking, Fast and Slow,” I asked you about your own investing process. And you said despite knowing everything that you know about human decision-making, you still catch yourself making the same sort of mistakes that everybody makes. Is that still the case? Do you still feel that way?
KAHNEMAN: Oh, yes. I mean, you know, I’ve been at it for more than 50 years. And I’m really not better than I was.
In general, my thinking has been that it was true when I wrote “Thinking, Fast and Slow”, which was focused on the individuals, that the — the hope of improving thinking is in organizations because organizations thinks slowly and they have procedures. And it’s by imposing procedures by adopting procedures that you can improve things. And in the case of “Noise,” we have a procedure that we recommend to get started, and that’s measured noise.
If you are in an organization where you have multiple people making the same judgment and no very good feedback, conduct what we call a noise audit. Give them the same problem and look at their solution. We predict that you’ll find more noise than — than you think you will. That’s — that’s our prediction. And that’s — that’s a recommendation to organizations. It’s not something that you can recommend to an individual.
RITHOLTZ: Quite interesting. I have to ask you before we get to our favorite questions, what’s the next project? What’s the next book look like? What is tickling your curiosity these days?
KAHNEMAN: Well, I’m — actually I’m back to a topic that I was working on 20 years ago. I — almost by accident, I’m back studying wellbeing. And I’m involved in several research projects. None of them is as big or ambitious as “Noise” was and “Thinking, Fast and Slow,” but all of them are quite interesting, so I’m not bold.
RITHOLTZ: I can’t picture you bored because you always seem to have a lot of different things going on. Let me ask my favorite questions that I ask all of our guests. And let’s start with what are you doing to stay entertained during this pandemic lockdown? In addition to working on the book, what are you streaming? What are you watching on Netflix, if anything?
KAHNEMAN: Oh, I’ve been watching several series — several very good series. Let’s see, the last ones — there is a political series on Netflix, the Baron Noir, which is a French political thriller that is very good. There is a Danish political series, Borgen, that is very good.
I am now watching Babylon Berlin about Berlin in the 1920’s, which is excellent. And so, I do my watching mainly while I exercise, and I exercise a fair amount, but so I’ve — I’ve seen a lot of series since — well, from — for the last two years.
RITHOLTZ: Baron Noir was the French one. What was the Danish one?
KAHNEMAN: Borgen.
RITHOLTZ: Yeah.
KAHNEMAN: Borgen is great. Actually, the Danish one, Borgen is a thriller. It’s a Scandinavian thriller. There is a Danish one about the — a woman prime minister, and it’s not Borgen, and I am now blocking its name, but it will be easy to find. And I really recommend it. It is superb.
RITHOLTZ: All right. I will — I will check that out. So, let’s talk about your early mentors. Who helped to shape your career? And I guess, we have to include collaborators in that as well?
KAHNEMAN: Well, I mean, there’s been one major influence on my career, and it was Amos Tversky. The collaboration with him completely changed my life and — and it changed the way I do things, but — and it gave me a — yeah, it changed my life. And it was the best period of my life, too, professionally.
(COMMERCIAL BREAK)
RITHOLTZ: The thing I recall from Michael Lewis’ “Undoing Project” is that people said you guys would lock yourself into an office or a classroom, and all they would hear all day long is peels of laughter coming from within. Is that true? Is that an exaggeration or did you guys …
KAHNEMAN: No, that’s really not an exaggeration. Amos and I work very closely together for about 12 years. And we spend many hours a day together. And he was funny. He had an excellent sense of humor, and he loved laughing. And in his presence, I also became funny, so we were amusing each other. And the field that we studied was — was one that was conducive to laughter because we were looking for mistakes in our own thinking.
And to trap ourselves or to see that you are tinted to make a stupid error, that is quite funny. And that’s the game that we engaged in in studying judgment and studying decision-making was looking for errors in our own thinking, and that was very amusing.
RITHOLTZ: I can imagine. So, let’s talk about books. What are some of your all-time favorites? And — and what are you reading right now?
KAHNEMAN: Well, I would say my all-time favorites of recent years was “Sapiens.” I think it’s many people’s favorite book by Yuval Noah Harari. I read it twice, which is something that I rarely do.
And right now, well, I’m reading the new edition of “Nudge,” which is coming out, I think, in August and it’s called “Nudge: The Final Edition” by Dick Thaler and Cass Sunstein — the same Cass Sunstein. And — and it’s quite different from the original “Nudge,” which appeared I think in 2008. And it’s what — but it — it — it had the same characteristic that “Nudge” had. That’s why that it’s funny.
RITHOLTZ: Right. Dick said it’s about two-thirds new, and I think that’s August 4th that comes out.
KAHNEMAN: Yeah, that’s right. So that’s …
RITHOLTZ: Right.
KAHNEMAN: … I happen to be reading that right now.
RITHOLTZ: August third, I’m looking at a message from him. He’s — he is a very amusing person to begin with. And if — if you’re telling me the book is funny, then I am really looking forward to — to reading that.
KAHNEMAN: Oh, the book is — you know, he just — he can’t help himself. He is funny all the time. He is my best friend, my best living friend.
RITHOLTZ: Let me ask you this question. If a recent college graduate asked you for some advice if he was interested in a career in either psychology or behavioral finance, what sort of advice might you give him or …
KAHNEMAN: Well, you know, I — I tend to refrain from advice because I don’t believe I have a crystal ball into the future. I can tell you what I would have been doing if I was starting today. The fields that are very exciting from my perspective are neuroscience, including neuroeconomics, which is the — the — the neuroscience of decision-making and artificial intelligence.
I mean, in those two areas, right now, there are extraordinary developments, very exciting. And so, when you see that — and they are attracting massive talent, both areas, so you know that for the next decade or so there will be (inaudible). A lot is going to happen. And what happens after that, I have no idea.
RITHOLTZ: And — and our final question, what do you know about the world of psychology, behavioral finance, economics today that you wish you knew 50 or so years ago when you were first getting started?
KAHNEMAN: Oh, well, so much has been learned. You know, if I — I can’t say that I wish I had known earlier what — what has been so much fun to find out over the years, both in my work and in the work of others. So, I can’t think of a thing that would’ve made me act differently. But all I can say you — to you is oh, yes, things have really changed since I’ve been in that field.
RITHOLTZ: Quite fascinating. Thank you, Danny, for being so generous with your time. We have been speaking with Danny Kahneman whose new book “Noise: A Flaw in Human Judgment” was co-authored with Olivier Sibony and Cass Sunstein.
 
Interview 15. Issues in Science & Technology (2022):

During the pandemic, people have had to make elaborate risk assessments to decide whether to visit loved ones, or send their kids to school, or sometimes just leave the house. How did you see the phenomena that you’ve explored in your work—our intuitive and effortful ways of thinking and our mental shortcuts and biases—operating in the context of the pandemic?
Kahneman: Well, the first thing that was very salient at the beginning of the pandemic was that people really find it difficult to deal with exponential growth. I recognized this in myself. I was about to take a flight to France when there were just a hundred cases in France; that didn’t look like much, except it was doubling every couple of days. And that was really quite powerful.
What we’ve seen since is that people think about risk a lot, but it doesn’t look as if we have a very explicit idea of what those risks are. And I’ve been struck by the role of emotion, which I hadn’t emphasized in my previous work. Some people are very afraid and other people are much less afraid, and it’s the level of fear that seems to dominate behavior. You have people who have barely gone out over the two years and other people who have exploited every opening and every opportunity. And that looks more like a different emotional response than a different risk calculation, because we haven’t had much material to really make calculations.
In Thinking, Fast and Slow, you wrote that you weren’t generally optimistic about the potential for individuals to control the cognitive biases that send our thinking off track. In the decade since that was published, have you seen any evidence or intervention that has convinced you otherwise?
Kahneman: No, not really. I mean, there have been some published successes, but they were fairly minor. Not all that much has happened. Again, my optimism with respect to the ability of individuals to improve their thinking is limited. As I think I said in Thinking, Fast and Slow, I have more confidence in the ability of institutions to improve their thinking than in the ability of individuals to improve their thinking.
That brings us to your more recent work on noise, which you define as unwanted variability in judgments that should be identical—for example, when different judges hand down dramatically different sentences for the same crime, or doctors make different diagnoses for the same patient. How did you get interested in noise? What convinced you that this is a big enough problem that it needed public attention?
Kahneman: Well, I had an experience with an insurance company where I ran an experiment—the kind of experiment we now call a noise audit—where we presented the same cases to a large number of underwriters and we asked them to set a premium for these cases. Now, nobody would expect two underwriters looking at a complex case to arrive at exactly the same number. Underwriting is a matter of judgment, so you’d expect some disagreement.
I tried to identify how much disagreement people would tolerate by asking the executives: If you took two underwriters, by how much would you expect them to differ? And there is a number that comes up more frequently than any other, which is 10%. This is not only for underwriters; it seems to be a general number, that where judgment matters, 10% variability seems tolerable.
But in fact, among the underwriters the variability was closer to 50%—five times as much expected, and that is qualitatively different. I mean, if there is that much variability in the underwriting system, you should go back to the drawing board, because clearly they’re adding a lot of noise.
And the other thing that is important is that this was completely new to the people I talked to. The organization had a very large noise problem and was completely unaware of it. It’s really that combination—of there being noise, and people not being aware of it and not recognizing it as a problem—that made it tempting to do something about it.
In what systems did you and your coauthors find high levels of noise? Where do you think noise showed up in the worst way?
Kahneman: Well, we found noise wherever we looked for it. Where I personally found it the most shocking is in the justice system. And that is an extraordinarily interesting case because there is huge variability among judges in terms of the sentences they are imposing for the same offenses. And yet judges really do not want to be made to be uniform. It seems to strike very deeply—the possibility of enforcing or even suggesting that uniformity is desirable is already quite threatening.
What do you think is driving that reaction?
Kahneman: In part, there really is a tradition that justice is something determined by an experienced individual with high ethical standards and understanding of the norms of society. Justice is whatever that individual decides with full, complete knowledge of the circumstances, and no other individual who doesn’t have that information can make judgments about it. The judge is like an instrument for determining what is just. And once you threaten that—and the idea of noise really threatens that—then it becomes very difficult, I think, for judges to reconcile themselves to the situation.

It’s also the case that if the extent of noise in the judicial system were something that people talked about a lot, then people would lose respect for the justice system. But it’s not talked about a lot. And it’s quite remarkable, there are few efforts to do anything about this in the justice system.
And then, of course, there are things that are not part of the justice system but operate in similar ways—so, asylum judges, patent officers, reviewers of grants, and even teachers who grade students in ways that determine their future. Noise in all those systems seems to potentially be the source of unfairness.
In other institutions, in insurance companies for example, it’s clear that noise in underwriting is costly, and it leads to decisions that are not good for the business. I’m more hopeful about reducing noise in business than reducing noise in the judicial system. But you asked me what shocks me most—it’s there.
With regard to the justice system, one of the objections people have to making sentencing more uniform and less noisy is that judges really need to be allowed to take into account the particulars of a case. Are there ways to lessen noise in the justice system while still allowing for that to happen?
Kahneman: There are circumstances where very clearly you have a critical piece of information that’s a deal-breaker, and clearly deal-breakers should be allowed. You don’t want a system that doesn’t allow for those. What is insidious are aspects of the situation that are not by themselves deal-breakers but that people have intuitions about. Then we see that the weight that people give to the information is really not optimal, and that’s where noise comes in.
The quality of people’s decisions in many cases doesn’t increase consistently with the amount of information that they have. There are some items of information that help, and then it reaches a point where more information is actually more likely to make you go astray than to add to the quality of your decisionmaking.
It turns out that people really do best with a small amount of information, and that when they begin to consider the details and the complexities of the individual case—except if it’s a deal-breaker—they’re likely to give improper weight to insignificant matters.
What are some examples of practices that organizations can use to reduce noise?
Kahneman: I think the book is, in an important respect, premature. That is, in general with an idea of this size, there should be at least 20 years before you publish a book, because there’s a lot of research to be done. Now as it happened, I was 80 when I had that idea, and so I didn’t have 20 years. When we speak of what we call “decision hygiene,” which are procedures that hopefully will reduce noise, a fair amount of that is speculative—that is, it hasn’t been tested through research. It’s backed up indirectly—we didn’t completely invent things out of our head—but there is a lot of work that needs to be done to establish those things. So, that’s sort of a confession.

Given that, we do have ideas about procedures that are better than others, and the main example in my mind was a contrast between structured and unstructured hiring interviews. Unstructured interviews are when interviewers do what comes naturally. The structured interview breaks up the problems into dimensions, gets separate judgments on each dimension, and delays global evaluation until the end of the process, when all the information available can be considered at once.
We know that neither structured nor unstructured interviews are very good predictors of success on the job, which is extremely difficult to predict. But within those limits, the structured interview is clearly better than the unstructured one.
If you think of decisions, then decisions involve options, and you can think of the options as similar to job candidates. That means that each option has attributes, and you want to assess those attributes separately. And we expect that approach to have the same kind of advantages that structured interviews have over unstructured interviews.
So, the most important recommendation of decision hygiene is structuring. Try to design an approach to making a judgment or solving a problem, and don’t just go into it trusting your intuition to give you the right answer.
One method you’ve considered to reduce noise is through the use of algorithms. But there have been a lot of concerns raised about their use in decisionmaking, in particular that they might amplify racial and gender biases. How should we weigh the benefits and risks of using algorithms?
Kahneman: Well, I think that there is widespread antipathy to algorithms, and it’s a special case of people’s preference for the natural over the artificial. In general we prefer something that is authentic over something that is fabricated, and we prefer something that’s human over something that is mechanical. And so we are strongly biased against algorithms. I think that’s true for all of us. Other things being equal, we would prefer a diagnosis to be made or a sentence to be passed by a human rather than by an algorithm. That’s an emotional thing.

But that feeling has to be weighed against the fact that algorithms, when they’re feasible, have major advantages over human judgment—one of them being that they are noise-free. That is, when you present the same problem to an algorithm on two occasions, you are going to get the same answer. So, that’s one big advantage of algorithms. The other is that they’re improvable. So, if you detect a bias or you detect something that is wrong, you can improve the algorithm much more easily than you can improve human judgment.
And the third is that humans are biased and noisy. It’s not as if we’re talking of humans not being biased. The biases of humans are hidden by the noise in their judgment, whereas when there is a bias in an algorithm, you can see it because there is no noise to hide it. But the idea that only algorithms are biased is ridiculous; to the extent they have their biases, they learn them from people.

A famous example is, I think, an attempt to measure and predict crime in different areas. If the measure of crime is arrests, then you’re going to end up with something that is grossly racially biased because arrests are grossly racially biased. So typically, the biases are introduced into algorithms by human decisions about how to define the problem. But if you take care to define the problem properly, the algorithm is not going to invent biases.
What about the concern that rules intended to reduce noise might also reduce creativity and ingenuity? How might that happen? Are there ways to reduce noise that won’t have that effect?
Kahneman: Well, I think there is a real risk that when you produce procedures that guide judgment and decisionmaking, and that makes it more homogeneous and more uniform, the risk is demoralization and bureaucratization. No question, that risk exists. And so reducing noise without demoralizing people—that’s a skill that has to be acquired, and clearly that’s a constraint on the implementation of noise reduction techniques.
Whether noise reduction will impair creativity or not, I’m really not sure. And that is because you really want to create a distinction between the final decision and the process of creating that decision. And in the process of creating a decision, diversity is a very good thing. When you’re constructing a committee to make decisions—whether of hiring or of strategy—you do not want people to come from exactly the same background and to have the same inclinations. You want diversity. You want different points of view represented, and you want different sources of knowledge represented. In some occasions increasing diversity in the making of the decision could reduce noise in the decision itself.
The real deep principle of what we call decision hygiene is independence. That is, you want items of information to be as independent of each other as possible. For example, you want witnesses who don’t talk to each other, and preferably who saw the same event from different perspectives. You do not want all your information to be redundant. So, good decisions are decisions that are made on the basis of diverse information.
You mentioned that a lot of research still needs to be done about noise. What are some key questions that you would most like to see answered?
Kahneman: Well, I think the most urgent questions are about mitigation, and they’re about really verifying decision hygiene and improving our recommendations and testing them. That would be the first thing I would hope would happen.

Then, it would be very interesting to study, I think, individual differences in judgment, in different kinds of judgment. Where do the differences come from, and can they be anticipated?
And what is the real value of experience? Experience always increases confidence, and experienced people have more confidence in the quality of their judgment. But this is true even when they get absolutely no feedback from the environment about the quality of their decisions. So, underwriters never know whether they set the right premium or not, and yet they become more confident. Now, how do people become more confident? Well, it’s when they begin agreeing with themselves. That’s basically the criterion that, “Oh, I had a similar problem and that’s what I decided then and I feel like deciding the same thing now.” And that gives people confidence that they’re doing the right thing—with absolutely no objective justification.
Also, studying what we call “respect-experts”—that is, what distinguishes those people who become well-recognized experts in the absence of objective feedback? Trying to understand that phenomenon is interesting.

 

Interview 16. Max Raskin Interview (2022):

Max Raskin: I'm reading Amos Oz’s book about his childhood and thinking about what heady times it must have been for you to be in Israel at that time around those people. So where I want to start is with Yeshayahu Leibowitz. Was he influential in your intellectual development?
Daniel Kahneman: Oh yes, he was bigger than life. I knew him quite well because when we first came to Israel and I was in eighth grade, his son was my best friend, so I was often in their home. He was an amazing character with multiple PhDs and an MD – a very abrupt voice and quite impressive and charismatic. I had him as a teacher in high school as a chemistry teacher.
MR: Wow. Where did you go to high school?
DK: I went to high school in Jerusalem.
MR: What was the name of it?
DK: At that time, it was called Beit-Hakerem High School but now it's the Hebrew University High School and known by the Hebrew word for “near,” because it is attached to the university.
I also had him as a teacher when I went to university – he was teaching physiology. His lectures were so inspiring and exciting that I remember going to a lecture with a temperature of 103 or 104. It was something that you never wanted to miss. It was that good.
MR: And he wasn't lecturing on anything religious?
DK: No, no – he was not. He was religious but I think he wasn't a believer. But I never knew the religious side of him.
MR: Wasn’t he a famous theologian?
DK: He became mostly famous in Israel for his opposition to the occupation, and he was extremely eloquent and used phrases that shocked the public like “Jewish Nazis.”
MR: …and “diskotel” [a portmanteau of discotheque and Kotel (the Western Wall)].
DK: He had a very big following on this issue because he was one of the first, and he was very extreme in his choice of words and quite unafraid of offending. He didn't care. He was morally very brave. And at the same time, he was very decent.
MR: His sister was also a famous thinker.
DK: Yes, she was. I think she was a biblical scholar.
He had interests in everything. I should say that part of the humor of his physiology class is that while I found it absolutely fascinating, later I realized I don't think he was right. 
He had something that was very striking – I still remember it almost 70 years later. He would draw the sensory nerves to a center and then there were motor nerves going out – and then there was a huge question mark in the middle, and he would almost break the chalk. I still remember the sound of the chalk hitting the blackboard. He was an extraordinary figure.
MR: Were there any other people in that category? In that Oz book, he talks about Bialik and Agnon…
DK: If he talks about Bialik, Bialik was dead by then.
MR: But that milieu of early Zionists and refugees – I guess I was thinking from the early 30s until the early 50s.
DK: Well, we were all very caught up in patriotism at the time. The period of the war was very threatening and also exhilarating – I still remember. It started in November ‘47 with the UN decision for the partition.
MR: Do you remember where you were?
DK: Yes. I remember that – I remember dancing in the streets, which is what happened.
MR: Were you in Tel Aviv?
DK: I was in Jerusalem in November ‘47. There was a siege of Jerusalem, but my mother and I escaped to Tel Aviv. My sister remained there, and she fought in the war. We didn't know all the things that have become known in recent decades about what the Jews did to the Arabs and the expulsions and so on. At the time, we swallowed everything that we were told – it was a purely defensive war and quite heroic – which it was in many ways.
MR: Did you ever meet Ben-Gurion?
DK: No, I never met him, but he was a heroic figure, an epic figure. I still remember my cousin – who later was president of the university, but he was 11 at the time – asking me whether Ben-Gurion goes to the toilet. It seemed so strikingly impossible.
MR: I think Montaigne has this quote that’s like, “On the highest throne in the world, man still sits on his ass.”
DK: He was bigger than life. It was very exciting. I remember episodes from that period including the day on which the state of Israel was announced – the 14th of May. I went with my cousin to row on the Yarkon – the river in north Tel Aviv. That was the afternoon on where this was happening…I was 14.
MR: Were you partying?
DK: No, that was just my cousin and I, but it was really very festive that day. There was a sense that the memories of the Holocaust were still very much on peoples’ minds. I had come to Israel from France where we had spent the war years. The contrast between being a hunted rabbit during the war and fighting for ourselves – it was a huge thing for me and for many others.
MR: Do you have any habits from the war years that stay with you? My father is a surgeon, and he always ate very quickly because of when he was training as a resident. Do you have anything like that? Do you eat quickly? Do you hoard food?
DK: No. No.
MR: That's interesting.
DK: It was a somewhat different childhood than others, but it was nothing compared to what others suffered.
MR: Was it a purely secular Zionism?
DK: It's mostly secular. There were the ultra-religious who were not Zionist, and they were largely segregated and largely ignored. They have hugely increased in numbers in Israel and have become a potent political force, but at the time they were not. The religious Zionists were just part of the movement. They were wearing yarmulkes, but they were otherwise on the whole quite moderate. I remember growing up with a sense that religion had one generation to go and then it would disappear because all the people I know were less religious than their parents, who were in turn less religious than their parents. Extrapolating from those two generations, I thought this was it. I distinctly remember that thought from my adolescence.
MR: There's two kinds of people in the world. There's those who can extrapolate from limited data sets…
________________________________________
Rabbi Kahaneman
MR: Let me ask you this, were you ever religious in your life?
DK: No. I went to a religious school. My uncle on my father's side was one of the most famous rabbis in Israel.
MR: Who was it?
DK: He was called Rabbi Kahaneman…you can find him on Wikipedia, there is a lot about him there. There is the Ponevezh Yeshiva in Bnei Brak, and that was his. So he was religious and my mother's family was also moderately religious.
I went to a religious school in my first year in Israel. We arrived in 1946 and until we escaped in early 1948, I was in religious school. And actually, I was still in religious school in Tel Aviv for a year, but I lost my faith.
MR: You studied Gemara and Mishnah?
DK: Yes, I did, but not intensely.
MR: Did you believe in God at the time?
DK: I must have believed because I remember very precisely the moment at which I stopped believing in God.
MR: When was that?
DK: I must have been 15, and I remember where I was because it was very sudden insight.
MR: Where were you?
DK: I was in Jerusalem, and I remember where.
MR: Where was it?
DK: I was walking home, and I had the insight that maybe I could believe in God, but I could not believe in a God that cared whether or not I masturbate. That was a very sudden insight. That if I can't imagine God caring about me, then we were irrelevant to each other, and it really didn't matter whether he existed or not. And that was the end of the religion for me.
MR: Do you believe in an afterlife?
DK: No.
MR: Nothing?
DK: No.
MR: And no reincarnation?
DK: No. There's nothing mystical.
MR: Do you meditate?
DK: No. I'm not really spiritual in any significant way.
MR: Do you play chess?
DK: I do. Not very well, but I did, yes.
MR: Do you have a favorite opening?
DK: Oh, don't ask me it's been decades. I play the King’s Gambit.
MR: I play the King’s Gambit!
________________________________________
A Scribe in Jerusalem
MR: What’s the most difficult thing you do nowadays in terms of intellectual activities?
DK: I still do research and it's quite difficult. I try to understand papers – I find that difficult.
MR: “Judgment under Uncertainty” – it’s a very short paper. Do you think that the quality of paper has changed since you were writing?
DK: In what ways?
MR: I feel with more specialization, people can't write papers like yours anymore. Do you think that's right or no? I could be totally wrong.
DK: Nobody could write that paper – that paper was unique. And the reason it was unique was that it was very different in format from other papers. The reason it was influential – all of that is really an accident. 
I was very influenced as an undergraduate by the Gestalt School. Those were people whose books were full of illustrations like illusions or figure-ground effects that were supposed to work on the reader so that the reader was a subject. If you look at our work, we did this thing.
MR: It's a joy to read.
DK: What makes it work is that the reader is a participant, the reader is a subject. You get those puzzles, and they work on you. That is unique – not in terms of uniquely brilliant, but there is just no other topic on which you can do that. We happened to hit on a topic that permitted these things.
MR: Did you write the initial draft in English or in Hebrew?
DK: Everything was in English.
MR: The writing is beautiful and it’s just a pleasure to read. Are there any writers that influenced you?
DK: Nothing of which I'm aware. Amos [Tversky] and I wrote every word together, and we spent a lot of time on every sentence. And we really tried not to have a superfluous word. The prose doesn’t flow because every word was chosen. We spent almost a year writing those five pages. We did little else.
MR: Where would you actually write?
DK: There is a place in Jerusalem called the Van Leer Institute. It's a lovely place – it’s sort of the center of intellectual life. The director of it was a friend of mine and he gave us a room that we could work in.
MR: Did you write it by pen?
DK: By pen. I was the scribe, usually. Amos would sometimes edit and then he would work in pencil.
MR: How do you write today – by pen or on a computer?
DK: No, I write on a computer.
________________________________________
Subject as Subject
MR: Did you know you had something special right after you finished it?
DK: What do you mean by special? We thought it was good. We had no idea of how significant it would turn out to be. And the reason we didn't was that it was adopted as part of what was called later, the Great Rationality Debate. That is a debate on the rationality of people, but I don't think the word “rationality” is there in that paper.
MR: You say you don't like the term irrational.
DK: We don't like it at all. Because I think it's a complete misunderstanding. To claim we were studying irrationality – we absolutely were not. All the examples that we deal with were examples that worked on us. It’s just that we knew better because we had thought about the statistics. But every intuition that we described was an intuition that we found appealing, and we never thought we were irrational or stupid or anything like that. I really hate that word. And the word “rationality” in my mind is a technical word. It describes logic, and people cannot be rational in that sense anymore that they can speak perfectly grammatically. Obviously, they don't.
MR: Do people ask that of you? There’s all these cognitive biases and heuristics that exist – do people ask if you think you’ve graduated beyond them?
DK: It's a question that I often get, and I tell people that my thinking has not improved in all the years that I’ve been doing this.
MR: When you write do you listen to music?
DK: I used to for many years until I found that it actually distracts me.
MR: Do you listen to music today?
DK: No, very little now. For years I spent the whole day listening to music.
MR: What would you listen to?
DK: Schubert was my favorite and Mozart.
MR: The early days of Israel with all those refugees who were just brilliant musicians – the philharmonic must have been incredible. The fifth chair could have been the first chair anywhere else.
DK: Actually, the big development in Israeli music was when the Russians came. The Russians came and there were hundreds of violinists and orchestras. Violinists and mathematicians. That was a big change on the musical scene.
________________________________________
Nobel Nod
MR: Your new book is a collaboration with other authors. In your life you've really collaborated with people.
DK: I've done almost nothing by myself. I've always collaborated.
MR: Seeing you and Tversky – it looks like Lennon and McCartney.
DK: We've been compared to them. That's a compliment.
MR: This book that was written, The Undoing Project – what is it like to have a relationship with someone dramatized?
DK: It's mildly unpleasant.
MR: Are you surprised at the folk hero status that you've attained? 
DK: Oh, sure. I mean, I never anticipated it. It's not something that's really part of how I live. I don't live it every day.
MR: Where were you when you found out about the Nobel Prize?
DK: Home. Some people are surprised, but I think many people are not surprised. And in fact, many people wait by the telephone because they know when it's about to happen and they know they're shortlisted.
MR: Were you surprised?
DK: No.
MR: You got a tip off?
DK: No. There was an audition a year earlier, which was clearly an audition. It was convened by the Nobel committee – it was a workshop in behavioral and experimental economics with participants. It’s not just the candidates but the whole cast of people who have been influenced by the candidates.
MR: When you got the call, what was your first thought? Do you remember your emotional state?
DK: Of course I remember – everybody remembers those things.
MR: I don't remember those things.
DK: Everybody who's had that experience remembers it. My wife and I were waiting and then the call didn't come. I remember I was writing a reference letter for someone, and my wife went to exercise and then I got the phone call. They really take care so you'll know it's not a prank. I forget the exact detail, but they make sure that you’ll believe them. And then I went to the bedroom where my wife was exercising, and I told her I got it. And she said, “You got what?”
MR: This is a silly question, but do you jump up and down?
DK: No, but it's a big deal of course.
________________________________________
Lieutenant Kahneman
MR: You mentioned remembering the establishment of the State of Israel. What other historical events in your life are blazed in your memory?
DK: It’s not historical, but for me my military service was a very important period in my life in different ways. I was in the infantry for a year and that was sort of an antidote to being a Jew.
MR: Were you a good infantryman?
DK: Yes. I was a lieutenant. I was quite good.
MR: Were you athletic?
DK: I was in very good shape then. I'm not an athlete – Amos was more athletic than I was, but I was in very good shape, yes.
MR: Do you exercise now?
DK: Yes.
MR: What do you do?
DK: I have a cardio glide. It's not quite like a rowing machine – you push with your feet and pull with your arms.
MR: Do you exercise every day?
DK: Yes – I do that for 40 minutes a day when watching thrillers.
MR: What thrillers do you watch?
DK: Right now, I'm watching an Islandic thriller, Trapped – it’s very good.
MR: What are some thrillers you love?
DK: Breaking Bad. There’s The Sopranos. 
MR: Who’s your favorite character in The Sopranos?
DK: The hero.
MR: Did you like Hitchcock?
DK: Not particularly, no. I would say I'm a fan of French films right now. There is a French-speaking spy series called The Bureau – the first two seasons are wonderful.
MR: What do you read in the morning for your news?
DK: The New York Times, and then I get the feed from the Washington Post that ruins my life because I look at it too often – I get their opinion pieces that stream all day long – opinions and news.
MR: You don't turn it off?
DK: I'm thinking about it.
MR: That's funny.
DK: Yes. I'm not a very disciplined person.
________________________________________
Kahneman and Tverskys
MR: Why do you like thrillers?
DK: Always have.
MR: Were there any moments in the army when you were very scared?
DK: I was in scary situations.
MR: Are you cool under pressure?
DK: Yeah.
MR: Was Amos like that as well?
DK: Oh, he was altogether exceptional in those respects.
MR: Do you think about him every day?
DK: Well, yes. His widow and I live together.
MR: I interviewed Barbara!
I think of her research as more physiological and it’s like your early research on pupil dilation, which was very physiological. Do you still think about that at all?
DK: Oh yes. It turns out that there's a big resurgence of interest in that. I wrote a book almost 50 years ago now called Attention and Effort, which was based on that work. There’s a lot of interest in those topics – including the pupil – over the last 15 years or so.
MR: Which ads it looks at.
DK: Well no, it's mainly as an indication of mental effort.
MR: Do you and Barbara ever talk about your work together?
DK: Yes, of course.
MR: That must be a lot of fun. 
She's very cultured – and I don’t want to insult you – but she is very high brow in her taste, and it seems like you have the same tastes as me with Breaking Bad and The Sopranos. What’s that like?
DK: But I also like the theater and I also like ballet. I’m not only thrillers.
MR: Will you crack open a beer and watch sports at all?
DK: No. I used to for a brief period. Amos used to watch basketball a lot. There was a period when I watched but very little.
MR: Do you drink wine or beer?
DK: I drink wine – mostly to flavor a sparkling water.
MR: You live in New York now, correct?
DK: Yes.
MR: Is there anything you miss from Israel food-wise?
DK: Oh yeah, pickles. Pickles in brine is what I miss. Most other things we can find, but for some reason those are hard to find.
MR: Do you have any favorite restaurants that you enjoy ordering from?
DK: There’s a very good Italian restaurant that I recommend ordering from – L'Artusi.
MR: Do you like pizza?
DK: No, not particularly, but we do order a large amount of Italian food.
MR: What's your favorite? What dish do you get?
DK: Lasagna. When I have my choice, I'll do a lot of steak tartare and a lot of sashimi.
MR: This has been so much fun for me. Did I ask questions that you don't normally get asked?
DK: Yes, you ask very odd questions.
MR: You know what I do is I read someone's Wikipedia page and whatever's not on it, I want to ask about. Thank you so much for doing this. Do you have any final thoughts?
DK: There is so much.
 
Interview 17. Strategy+Business

S+B: In your classic work on inconsistencies in individual decision making, the focus seemed to be on the fact that people make irrational choices even when they have pretty good information.
KAHNEMAN: When you are interpreting old results or old thoughts, you have to think what was in the background of the scientific conversation at the time. And at that time, in the 1970s, irrationality was really identified with emotionality. It was also obvious that a lot of explicit reasoning goes on: It was absolutely clear to us that people can compute their way out of some things. But we were interested in what comes to mind spontaneously. That led to the two-system theory.
S+B: Can you describe the two-system theory?
KAHNEMAN: Many of us who study the subject think that there are two thinking systems, which actually have two very different characteristics. You can call them intuition and reasoning, although some of us label them System 1 and System 2. There are some thoughts that come to mind on their own; most thinking is really like that, most of the time. That’s System 1. It’s not like we’re on automatic pilot, but we respond to the world in ways that we’re not conscious of, that we don’t control. The operations of
System 1 are fast, effortless, associative, and often emotionally charged; they’re also governed by habit, so they’re difficult either to modify or to control.
There is another system, System 2, which is the reasoning system. It’s conscious, it’s deliberate; it’s slower, serial, effortful, and deliberately controlled, but it can follow rules. The difference in effort provides the most useful indicator of whether a given mental process should be assigned to System 1 or System 2.
S+B: How did you begin your research into the two systems?
KAHNEMAN: In our first paper, Tversky and I did a study of the statistical thinking of professional statisticians when they’re thinking informally. We found what we called the Law of Small Numbers, a term we coined in 1971 to describe how people exaggerate the degree to which the probability distribution in a small group will closely resemble the probability distribution in the overall population. And we also found that people, experienced statisticians, do not apply rules that they’re aware of in guessing the probability of statistical outcomes.
S+B: So even “good” statisticians can be “bad” statisticians.
KAHNEMAN: That’s right. When they’re not computing seriously in System 2 mode, they rely on their intuitions for the kind of simple problems we gave them. We were hoping that, where things really mattered, they would replace their intuitions with computations. Yet what was striking to us was that even people who should know better were making those mistakes.
What’s Risky
S+B: Has your perception of risk and the meaning of risk evolved or changed since you began doing this work?
KAHNEMAN: The perception of and reaction to risk previously had been seen as emotional.
S+B: Not just seen as emotional; dismissed as emotional.
KAHNEMAN: Yes, exactly right. Our innovation was that we identified some categories of risk that were the result of certain cognitive illusions. That was a novelty and that got people excited. But it’s only part of the picture. There is an alternative way of looking at this that is becoming much more fashionable. There’s a paper that I really like a lot. The title of it says the whole story: “Risk as Feeling.” The idea is that the first thing that happens to you is you’re afraid, and from your fear you feel risk. So the view of risk is becoming less cognitive.
S+B: So it’s not that generalized emotion influences decision making. It’s that one emotion — fear — distorts the perception of risk and introduces error into decision making.
KAHNEMAN: What actually happens with fear is that probability doesn’t matter very much. That is, once I have raised the possibility that something terrible can happen to your child, even though the possibility is remote, you may find it very difficult to think of anything else.
S+B: It’s like a Lorenzian imprinting of goslings: The phenomenon of fear imprints on a decision maker.
KAHNEMAN: Emotion becomes dominant. And emotion is dominated primarily by the possibility, by what might happen, and not so much by the probability. The more emotional the event is, the less sensible people are. So there is a big gap.
S+B: You’re saying that the shadow cast by a worst case overwhelms probabilistic assessment?
KAHNEMAN: We say that people have overweighted the low probability. But the prospect of the worst case has so much more emotional oomph behind it.
S+B: So even experts make cognitive mistakes. But experts and executives in organizations don’t make decisions in isolation. They make decisions in meetings and committees and groups. Do we have the counterpart of System 1 and System 2 thinking in groups as well as individuals?
KAHNEMAN: We know a lot about the conditions under which groups work well and work poorly. It’s really clear that groups are superior to individuals in recognizing an answer as correct when it comes up. But when everybody in a group is susceptible to similar biases, groups are inferior to individuals, because groups tend to be more extreme than individuals.
S+B: So it’s a positive feedback loop. In a group, you get an amplification of the extremes.
KAHNEMAN: You get polarization in groups. In many situations you have a risk-taking phenomenon called the risky shift. That is, groups tend to take on more risk than individuals.
We looked at similar phenomena in juries. You collect judgments from the individual members, then you have them delivered, and then you look at the result compared to the median judgment of the group. It’s straightforward what happens: The group becomes more extreme than the individuals.
S+B: Why does this occur?
KAHNEMAN: One of the major biases in risky decision making is optimism. Optimism is a source of high-risk thinking. Groups tend to be quite optimistic. Furthermore, doubts are suppressed by groups. You can imagine the White House deciding on Iraq. That’s a situation where it’s easy for somebody in the administration to think, “This is terrible.” It’s equally easy to understand how someone like that would suppress himself. There is a tendency and the incentive to support the group. That underlies the whole class of phenomena that go by the label of groupthink.
S+B: What about decisions relating to asset allocation and financial investments? That strikes me as a perfect playground for some of these ideas on the relative sobriety of the individual versus the extremism of the group — such as the corporate investment committee.
KAHNEMAN: No, no. They are not the same dynamics. When you’re looking at the market and investment committees, you’re really talking about the dynamics of competing individuals. We really should separate those cases.
S+B: But I’m looking at the management committee, I’m looking at the jury, and I’m looking at the investment committee, and they all seem to be weighing evidence and evaluating risk. Their similarities seem to outweigh their differences.
KAHNEMAN: I’m a psychologist, so I start at the individual level and I look at individual-level biases or errors. Then I look at the group and I say, What happens in the group? How is the group structured? What are the incentives? What do people do to each other in the group situation that would either mitigate or exacerbate risks? Then there are market things where people respond to each other.
S+B: What you’re describing is an internal marketplace where groups come to a consensus about — or at least some sort of agreement about — the risks and rewards associated with their decisions.
KAHNEMAN: That’s correct. But remember that the internal incentives that shape how the group perceives risks and rewards may be very different from the reality of the risks and rewards in the external marketplace. Those incentives can distort risk perception.
S+B: Do you think the dysfunctions of group decision making are worse than the cognitive dysfunctions of individual decision makers?
KAHNEMAN: That depends on the nature of the decision, the individuals, and the groups. But I strongly believe that both individuals and groups need mechanisms to review how their decisions are made. This is particularly important for organizations that have to make many significant decisions in a short amount of time.
Business Decisions
S+B: How much interaction have you had with business leaders about this? Do you get senior executives asking, Look, we make a lot of decisions, we have to assess risk. What insights can you give us into how to do better risk assessment as individuals and as groups? Are there ways for us to become aware of our biases, either by setting up checklists or learning how to frame things better?
KAHNEMAN: I’m very impressed, actually, by the combination of curiosity and resistance that I encounter. The thing that astonishes me when I talk to businesspeople in the context of decision analysis is that you have an organization that’s making lots of decisions and they’re not keeping track. They’re not trying to learn from their own mistakes; they’re not investing the smallest amount in trying to actually figure out what they’ve done wrong. And that’s not an accident: They don’t want to know.
So there is a lot of curiosity, and I get invited to give lots of talks. But the idea that you might want to appoint somebody to keep statistics on the decisions that you made and a few years later evaluate the biases, the errors, the forecasts that were wrong, the factors that were misjudged, in order to make the process more rational — they won’t want to do it.
S+B: Are people introspection-averse, or are they risk-averse? You’re a psychologist; you say your unit of analysis is the individual. Why don’t individuals want to know?
People look at mirrors.
KAHNEMAN: But when they have made a decision, people don’t even keep track of having made the decision or forecast. I mean, the thing that is absolutely the most striking is how seldom people change their minds. First, we’re not aware of changing our minds even when we do change our minds. And most people, after they change their minds, reconstruct their past opinion — they believe they always thought that. People underestimate the amount to which their minds have changed. Now in addition, people in general, when they have been persuaded of something, they think they always thought that. There’s very good research on that.
S+B: We’ve just lived through one of the biggest bubbles in history. We both know people who said, “I put money in dot-coms or telecoms at their peak. What was I thinking?”
KAHNEMAN: Oh, many people will admit that they made a mistake.
But that doesn’t mean that they’ve changed their mind about anything in particular. It doesn’t mean that they are now able to avoid that mistake.
S+B: So your bet, based on your study of how individuals and groups make decisions, is that the stock market bust is not going to fundamentally change how people think about risk.
KAHNEMAN: For a long time it’s going to have the effect of people getting burned by a stove. There’s going to be an effect at the emotional level, and it could last for a while.
S+B: But their mind hasn’t changed. So you think it’s an emotional phenomenon, it’s a System 1?
KAHNEMAN: I think that is entirely based on emotion.
S+B: Do we want to use Freudian, self-destructive explanations for why people rely on flawed intuitions in making decisions, rather than on their statistical expertise?
KAHNEMAN: Oh, no, God forbid!
S+B: Well, how about using evolutionary psychology? Maybe it makes sense that humans have evolved a cognitive bias toward drawing inferences from small numbers.
KAHNEMAN: You can always find an evolutionary quotation for anything. But the question is whether it’s functional, which is not the same as being evolutionary. There might be some environment in which
it’s dysfunctional, but mainly it’s inevitable.
But, you know, there’s also the issue of perception, which links to intuition. Perception evolved differently than either intuition or cognition evolved.
S+B: Now it seems like we’re dividing decision making into three systems: there’s the emotional stuff; there’s the rational-computational system; but there’s also a perceptual system.
KAHNEMAN: Yes, I think of three systems. In my current perspective, the question I ask is, What makes thoughts come to mind? And some thoughts come to mind much more easily than others; some really take hard work; some come to mind when you don’t want them.
Decision Analysis
S+B: When you began your research in the psychology of decision making, the business world was intent on making the managerial decision process as rational as humanly possible.
KAHNEMAN: The rational model is one in which the beliefs and the desires are supposed to be determined. We were real believers in decision analysis 30 years ago, and now we must admit that decision analysis hasn’t held up.
S+B: Didn’t your own research help kill it? The essence of your work seems to be the ongoing tensions and contradictions between System 1 and System 2 thinking. That makes it almost impossible for rational System 2 thinking to win out.
KAHNEMAN: That’s not quite true. Our research doesn’t say that decision makers can’t be rational or won’t be rational. It says that even people who are explicitly trained to bring System 2 thinking to problems don’t do so, even when they know they should.
S+B: Howard Raiffa, a father of formal decision analysis, basically recanted on his original work in the 50th anniversary issue of Operations Research. He argued that decision analysis didn’t have nearly the impact he felt it could have had on managerial thinking.
KAHNEMAN: And I think it’s very clear why that happened, but it was not clear then.
S+B: Does this obviate all the decision analysis courses — all the drawing of decision trees — that students take in graduate business programs?
KAHNEMAN: It doesn’t mean you shouldn’t take decision analysis. It just means that decision analysts are not going to control the world, because the decision makers, the people who are in charge, do not want to relinquish the intelligence function to somebody else. After all, in principle, under decision analysis, there would be somebody generating probabilities, and the decision makers would look at the trade-offs and decide about the assignment of utilities. In addition, the decision maker would have a managerial function, to ensure that the whole thing is done right. And that is absolutely not the way it is. Decision makers don’t like decision analysis because it is based on that idea that decision making is a choice between gambles.
S+B: That’s a wonderful phrase, “choice between gambles.” Is it more important to influence the choice between gambles, or to make a choice between gambles?
KAHNEMAN: I think decision makers, in business and elsewhere, just reject the metaphor altogether. Managers think of themselves as captains of a ship on a stormy sea. Risk for them is danger, but they are fighting it, very controlled. The idea that you are gambling is an admission that at a certain point you have lost control, and you have no control beyond a certain point. This is abhorrent to decision managers; they reject that. And that’s why they reject decision analysis.
S+B: So what should we do instead?
KAHNEMAN: That’s why you ought to think of systems. There are ways of thinking about a problem that are better than others. But I admit I’m less optimistic than I was before.
S+B: Because?
KAHNEMAN: Because I don’t think that System 1 is very educable. And System 2 is slow and laborious, and just basically less significant, less in control than it thinks it is.
S+B: What is it that you would most like senior managers who have influence over people’s lives and money to understand about your work?
KAHNEMAN: If I had one wish, it is to see organizations dedicating some effort to study their own decision processes and their own mistakes, and to keep track so as to learn from those mistakes. I think this isn’t happening. I can see a lot of factors acting against the possibility of that happening. But if I had to pick one thing, that would be it.
 
Interview 18.
 
Interview 19. 
 
Interview 20. https://time.com/6961454/daniel-kahneman-death-interview-thinking/

In the book you frame the way we think into two different systems. There’s the fast system, System One, and System Two, the slow thinking. Can you explain the difference?
If I say, "What is 2+2?" the answer comes to your mind, you don’t have to decide to do it, it just happens. But if I say, "What’s the product of 17 times 24?" probably nothing comes to your mind. Slow thinking has the feeling of something you do. It’s deliberate, it gives you a sense of agency, and you’re the author of the things you do. That’s not at all the way it happens when System One operates, when you brake a car suddenly or have an emotion.
Are there public figures who you think are typical of slow thinking, or fast thinking, or is it within all of us? All of us have the ability both for fast thinking and for slow thinking. We couldn’t survive with only one. There are people who are more obviously in touch with their emotions and who follow their gut more. You can compare the current President [Barack Obama] and his predecessor [George W. Bush]. [Obama] is certainly much more reflective and much more deliberate. And the previous one quite explicitly trusted his intuition, trusted his gut, and very much followed what System One was telling him to do.
What are the most common decision-making mistakes involving these systems? In the first place, many of the decisions we make are influenced by emotions of various kinds. We are biased to like some people and to dislike other people; we are biased by words. You’re not going to have the same attitude to a cold cut of meat if it is described as 10% fat or 90% fat-free. People actually are willing to pay more for the latter.
We all think we’re very considerate and judicious and reflective, but does System One, fast thinking, have effects on us that we just don’t even realize? System One—you can think of it as events in your mind that happened very quickly and that operate as suggestions. And then you have System Two, the slower thinking, endorsing many of these suggestions, or sort of relying on them and following up on them. They are the basis, they are the anchor, which is modified by further thinking. But the effects are still there.
You don’t seem, in the book, to be a huge fan of intuition. Is it idiotic to go with your gut? It really depends on the situation. All of us rely on intuition all the time. And most of us are very good at what we do—we couldn’t live without System One. In some situations, people have considerable confidence in intuitions that are worthless. If you are making a judgment on an impression that is based on very little information, you might want to stop yourself if the judgment is important. If you are negotiating and somebody has put a number on the table, you should be very wary, because that number looks more reasonable the moment it comes to the table.
Can we train ourselves to notice when we’re being misled by our System One, or when we’re leaning on System One when we shouldn’t be? Well, I’m not a good case study because I’ve been studying this for 45 years and my intuitions really have not improved. I don’t believe in self-help. I believe occasionally you can recognize a situation in which you’re making a mistake. My goal in the book was actually to educate gossip, because I think we are much, much better at correcting the mistakes of other people than at detecting our own. And if there was better gossip in the world, if people were gossiping more intelligently, I think decisions would actually be better. Because we do anticipate the gossip of other people. And if we anticipated intelligent gossip, it might help us.
What do you mean by intelligent gossip? Intelligent gossip is gossip about judgments and decisions that is informed by the psychology of judgment and decision-making. In order to understand a situation, you need a vocabulary and you need a set of concepts. You can’t be a physician without having names for diseases, and you need names for the various psychological effects and for the different biases, so that you can pinpoint and say, "Oh, this is a case of that." And once you have the richer language, you have much richer associations, many more ideas, and more ability to discriminate between situations. That would be intelligent gossip.
You write about the fire captain who can tell that the floor’s going to collapse, and he thinks it’s his gut, but in fact you argue plausibly that it’s a lot of experience. What experts should we listen to and whom should we ignore? It’s mostly what they’re talking about and whether expertise is possible in their domain. There are domains in which expertise is not possible. Stock picking is a very good example. Long-term political strategic forecasting. It’s been shown that experts are just not better than the average reader of the New York Times at making long-term predictions, and that’s not very good. That’s about like a dice-throwing chimp, for moderately difficult questions. So, if people are claiming expertise in a situation that is basically unpredictable, don’t believe them.
So we should all fire our stockbrokers? No, you should not. There is a lot that your stockbroker knows that is going to be very useful. They know about risk in general, so they know what investments are generally more risky than others. They know about taxes. They have a lot to tell you. When they’re telling you invest in this rather than in that, they’re likely to be not much better than chance.
Digital media gives us answers quickly and means that we have to work a lot less hard at System Two, because we don’t have to recall so many facts. If I don’t remember who the President of Bulgaria is, I can just ask my phone. Is that changing the way we think? It probably is changing the way we think. It probably is changing the way that we learn about the world, but I don’t really know enough to have an intelligent answer to that question.
What are the biggest mistakes that people make in thinking about themselves? In the first place, they think that other people have biases but that they don’t. We’re generally very overconfident in our opinions and our impressions and judgments. Many people—not all, but the people who make the most difference to the lives of other people—are optimistic and they have an illusion of control. And we exaggerate how knowable the world is. For example, we think that there were people who knew that there was going to be a recession. I think they didn’t know it. They thought it, and then it happened, but there were other equally knowledgeable, equally intelligent people who knew the same thing and didn’t think there was going to be a recession. So we use the word know in peculiar ways, and that strengthens the illusion that we understand the world, when we really don’t.
What can we do? All we can say is, "Gosh I don’t know anything." Does that make us stop and think, or does it just sap all the confidence out of us to do anything? Clearly you need a balance, because there is such a thing as paralysis-by-analysis and you don’t want to fall into that trap. Being more reflective when things matter is good, but on most decisions we’d better follow our intuition and not worry about it. When we’re trying to predict what it will be like in the future in particular, psychologists have demonstrated that your intuition is a pretty good guide, and if you like something now, you’ll likely like it later. If you like somebody now, you’re likely to like them later.
We’ve talked a lot about the impact of these theories on economics, but what about areas outside economics? Should we be thinking about this in terms of who we marry? Well, I should think so, yes. Knowing something about the future, not expecting that your feelings will remain exactly the same as they are now – that, I think, will be quite a useful thought to have when people marry.
You have some interesting recommendations in your book on how to interview a candidate for a job. Do you have any about how you interview a candidate for your life? I haven’t prepared a list of criteria for that, but I would say, this is a person you love now, but you are going to have to like them later. And that’s quite important.
Do you think that most success is luck? No, there’s a considerable amount of skill in success, but there is more luck than we’re generally inclined to believe. There is a whole business literature that claims to tell you that if you follow the advice of these experts, then you are going to be successful. When there are big successes, there is a lot of luck.
So somebody like Steve Jobs was incredibly lucky? Steve Jobs was very lucky in many ways. You know, he was lucky to be paired with a technological genius when he started. He was lucky a lot along the way. And then he did have a knack. And he had, really I think that is true, he had his taste. He trusted his taste, and his taste turned out to be a taste that people shared eventually, or could be made to share, and that is a genuine talent. He was lucky to be able to exercise that talent.
Does your theory have room for something like faith? How does faith play into the way we make decisions? Is it a net positive or negative, or neither? People have values that guide their choices and guide their judgments, and the values come from a variety of places, and it is not that people who do not believe in God do not have values that guide them. This being said, the sense of confidence that people have in their faith, and the idea that many people of faith have that other religions and other faiths are ridiculous on the face of it, that is strange, from a psychological point of view. And that fits reasonably well with the idea that faith is associated with overconfidence.
How big a role should fear of regret play in decision-making? Actually, there is some disagreement about that among psychologists. I happen to believe that regret is quite important. In some ways it’s absurd to regret spilt milk, you should focus on actual consequences, and that’s what economists tell you. But in fact, regret is a psychological fact of life, and if you anticipate that you’ll regret something, you probably shouldn’t do it. But to some extent you can inoculate yourself against regret. There are things that people can do so that, whatever the outcome, their regret will not be too severe. For example, just the act of anticipating it. You know you’re making a decision and you know chance is involved, and later, if the outcome isn’t good, you at least will know that you thought about it carefully. That actually does mitigate regret.
You write that the halo effect [an overall positive impression of a person or thing that is based on a single characteristic] plays a big role in who we vote for. Is there a way of mitigating against that? Well, it turns out that it’s not only the halo effect, it’s the face – it’s whether people like the face. There is a marvelous study done at Princeton where you show students pictures of politicians for one-tenth of a second and you ask who looks more competent, and that predicts 70% of the congressional elections. And it’s even more predictive for people who know very little about politics, and who just follow their gut. So being more reflective about how you use your vote is clearly better, I think.
 
Interview 21. NPR Hidden brain 

VEDANTAM: So, Danny, as I was reading that introduction, I could almost see you cringing because you've spent a lifetime worried about overstatement and exaggeration and overconfidence and luck. And I'm wondering if we could just start there. If you were to look back at your own life, how much of your success would you attribute to talent and how much to luck?
KAHNEMAN: I mean, you know, some talent was really needed. And - but luck - you know, I can see so many points in my life where luck made all the difference. And mainly, the luck is with the people you meet and the friendships you make. There is a large element of luck in that. And my life was transformed by sheer luck in, you know, finding a partner, an intellectual partner, with whom we got along very well and we got a lot done.
VEDANTAM: Before we get to Amos, I want to talk about another person whom you met. This was in 1941-42. You're a very young Jewish boy living in German-occupied Paris. And one day, you're out beyond curfew. An SS officer spots you and runs up to you. What happens next?
KAHNEMAN: Well, he doesn't run up to me, but he beckons me to him. And I was wearing a sweater. I was - it was past the curfew, and my sweater had a yellow star on it, and so I was wearing it inside out. And then he called me. And he picked me up. And I was really quite worried that he might see my yellow star. And then he hugged me tight, and then he put me down. He opened his wallet, and he showed me a little boy. And then he gave me some money, and we went our separate ways.
Obviously, I reminded him of his son. And he - you know, he wanted to hug his son, so he hugged me. That's an experience that for some reason - you know, I mentioned it in my Nobel autobiography - but as illustrating a theme that was a theme in my family actually, in my mother especially - that people are very complicated. And that seemed to be an instance of something very complicated. And so it stayed that - you know, in that sense. It's a memory that was important to me.
VEDANTAM: So when an event like that happens, I can imagine most people just saying thank God and moving on, but you found it interesting partly because you said there's something interesting that happened here. And I - and from a very young age, it seems you were drawn to these curiosities about how the mind work.
In some ways, the SS officer was making a mistake. He was looking at you and drawing an association from you to - so to another child, maybe his own son. And, of course, in many ways, it was an error. It was - the mind was not working in a quote, unquote, "rational fashion," but it was more associative.
KAHNEMAN: The complexity was that it's the combination of somebody who must have done some very evil things and had thought some very evil thoughts and yet, he was hugging me. And, I mean, you know, that kind of complexity was everywhere. I mean, Hitler, you know, liked children and liked flowers and was very kind to some people. So - and we have a lot of difficulty putting that together with, you know, the things he did. But it - that complexity was always interesting.
VEDANTAM: At what point do you feel you became the person who was paying attention to his own thoughts? Because so much - so many of your early insights were developed obviously in experiments that you ran on people, but you were also observing the way your own mind worked and observing, if you will, oddities in the way that your own mind worked. Was that always the case with Danny Kahneman?
KAHNEMAN: I think so. I mean, I - yeah, I wrote a psychological essay when I was 11. So I, you know, it was short.
(LAUGHTER)
KAHNEMAN: But, well, you know, I'll tell you what the essay said, actually, because it shows quite a few things, I think. But so my oldest sister was taking exams in philosophy, and I had read some Pascal. And, you know, Pascal explained why - gave proofs of God's existence. Pascal said that faith is God made sensible to the mind. And I, you know, a little boy of 11, very pompous, of course, I said, how right, you know.
And then the psychological part was I said but this is very hard. The experience of faith is very rare. And so that's why we have churches and organs and pomp to sort of - and I called it air zaps - I mean, the sort of fake experience - generated, fake experience. So that was - you know, that was psychology. And obviously, you know, that's what interested me then, and it's interested me since.
VEDANTAM: Later on, as you were working as a professional psychologist now, you made, in some ways, a career of thinking about how your own mind worked. And I'm fascinated by this idea because in some ways, a lot of people look at how their minds work and they're defensive about it, or they defend how their minds work. Or they say, no, I - what I did made perfect sense. And instead, in some ways, I think your humility - and clearly, it's a temperamental quality of yours - helped you to sort of see some of these oddities and think about why they happen.
KAHNEMAN: That's not quite the way it happened, actually. I had my friend and collaborator - Amos and I, we worked together on that. And nobody ever accused him of being humble. He was not.
(LAUGHTER)
KAHNEMAN: And - but what the two of us did - we found it - we found our own mistakes very funny. And so we had a lot of fun just exploring what is our first impulse when it's wrong. And that, you know, that can be an endless source of fun. And there was no particular humility in it. On the contrary, in a way, that is we never thought that people are stupid because we were finding all of that in ourselves, and we didn't think we were stupid. So there was very little humility there. What there was was irony. And the irony was part of the fun.
VEDANTAM: What was funny about it? I can see why it was interesting or why it was curious. But I understand that when you and Amos worked together, there was just endless amounts of hilarity.
KAHNEMAN: There was a lot of laughter. And, you know, what was fun was finding yourself about to say something really stupid and, you know, having - and sort of holding back because you know better. But it's that impulse to say things that, you know, that are without basis or that are purely associative or that - and really doesn't matter, you know, how intelligent you are or how educated you are. There are those intuitions or those thoughts that come from somewhere that come very reliably and predictably and that are wrong. So that - you know, it's a big field to study.
VEDANTAM: Meeting Amos was clearly a stroke of luck. I mean, I don't think your life would have taken the same path that it did...
KAHNEMAN: Certainly not. I mean, you know, it's rare, really. But he was exceptionally smart and very, very quick. And there is - when you have two people who are working together who really, in a way, love each other's mind and admire each other's mind, that is very special because it gives you a sort of confidence when the other - you say something and the other person sees something in it that you haven't seen.
And this is very rare, this kind of mutual trust and looking for what's interesting and good in what the other person is saying. And both he and I sort of made - we were both quite critical people, I mean, he even more than I. But we made an exception for each other, and that was a joy.
VEDANTAM: So many of your early insights were based on thought experiments where you came up with sort of very simple questions that you posed to both yourselves and to other people. Why these thought experiments? And when we talked a few days ago, you actually said that this is part of the reason you think that your work appealed to a larger audience because even if the ideas were complex, the questions were inherently interesting and accessible.
KAHNEMAN: Well, that's a stroke of luck, really. And there's a famous psychologist, Walter Mischel, who wrote a book on the marshmallows test a few years ago. And in 1964, he published his dissertation. And his dissertation was done in Jamaica with small children. And he asked those children two questions. And one of them was there is a fairy who can make of you whatever you want to be. What do you want to be? And the other question was you can have this lollipop today or two lollipops tomorrow. What do you prefer? Now, these two questions were correlated with everything in sight. I mean, they were correlated with how bright the child was, with how educated the parents were. And I just fell in love with that idea, the psychology of single questions. And I looked for ways to do that sort of thing. And the work with Amos on judgment turned out to lend itself to just that, that is there is a single question that elicits a funny thought, and it makes a point.
And, you know, the first place, we were very lucky in the truest of problem. There are just no other problems in psychology that lend themselves to that sort of thing, that you can involve the reader and present questions to the reader, and you make the reader think. So you can do that in vision. And everybody here, I'm sure, has had the introductory psychology at some point. And there are those demonstrations of perceptual effects, like figure-ground or...
VEDANTAM: Optical illusions.
KAHNEMAN: ...Perceptual organization or - and they are on the page, and that's the phenomenon. You are your own subject. Now, you can do that on vision. You can do that on judgment, which is the field that we did it in, and that's it. You know, you can't do it on self-control. You can't do it on many other things. You can't do it on personality studies. So when I was talking of luck, that's luck, I think, to hit on something that, you know, we happen to be prepared for and that is uniquely - you know, that lends itself uniquely to something that creates experiences in readers, you know, sheer luck.
VEDANTAM: So after many, many years of collaboration together, your partnership with Amos floundered, I think it's fair to say. I'm wondering whether you've given the same thought to why that happened that you gave to other things that your mind does and whether those insights - I mean, so many of your insights about how your mind has worked have helped the rest of us. Is there anything here that could help the rest of us think about collaboration and partnership?
KAHNEMAN: No. I mean, you know, there's natural stresses in collaboration. The world is not kind to collaborations. You know, when you have two people who are reasonably talented, and they work together, and they overlap closely, then - I'm quoting Amos - he said, "when I give a lecture, people don't think I need anybody else to do the work." And that was true, to some extent, in me as well.
And so that creates stresses. And, of course, I've given a lot of thought to it. We were fortunate that we went on as long as we did. We were fortunate that we remained friends, you know, even when there were stresses in the collaboration and in the friendship.
VEDANTAM: I remember research that Abraham Tesser did many years ago where he looked at couples or other pairs of people who were very similar to one another. And one of the things he found is, of course, the closer in similarity people were, the more they reached for the same goal. You had, let's say, a couple who are both writers. The success of one person tended to make the other person feel smaller. Even though you're happy for your partner, there's a part of you that says, why can't I have the success that my partner has? And it's a very human thing, of course.
KAHNEMAN: Yeah, of course. You know, and it's, of course, especially true if it's joint work, which they are. So this is - you know, there's really a dynamic, and it's - I would say we were just about perfect for, you know, 10-12 years, which is a very long time.
VEDANTAM: When we come back, what Danny and Amos discover together. Stay with us.
(SOUNDBITE OF MUSIC)
VEDANTAM: For HIDDEN BRAIN's 100th episode, I interviewed Daniel Kahneman. He's the author of the book "Thinking, Fast And Slow." In the 1960s, Danny spent a summer with a group of eminent psychoanalysts at a treatment center in Massachusetts. The center had a routine. A patient was examined for a month by multiple experts and then everyone came together to do a case study. They reviewed notes and interviewed the patient together. One particular case left a strong impression on Danny.
KAHNEMAN: In the morning, we learned that the woman, the young woman about whom we'd written the report, had taken her life. And they did a very brave thing. They ran the case study. And I was deeply impressed, both by the honesty of what they did, but what they were trying to do, they were seeing signs that they had missed. And it was, you know, in retrospect, obviously. This was hindsight at work. I mean, now you know what's happened. So you're seeing signs and premonitions and people are really feeling guilty. I saw her on the stairs and she looked strange. And, you know, why didn't I stop to inquire? I mean, you know, people look strange all the time. But, you know, when somebody - so yeah. That was - that was an important episode.
VEDANTAM: And, of course, what this episode reveals is how once an event happens, we trace back a story about how that event came to be. And, of course, in journalism, we do this all the time. You know, I remember after the 9/11 attacks, we spent years sort of deconstructing all the errors that were made and drawing a pattern. And when you see that pattern laid out, you have to say, well, those people must have been really dumb because it's so obvious that there was a pattern that led to the 9/11 attacks.
KAHNEMAN: Yeah. This is hindsight. And it's one of the most important phenomena, truly, in psychology - in the psychology of judgment because you understand the past. And the past surprises stop being surprising at the moment they happen. You know, then you have a story. And you shouldn't have been surprised. And when you reconstruct it, you also reconstruct wrongly what you believed at the time. So you minimize - you reduce the surprise. So not only was it inevitable, but also I almost - I really sensed it, so, you know.
Now, where this goes really wrong is that the stories about the past are so good that they create an illusion that life is understandable. And that's an illusion. And they create the illusion that you can predict the future. And that's an illusion. And it's maintained by hindsight. So hindsight is a central phenomenon, really.
VEDANTAM: And, of course, the errors we make eventually lead to prospect theory, which was the work which you were cited for in the Nobel Prize, among other things. If you were to explain prospect theory to an eighth grader, is there a way to do that?
KAHNEMAN: Well, it's very easy to explain. It's much harder to make it interesting. And...
(LAUGHTER)
KAHNEMAN: ...It's the theory that dominated thinking when we wrote and, to a very large extent, still dominates economic thinking. It was formulated first in 1738, so it's been around a long time. And what it says is that when you're looking at a gamble, what you are evaluating is you're evaluating two states of wealth - your wealth if you will win and your wealth if you will lose. And then if you're offered a sure thing, your wealth if you get that sure thing. And for 200 and, you know, 60 years and so, people accepted that theory.
Now, the theory really is - it doesn't make sense if you stop to think about it. People don't think of gains and losses as states of wealth. They just don't. They think of gains and losses as gains and losses. That was the fundamental insight of prospect theory. So, you know, you could ask that, you know, you get the Nobel Prize for that.
(LAUGHTER)
KAHNEMAN: And you do in a certain context because - if it surprises people.
VEDANTAM: One of the things you say in the book is our comforting conviction that the world makes sense rests on a secure foundation - our almost unlimited ability to ignore our ignorance. And, of course, you've made - spent a lifetime exploring the depths of your ignorance and all of our ignorance. But in many ways, there's something deeply human about this. To see the world as being chaotic and unpredictable and noisy is fundamentally unsettling. And it's easier to see the world as understandable and comprehensible and that fits in a story.
KAHNEMAN: Well, it's not - you know, we really have no option. I mean, the mind is created to make sense of things. I mean, vision makes sense of things. We see objects. We see objects moving. And it's the same with judgment and thinking. We have to make sense of things. And we can't do otherwise. So it's not, you know, that we would be unsettled if we did otherwise. We can't. We make sense of things. That's the fundamental - we are sense-making organisms.
VEDANTAM: And, of course, it's worth pointing out that even though this leads to errors, it's also the case that, much of the time, this is enormously valuable and our sense-making ability is - actually works great, that it actually allows us to navigate the world successfully.
KAHNEMAN: Of course. I mean, you know, we're right almost all the time. I mean, you know, we couldn't survive if we weren't right almost the whole time. We make interesting mistakes. And sometimes they're important mistakes. But mostly, we're very well-adapted to our environment.
VEDANTAM: So when you think about news events - you know, if I tell you there are 19 hijackers who have flown planes into major buildings, and then we go back and we get biographical sketches of these people and we understand their ideologies and, you know, it activates things in our minds because of course there are these agents that are doing these things to us. And, you know, we then spend hundreds of billions of dollars trying to combat terrorism. And you say, OK, that makes sense. This was a major threat.
We've dealt with it. But let's say you have another threat over here where I tell you that in 80 years or 100 years, the temperature might rise five degrees. And as a result of this, the oceans might warm a little bit and sea levels might rise by two or three inches. And as a result of this, models predict that climate events will become more serious - at least, according to the models. But you have to understand probability. And in order to try and head that off, you actually have to take very painful steps right now - maybe driving your car less, maybe living in a smaller house, all kinds of things that are painful in the here and now - for something that seems difficult off in the distance and requires you to really understand statistics and probability. You've actually called climate change, in some ways, sort of a perfect storm of the ways in which our minds are not equipped to deal with certain kinds of threats.
KAHNEMAN: I mean, it's really - if you were to design a problem that the mind is not equipped to deal with, you know, climate change would fit the bill. It's distance. It's abstract. It's contested. And it doesn't make - it doesn't take much. If it's contested, it's 50/50, you know, for many people immediately. You know, you don't ask, what do most scientists do? Which side of the National Academy of Sciences - that's not the way it works. You know, some people say this, other people say that. And if I don't want to believe in it, I don't have to believe in it.
So it's - I'm really - well, I'm pessimistic in general. But I'm pessimistic in particular about the ability of democracies to deal with a threat like that effectively. If there were a comet hurtling down toward us - you know, an event that would be predictable - within a day, we'd mobilize. So it's not even that it's distant in time. If it was going to affect our children, we'd mobilize. But this is too abstract, possible, contested. It's very different. We can't - we're not doing it, in fact.
VEDANTAM: So besides being pessimistic, does your research and understanding of this phenomenon give you any insight into how we should maybe talk about climate change and what we can do?
KAHNEMAN: Well, I think scientists, in a way, are deluded in that they have the idea that there is one way of knowing things. And it's you know things when you have evidence for them. But that's simply not the case. I mean, you know, people who have religious beliefs or strong political beliefs. they know things without having, you know, compelling evidence for it. And so there is a possibility, you know, of knowing things, which is clearly determined socially. I mean, we have our religion and our politics and so on because we love it - we love or used to love and trust the people who held those beliefs.
There is no other way to explain, you know, why people hold to one religion and think other religions are funny, you know, which is really a very common observation. So the only way would be to create social pressure. So, for me, it would be a milestone if you manage to take influential evangelists, preachers, to adopt the idea of global warming and to preach it. That would change things. It's not going to happen by presenting more evidence. That, I think, is clear.
VEDANTAM: When we come back, we'll talk about happiness, memory and noise. Stay with us.
(SOUNDBITE OF MUSIC)
VEDANTAM: This is HIDDEN BRAIN. I'm Shankar Vedantam. Daniel Kahneman won the Nobel Prize for a series of ideas that helped develop the field of behavioral economics. Danny, I don't know how you got an ethics panel to approve the study, but it's one of my favorite studies of all time. Tell me about the colonoscopy study and the peak-end rule.
(LAUGHTER)
KAHNEMAN: Well, the colonoscopy study was devised to test an idea that when people form a memory of an episode or an impression of an episode that had a certain duration, that actually they completely neglect the duration. And what they are sensitive to are illustrative or crucial moments. And in particular, when it's a painful experience, it's the peak of the pain and it's the end of the pain. It's how much pain you're at in the end. So that was a theory for which we had other evidence.
And my friend, Donald Redelmeier, who was a physician in Toronto, he volunteered to create a study around that. So the study was run on people who had a colonoscopy, which at the time was very painful. I mean, for those of you who, you know, have not reached the age of colonoscopy, it won't be painful when you have it.
(LAUGHTER)
KAHNEMAN: But at that time, it really was. So people had a colonoscopy. And then half of them, you know, it ended when it ended. But for half of them, they left the tube in for another minute or so. Now, this is not pleasant. Nobody would volunteer to have the tube in for another minute. But it improves the memory very significantly because it's less painful than what went on before. It's not desirable. You wouldn't choose it. But it makes a difference between the really aversive memory, which you have - when they pull the tube at the moment of high pain, the whole thing is very bad.
But if you end on a gentler note, even if it's still painful, the memory improves. Memory wasn't designed, you know, to measure ongoing happiness or to measure total suffering. For survival, you really don't need to put a lot of weight on duration - on the duration of experiences. It's how bad they are and whether they end well. I mean, that is really the information that you need for an organism. And so there are very good evolutionary reasons for the peak and end rule and for the neglect of duration. It leads to, you know, in some cases, to absurd results.
VEDANTAM: So if you were a policy maker, I feel like this is a real ethical dilemma. So let's say, for example, I'm running a hospital. I think the colonoscopy study, or versions of it, have later found that if you actually give people the painful experience followed by the less painful experience, they are more likely to come back for the next colonoscopy because their memory of the colonoscopy was less painful. So you could argue, from a public policy standpoint, if you want people to get tested, the right thing to do is to extend their pain in order that they will remember the pain as being less and come back more often. However, also from an ethical point of view, you could argue that subjecting people to more pain than you need to subject them to is unethical. So what should we do?
KAHNEMAN: That one is easy.
VEDANTAM: OK.
(LAUGHTER)
KAHNEMAN: I mean, you know, there are harder versions of it. But that one is easy because you would never frame it that way. You would just tell - you would just tell the people who are doing the procedure, be very gentle at the end. You know, be slow and gentle at the end. And, you know, that sounds like a good thing. And it's good for policy. And it will get more people - it will leave better memories. It will - more compliance and so on. So there are ways sometimes of not presenting quite as sharply as you did.
VEDANTAM: What would be a more difficult ethical dilemma that I didn't think of that you could place to your - apply to yourself?
KAHNEMAN: Well, I think that if real suffering is involved, you know, somebody in pain, I'd say you can be in pain and barely conscious, or you can be in pain and they will eliminate the memory at the end. So what is the - what - how much weight should you give to pain that the patient might be screaming but will not remember? You know, that's an ethical dilemma.
VEDANTAM: And, of course, this does have all kinds of other implications. You've done some work looking at, you know, if you could go on a vacation, but you couldn't take photographs on the vacation, how would you think about the vacation? In other words, you essentially have these two models of how the mind works. There's a mind that experiences life and there's a mind that remembers life, and these two minds don't always agree with one another.
KAHNEMAN: Well, I mean, they have different interests, in a way. I mean, so I spoke of the experiencing self, which is, you know, the one that lives moment to moment. And the remembering self is the one that keeps score. And the scores that are generated are generated, again, by rules, such as the peak-end rule and so on. And so sometimes you can see that experiences are a very different duration, and what - how do they matter? Or what is the value that you should attach to an experience that you will not remember or that somebody will not remember? So my question in that context was - I mean, consider your plans for your next vacation.
And now imagine that, at the end of the vacation, they will destroy all your pictures and they'll give you an amnesic drug so that you won't remember a thing. Now, would you change your vacation plans if you knew that? And many people would, actually, because I think many people go on vacations to create memories for future consumption, which doesn't always happen. I mean, in my case, it never happens.
(LAUGHTER)
KAHNEMAN: I never look at pictures. But that's a dilemma.
VEDANTAM: So you conducted a study, I remember, a few years ago. I think it was published in the journal Science where you evaluated how happy parents felt as they went through their days, and you - there's two ways you can, of course, ask the question. You can ask parents, how happy are you with parenting? And many parents will say, it's the best thing they ever did. But then you can also ask parents on a moment-to-moment basis as they are parenting how they feel, and the answer turns out somewhat differently.
KAHNEMAN: Well, yeah. I mean, it's - you know, it turns out that parenting, if you really take the experiencing view of it, then, you know, it's like washing dishes - you know, maybe a little worse often.
(LAUGHTER)
KAHNEMAN: And then - you know, and then it has its moments. And it's the peak moments that people remember. And when people remember the peak moments, it makes the whole thing worthwhile. So it changes the meaning of the whole experience. So that was a much-contested finding, very unpopular finding, but a very strong finding.
You know, if you look at the experiences, people have more fun with their friends than with their spouses, you know, quite a bit. And if you were trying to make - to increase the happiness of the experiencing self, you would do very different things than people do because what people typically do, they try to satisfy their remembering self. And maximizing the happiness of your experiencing self would make you more sociable, less ambitious. It would make you spend a lot more time with people that you love or like or enjoy because it's very largely social. So there are very important implications of that distinction.
VEDANTAM: Is there any insight that someone can draw from this work about whether they should become a parent, given this discrepancy between the remembering self and experiencing self? And I should remind you before you answer that your daughter is in the audience here with us.
(LAUGHTER)
KAHNEMAN: I have never met - almost never met people who regretted having had their children. So if you measure a thing by the remembering self, that's the - really the only way. The point is that the experiencing self doesn't make decisions. All the decisions are made by the remembering self. And the remembering self never regrets having had children. So, you know, from that point of view the answer is clear.
VEDANTAM: Well, we're in the process right now at Hidden Brain of hiring someone. And in fact, we just conducted two interviews today and we have a couple tomorrow. And as I was doing the interviews, I was thinking about some of the work that you've done. In some ways this was your earliest work going back many, many decades, looking at how you can reduce errors in the interview process. And I don't know whether you think of it as bias or think about it as noise, but either way it leads to flawed outcomes. And you came up with a technique that could address it.
KAHNEMAN: Yeah, I actually - I did come up with the technique a little more than 62 years ago actually. I was an officer of the Israeli army. It was 1954. The Israeli army was very young. It was 1956, actually. And I set up an interview system which is a template for a lot of what is going on and is certainly a template for the way I think decisions should be made. I haven't thought of that for many years, but - and the template is you have a problem. You need to evaluate people. Break it up into dimensions. You know, what sounds elementary. And I'm not going to say anything very surprising.
Make judgments of each dimension independently of all the others. That independence is essential. Don't form a general impression until you have all the information. Delay intuition. Don't give it up unnecessarily - delay it. And the results are just better when you do things that way. And I think that probably is very general as a way of thinking about judgment and decision-making. It's a way of reducing noise, of increasing reliability. And it's not very costly. And I'd like to promote it.
VEDANTAM: So of course the idea, if I understand correctly, is you score people on different criteria, give them a ranking so that you're evaluating it. But there's also an interesting piece of advice which I understand they still offer in the Israeli army when you're doing these evaluations, a final piece of advice after you've done the calculations. What is that advice?
KAHNEMAN: Yeah, well, that's - So I set up that interviewing system. I was 22 years old. And the people - the interviewers, who were 19 years old, they really didn't like that suggestion. They - what they really wanted was to have a heart-to-heart conversation and then to form a general impression of how good a combat soldier that individual would be. But they said, you are turning us into robots. And they had a point.
And then I told them, OK, you know, I'll compromise. You do it my way, the interview. You run the whole interview just and you generate those scores independently, fact-based and so on. Don't think of anything until the end. And in the end, close your eyes and give a score. How good a soldier will that person be? Now, much to my surprise, that intuitive score is really, very good. I mean, it's as good as the average of the six traits. And it's different, so it adds content. So having an intuition, if you delay it, it's quite good.
The kicker of that story was that about 50 years later or so I got a Nobel Prize. So for a short time I was a celebrity in Israel. And they took me to the army, to my old base. And they explained how they were doing the interview because they were still using that system essentially with very little change. And then the commander was telling me - and then she said, and then we tell them, close your eyes. So that thing had lasted for 50 years....
(LAUGHTER)
KAHNEMAN: ...That's that expression, so...
VEDANTAM: So what I love about that - it's not so much intuition versus bias, but it's more maybe by just delaying intuition the intuition gets better. And of course if you don't do the detailed analysis, you still have an intuition that feels very powerful. And your ignorance is sort of papered over by this tendency of the mind.
KAHNEMAN: And, you know, intuition is compelling as such. I mean, you know, we have the intuition. Almost by definition we trust it. And so delaying this and remaining very close to facts as you collect your separate dimensions is really, very useful. And it permits an intuition that is well-informed because normally we form intuitions very quickly and then we spend the rest of the time confirming that, yeah, this intuition was right. That, by the way, is a fact. It's been studied that way in interviews. People form impressions in the first minute or two and they spend the rest of the time testing that they're right and of course confirming that they're right. So...
VEDANTAM: So this was clearly an example of how you came up with a mechanism in some ways to overcome how the mind works. But on many, many other fronts it seems like the biases, errors that you've discovered, even yourself - you say that you don't necessarily - you're not the master of those biases after studying them for more than half a century.
KAHNEMAN: Yeah. I mean, even myself. I mean, I'm considered one of the worst offenders on many of these mistakes. So, you know, I'm overconfident when I really preach against that. And I make extreme predictions and I preach against that. But, you know, the - you know, some people read "Thinking, Fast And Slow" in the hope that reading it will improve their minds. I wrote it and it didn't improve my mind.
(LAUGHTER)
KAHNEMAN: So it's not - those things are, you know - they're deep and they're powerful and they're hard to change.
VEDANTAM: Danny, yesterday was your 84th birthday. Happy birthday.
(APPLAUSE)
VEDANTAM: You've studied a great number of different things over the years. And you tell me that one of the things that you're actually interested in studying is the subject of misery. Much more than happiness, you're fascinated by misery. Now, of course I can just put this down to the pessimism that clearly you've demonstrated for a long time. But you actually say you can draw more specific conclusions and there are takeaways from studying misery than from studying happiness.
KAHNEMAN: Yeah, I'm actually - you know, I contributed to what is called happiness research. But I'm really disturbed by it. And I'm disturbed by positive psychology in part because I think that making people happier is - you know, could be important, hard to do. It may not be society's business to make people happier, but reducing suffering - that's something else. It's easy to agree that this is important. It's easy to agree that society should be involved.
Furthermore, it's easier to measure misery than to measure happiness. And what we can do about it is clearer than what we can do to enhance happiness. So from all these points of view I think that - and again, you know, it's a matter of semantic luck. You know, we speak of length and not of shortness. And so we speak of happiness and not of - and not of the other side, of unhappiness. But if you focus on unhappiness and misery, you end up doing very different things, thinking very different thoughts and taking very different actions, which I think we should do.
VEDANTAM: So you've been a wonderful sport, Danny, and I'm really grateful for you for coming down. And I'm almost a little shamefaced about doing what I'm about to do right now, which is I'm wondering if we can increase your happiness just a tad. But it might increase your misery by singing "Happy Birthday" to you.
(LAUGHTER)
VEDANTAM: You're one of HIDDEN BRAIN's heroes, and we feel that it's really appropriate to end with that. So on the count of three. (Singing) Happy birthday...
UNIDENTIFIED CROWD: (Singing) Happy birthday to you. Happy birthday to you. Happy birthday, dear Danny. Happy birthday to you.
KAHNEMAN: Thank you.
(APPLAUSE)
VEDANTAM: Danny Kahneman, thank you for joining me today on HIDDEN BRAIN's 100th episode.
KAHNEMAN: My pleasure.
(APPLAUSE)
VEDANTAM: This episode of HIDDEN BRAIN was produced by Rhaina Cohen and Kara McGuirk-Allison and edited by Tara Boyle. Our team includes Jenny Schmidt, Renee Klahr, Parth Shah and Matthew Schwartz. Our engineers are Andy Huether and Neil Travault (ph).
Many months ago, we started a feature in our credits where we thank someone whom we call an unsung hero. This person was someone who worked their magic behind the scenes without whom the episode could not have come together. We have called out many unsung heroes in the past months. Our unsung hero this week is Lenore Shoham. Lenore is Danny's daughter, and she's here in Washington with us today visiting from Israel. A few hours ago, as news broke of a major snowstorm menacing the East Coast, Lenore had a difficult decision to make. She and Danny were planning to see a Paul Taylor show in New York tomorrow. If they were to get to New York safely before the storm hit, they would have had to leave three hours ago. We are truly grateful to you, Lenore. We literally wouldn't be here without you.
(LAUGHTER)
VEDANTAM: I'm Shankar Vedantam. See you next week.
 
Interview 22. A Conversation with Daniel Kahneman Catherine Herfeld

Catherine Herfeld: What do you take rational choice theory to be? Daniel Kahneman: I take rational choice theory to be a body of thoughts that provides an axiomatic treatment of logically consistent beliefs and preferences. Catherine Herfeld: What do you take to be the concept of rationality underlying rational choice theory? Daniel Kahneman: The underlying concept of rationality is coherence. Catherine Herfeld: Coherence or consistency? Daniel Kahneman: To me, it seems to be entirely coherence. And I think this is a big problem. Catherine Herfeld: What is the problem? 2 The interview was conducted in February 2014. 3 Daniel Kahneman: I think that there are two problems. The first problem is that rational choice theory is too demanding and the second problem is that it is too permissive. On the one side, rational choice theory is too demanding in the sense that coherence is psychologically completely impossible. To put it differently, it is too demanding in that having a definition that people cannot possibly satisfy with a finite mind is questionable for a theory. On the other side, rational choice theory is far too permissive because it does not allow for regret on the part of the decision-maker. Catherine Herfeld: Could you further specify this a little? Daniel Kahneman: For example, rational addiction is an interesting problem. One aspect of rational choice theory is that the analysis is entirely from the perspective of the present decision. The possibility that you will regret your decision later cannot be considered. Take as an example Gary Becker’s Economic Approach to Human Behavior when applied to the problem of addiction. His theory cannot take seriously the idea that an addict later will regret his choice. In his theory, somebody who gets addicted and later regrets that he consumed drugs is compared to somebody who goes to a restaurant and has a large meal and then it turns out that he does not have money to pay for the meal. One has very little sympathy for the person who went to the restaurant but one might have sympathy for the addict, just because we consider that he or she might, in the future, regret his decision to consume drugs. I think that the sort of hyper rational choice theories cannot acknowledge that we might have sympathies for people, such as drug addicts, who make a decision that they can regret later. Catherine Herfeld: You are often considered to be the founding father of behavioral economics. Interestingly, Gary Becker frequently considered himself to be a behavioral economist as well. In his analysis of addiction, for example, he meant to take psychological findings about addictive behavior into account. What do you take to be the difference between your and Becker’s work? Daniel Kahneman: First of all, let me stress that I do not consider myself as the originator of behavioral economics. If anybody is the founding father, then it is Richard Thaler. I do not even consider myself to be an economist at all. But those details aside, let me say that the main difference between Gary Becker and other behavioral economists is a methodological difference. Gary Becker begins with a set of assumptions that are given, such as for example the assumption of rationality. Then, when something appears to deviate from the assumption of rationality, he uses the assumption as a tool for discovery. The methodology is that you assume rationality and when you see a deviation, you have made a discovery about the utility function. 4 Catherine Herfeld: You say that rational choice theory is, on the one hand, too demanding, and on the other hand, too permissive. Indeed, it has been objected to Becker for example that his approach is too permissive. When one acknowledges the difference between people and their motives, as he does, but rationalizes those motives in his general framework, the theory becomes almost tautological. Is that what you have in mind? Daniel Kahneman: No. What I mean is that it is not within the framework of the theory. You make discoveries when the world is diverges from your theory. I think there is something quite deep going on here, in that it is true that if you have that assumption and you are not going to give it up, then you are making discoveries. More specifically, when things appear to violate this assumption, then you make discoveries. But it is exactly the same as when there was a geocentric theory of the universe and the planets didn't behave the way they were supposed to behave, then you see that there are epicycles and thereby you felt that you had discovered something. Catherine Herfeld: Oftentimes economists argue that idea behind rational choice theory is that you make the discoveries by seeing how people deviate from the standard or ideal behavior. The next step would then be to consider those deviations in your theory, to de-idealize the theory. However, there seems to be a tradeoff between how much psychological diversity in motives economists should acknowledge and which motives they should just ignore because acknowledging too much can make a theory, albeit making it very detailed, weak in the sense that it loses explanatory power. Because it explains everything, i.e. any kind of behavior, it doesn't really explain anything anymore. Is that what you meant by permissible? Daniel Kahneman: No. By permissive I meant that rational choice theory allows people to be rational while behaving foolishly. So, Amartya Sen has that paper entitled Rational Fools. Somebody with a rational addiction, is a fool; that's rational foolish. That is what I meant by overly permissive. I am not a decision theorist and I am certainly not a rational influence theorist. So, I don't have very much to say about how they should deal with rational choice theory, or what its problems are. I know that when you give up rationality, you get into very many problems in trying to develop a theory of human behavior because there is no limit. Rationality at least gives you a fairly simple answer, in principle. But a psychologically informed theory is not simple even in principle. And so, and the question about rational choice theory, which I'm not going to answer, but which I would be curious about getting an answer to is whether behavioral economists can build a cumulative theory where they make discoveries and the discoveries become part of the theory and the theory advances then. I asked that 5 question to Matthew Rabin and he said he believes it's possible and I don't have an opinion on that but I'm very curious. Catherine Herfeld: Is that not what behavioral economists have done in the last 20 years or so? Daniel Kahneman: Well I mean that's exactly my problem. My problem is that in most of the papers that I see, they study one anomaly at a time, and it's not that out of all the anomalies that they have studied, behavioral economists have a model of the human being and then they add something to it. They always start with complete rationality and with one exception and then one follows that exception. Rationality plays an essential role in modern behavioral economics, so far as I can see, in the theory. The question is whether it is actually possible to replace it, within this framework. Apparently not; that’s my impression. For example, Matthew Rabin assumes rationality in his work, except for some thing or other. Catherine Herfeld: One criticism of alternative theories of choice and at the same time a justification for keeping expected utility theory is that it is very simple and general and there is no alternative theory that would equally satisfy those criteria. Having suggested prospect theory, do you consider it equally challenging to arrive at a general psychological theory, which is more realistic than rational choice theory? Daniel Kahneman: I think it's not impossible. There's never going to be anything that is as simple as utility theory. But you know, it's very easy to have a simple theory, if it is completely false. It's not that the theory can be replaced by something a little more complicated and is true. Prospect theory was a little more complicated than utility theory but prospect theory is also not true. And it's very easy to find counterexamples to prospect theory. It's not complicated enough. And nothing is complicated enough. But whether the glory of a theory that is false is that it is simple, I don’t know. We talk about physical theory but they are true, approximately true, close to being true. But about utility theory, I'm not sure. The great virtue that you can keep the theory by denying the relevance of counterexamples, strikes me as funny. Catherine Herfeld: One challenge that economics as a policy science seems confront is that, although your theory are not yet satisfactory, you have to do something, you have to be pragmatic. In order to get scientific status, economics has to have some account of individual behavior. The question is what kind of individual behavior would be appropriate for the kinds of problems that economists address. Here again this idea of a trade-off is relevant because different problems might require distinct accounts with different level of detail and different degree of theoretical status. You suggest that psychology can offer economics a set of “integrative concepts and mid-level generalization, which gain credibility from the ability to 6 explain ostensibly different phenomena in diverse domains” (Kahneman 2003, 1449). How exactly can economics benefit from those contributions from psychology? Daniel Kahneman: I'm not an economist so I don't really even want to try to answer this question. Economist should answer this question. I can tell you that, as a psychologist, I would have no use for a very simple theory that is false, you know. It's not necessarily true that science is defined by theory, for me and for psychologists in general, and for some behavioral economists whom I know, science is about making discoveries, it is not about having a theory, it is about facts. It is about things that are observable and true. And theory is, in a way, secondary as an objective. It's beautiful to have a theory, but if you don't and you're making discoveries then you're making progress. Catherine Herfeld: In your early work, when you began to collaborate with Amos Tversky in developing prospect theory, a person to whom you responded was Maurice Allais and his experiments, which questioned the usefulness of rational choice theory as empirical and as normative approach. However, in your work you considered normative expected utility theory useful as offering a standard. Is that something you would still argue for? Daniel Kahneman: I mean we never changed our mind, really, about the normative appeal of utility theory. It's an ideal and, as a normative theory we never saw the point of changing it, because what Allais and many other people did was, they changed the theory to incorporate the deviation from the theory and still keep it rational so Amos would call that, that they were acting like lawyers for people, they would find justifications for things that people had done. But if there are so many deviations, then finding a solution to the Allais Paradox is not enough. So we didn't change. I was, I've never been terribly interested in normative theory, I am not a decision theorist. Of the two of us, Amos Tversky was the decision theorist. But we never saw any point in changing the traditional theory. It looks perfectly sensible and the requirements of consistency appear quite sensible, well, it's completely impossible psychologically, but it's better if it's satisfied, we never questioned that. Catherine Herfeld: You argue in various places that human agents, when shown to be wrong, do not actually want to change their behavior, i.e., they don’t aim for striving towards better decisions. Rather they feel uncomfortable and want go on with their business. You also mention that the implementation even of institutional structures that lead us to rational decisions is more often than not highly difficult, although organizations might benefit from such a reformulation. One of the reasons you state is that people do not like to be told that they are irrational and especially that they do not want to be predictable. Other people have argued that people behave 7 rational from their point of view. Given this difficulty, how useful is a normative theory of rationality then after all? Daniel Kahneman: I mean here it becomes tautological when you allow everybody to behave rationally from their point of view. That seems to be empty. I think it's true that when you confront people with the fact that they're not consistent, they're not horrified. Ok so we're inconsistent. People, in effect, know that they're not consistent. So the achievement of rationality, the achievement of coherence and consistency is not the highest value that people have, I think. Catherine Herfeld: Is it something that we should nevertheless strive for in our society? Daniel Kahneman: No. I think rationality as defined in terms of coherence is very largely irrelevant to human affairs, because it doesn't incorporate any conception of human interests, of what in people's best self-interests. There is no conception of anything that is good or bad within the theory, so there's freedom, it’s a very libertarian theory and that's a permissive aspect. However, I think that rationality theory it is irrelevant to human affairs to a very large extent for the two reasons I mentioned earlier. It is too demanding, which makes it impossible, and because it allows unreasonable behavior to be called rational, so the real criterion for human behavior is something like reasonableness, not rationality. And there is really very little direct contact between rationality and reasonableness. Catherine Herfeld: And what do you consider reasonableness to be? Daniel Kahneman: That is very poorly defined, but it incorporates the norms of society about, you know, what is in people's best interests and, to some extent, incorporates people's idea of what is in their best interests. But it's an incompletely defined concept because you know that reasonableness is not consistent, you know, otherwise it would be identical with rationality. It is something else. But it does incorporate criteria that are not incorporated in the coherence theory. It incorporates, in particular, a respect for regret, i.e., respect for my future self that the perspective of my future self on the present is quite important. And indeed, in the real world, this is how people think a reasonable person behaves. People think that a reasonable person behaves in a way now that later they will consider good. So it is not that you behave now and then that implies that you have considered the future and that you have accepted all the consequences of what you are doing. That's the difference. Catherine Herfeld: In your last book, you introduce an approach to distinguish between intuition and reason as two types of cognitive processes, which are labeled System 1 and System 2. The operations of System 1 are fast, automatic, associative, and hard to control while the operations of System 2 are slow, involve effort, and are deliberately controlled (Kahneman 8 2011, 2003). System 1 thus involves intuition while System 2 involves judgment. On the basis of this approach, you consider the rational agent of economic theory to be “endowed with a single cognitive system that has the logical ability of a flawless System 2 and the low computing costs of System 1” (Kahneman 2003, 1469). Could you elaborate further on the difference between your theory and traditional economic theories of rational choice? Daniel Kahneman: Reasonableness has a different perspective than rationality the traditional approach. Reasonableness is not for the moment of decision. The reasonableness of a decision is defined a view of the future, by a view of externalities. Catherine Herfeld: What are the implications of your approach for understanding a phenomenon like for example addiction, as opposed to for example Gary Becker’s Economic Approach to Human Behavior, which takes addiction to be rational? Daniel Kahneman: With a theory of reasonableness, you don't have reasonable addiction, except for people who are about to die or something, it's reasonable for them to be addicted to morphine. But otherwise, while you might be able to have rational addiction, it cannot reasonable. Catherine Herfeld: How do factors, such as regret, figure in your theory? Daniel Kahneman: What I say is that a theory of reasonableness takes the remembering self very seriously. That's what I meant. So it's the retrospective view of behavior, which is the perspective that defines whether behavior is reasonable or not. It's not reasonable to do something that you will regret later. Catherine Herfeld: How can your approach, and the concept of reasonableness upon which it is based, deal with the objection that, given our uncertainty about the future, we cannot really make reasonable decisions? Daniel Kahneman: You can evaluate the decision now as reasonable or not, if it takes into account, in a sensible way, the perspective of the future. And by that I mean that the future is probabilistic and uncertain and so on. But the focus on the future and on regret, I think, is really quite important in defining reasonableness, because that's where the more permanent interest of the individuals come in. That's where the future comes in and the relevance of the future selves. The moment that you abandon consistency, then you allow the self at different times to have different feelings and emotions and so on. The dominant perspective, the perspective of rational choice theory, is exclusively the point of decision. And it's not that there's an alternative to rationality. In everyday language, the perspective in evaluating decisions extends all the time. Catherine Herfeld: Before von Neumann and Morgenstern introduced the axiomatic method into economics to formally represent human behavior, economists relied on a notion of 9 rationality that was a different from notion of rationality understood as consistent choice. Since the enlightenment, the idea of judgment and deliberation, especially moral judgments, had been considered important for behavior to be considered rational. Thus, with the introduction of the axiomatic method, this idea of rationality changed radically and became much narrower and its basic principles were inspired by rules of logic, such as transitivity or consistency. Are the axioms of prospect theory different and how important is it for an axiomatic theory that the axioms are influenced by actual science? Daniel Kahneman: No. I mean the axioms of prospect theory have a different character. They are not normative, as they're not axioms of rationality. More generally put, the question that you're asking me is about the importance of theory in the empirical work, and here there are different tastes and different opinions. Think about Peter Wakker’s work. It's interesting because Wakker, as Matthew Rabin, also has been making prospect theory, as he defines it. But his is completely different from my prospect theory. They are not the same theory at all because his is much more rational, only with a few twists, and it doesn't allow framing. So in behavioral economics we have the same debate about how important it is to have theory. Even within behavioral economics, Peter would be at the extreme of scholars who are trying to do theory. But at the same time, he tries to link theory to measurement. He measures utilities and values especially in the health domain. But he is not particularly interested in discoveries. Catherine Herfeld: Some people have argued that conceptually, behavioral economics still remains in the traditional domain of rational choice theory instead of having lead to a scientific revolution, or at least to something that is conceptually different. Would you agree? Daniel Kahneman: I think it is conceptually different. It is conceptually different because it doesn't accept coherence as a descriptive axiom. What they have felt impossible to do is to put many deviations from rationality into a single model. For mathematical tractability, if you're going to do theory, I think people are forced to assume rationality except for one exception at the time. And whether that leads to cumulative science is a question that, I don't know the answer to. Catherine Herfeld: Could you elaborate further on what you meant by rational choice theory being too demanding? Daniel Kahneman: I mean that the idea of consistency of beliefs and preferences is psychologically absurd; I mean it's completely absurd because it assumes a kind of contextindependence that is violated all the time. But very characteristic of the way the mind works is that it's highly sensitive to the current context and meanings change and that is not represented 10 within the theory of consistency. A theory that denies framing is psychologically impossible and it is psychologically not interesting. Catherine Herfeld: Yet, at the same time you acknowledge the value of expected utility theory as a normative model. Daniel Kahneman: If you're going to have the normative theory, then I don't know of anything better than expected utility theory. What is the role of a normative theory? It is logic. It is the logic of judgments, of beliefs, and inferences. It is to be respected as logic. But it is a completely different enterprise from the descriptive enterprise, from the study of human beings. And if economics, as I understand it, is an empirical discipline, then the idea that logic can propose a theory for empirical behavior is difficult. It is a methodological assumption that helps economists work and it helps them work to the extent that they are very interested in theory, more than in discoveries. Catherine Herfeld: Max Weber gave an evolutionary argument for the usefulness of the instrumentally rational agent. In a capitalist system, only the instrumentally rational agent will survive in the long run because once an agent deviates, she will be driven out of the market and thus not survive. The idea type on an instrumentally rational agent is useful in this light, because as people's behavior becomes shaped in a way towards the appropriate idea type, it eventually becomes a real type, useful as an empirical theory. Daniel Kahneman: The theory that everybody must behave rationally in the market because otherwise they won't survive, or put it differently, that only the rational will survive assumes that we're in equilibrium. It makes so many assumptions that are so obviously incorrect. Evolution works very slowly, and evolution of the markets works very slowly and people get paid for making mistakes. They get paid very well for making mistakes, because the mistakes are not discovered immediately. So I think it's just not true that only the rational survive. Catherine Herfeld: You are a psychologist and Amos Tversky was a decision theorist. At the time, there was a large interest in studying decision-making; decision sciences became more important. Did you develop prospect theory in this context of decision sciences? And what was the actual contribution you wanted to make? Daniel Kahneman: There was a field of empirical decision science, and we were working in that field. That field was very strongly influenced by utility theory. The background hypothesis was always utility theory, everything was always in relation to utility theory, and that was true of what we did as well. So utility theory was a sort of scaffold, because everything that you did, every hypothesis that you had, was how does it violated utility theory. So it played a very important role in that sense. And we played by the rules of what it took to write a good theory 11 within that field. But one argument that I have been making is that what made prospect theory important and what made prospect theory acceptable are two completely different things. What made it acceptable was that it was a pretty good theory in a very limited domain. But that's not why it was important. It was important because of another few ideas, mainly the reference point in loss aversion and those ideas that we used. So it is an almost amusing thing that we had to pass a test of competence, that is, that we had to have a theory that was theoretically sound and empirically. It took a long time before people found counterexamples to prospect theory and by the time they found counterexamples, the theory was already viable, in the same way that Maurice Allais thought he would destroy utility, and people just didn't pay very much attention to it. But we had to have a theory that looked like a good theory and was empirically valid, for choice of the most non-zero outcomes and stated probabilities. Those were the rules of the game, and we played the game by the rules. Catherine Herfeld: Given that the economics discipline is sometimes characterized as rather closed and rigid, did you think they would accept prospect theory? Daniel Kahneman: I think that's just not true that the discipline is rigid. I think that the speed at which behavioral economics was accepted is remarkable. Around 30 years ago, it wasn’t guaranteed that Richard Thaler would get tenure, and now he is the president of the American Economic Association. And there have been several John Bates Clark medalists who consider themselves behavioral economists in the meanwhile. So I think anybody who says economics is very rigid is just wrong. The movement has been very rapid. Now, this doesn't have very much to do with us and with prospect theory. It has to do much more with Richard Thaler and with the sociological thing that happened. The most important thing in the history of behavioral economics was an accident, to some extent. Joseph Stiglitz was the editor of the Journal of Economic Perspectives. He invited Richard Thaler to write a regular column that was called ‘anomalies.’ And Richard Thaler took advantage of this, and so for several years, in every issue of the Journal of Economic Perspectives, there was an article showing an area where economic theory failed. It was always right, because he had a co-author who was an expert. And he is very funny, he writes beautifully and with humor. So every columnist read those. That is what, I think, is really what made prospect theory and behavioral economics vibrant and vital; it was reading all those anomaly columns. Now, Thaler got the benefit of prospect theory. It was a respectable theory. It was mathematical, it got published in Econometrica. People had to take it seriously. Given that background, prospect theory helped Richard Thaler. But behavioral economics is what Richard Thaler did. Catherine Herfeld: Well, he introduced your result into economics … 12 Daniel Kahneman: Well yes, that's true. Absolutely. Catherine Herfeld: So you made the discovery, he developed it further. Daniel Kahneman: Both perspectives are right. Because what happened was that Rochard Thaler also made discoveries, such as the endowment effect, bounded self-control, and many others. What happened was that Thaler was given an early version of prospect theory and he discovered that the value function and the reference point were what he needed to explain several things. So, both was needed, his discoveries and the theories as well as his ability to see that the theory was relevant and would help him to make sense of certain observations. That is the real beginning of behavioral economics, Richard Thaler’s work 1980 and I'm happy to say that. Catherine Herfeld: Did you intentionally target the economics profession by choosing its mathematical formulation and the journal? Daniel Kahneman: No. We didn't have the economists in mind. Econometrica just happened to be the most prestigious journal where you published theory. As it was a theory, we chose it. We chose the name ‘prospect theory’ because we felt maybe it was going to be successful. And if it is successful, it's better for it to have a name that is completely distinctive. But, we weren't sure about its success. Catherine Herfeld: Those factors – the mathematical formulation, the journal, the name – might have been factors that contributed to its success. Daniel Kahneman: That could be something, yes. And it was different, because most of the theories up to that time had tried to be normative. Catherine Herfeld: The focus on the individual agent was equally novel. Daniel Kahneman: That’s true. The focus on individual behavior really had started only with John von Neumann and Oskar Morgenstern’s contribution. If you followed their tradition, you would learn to work with individuals. Catherine Herfeld: Although their focus was primarily on social interaction. Daniel Kahneman: That's right. But the utility theory that they developed had to do with individual choice. Its connection with game theory is a separate thing but the part that influenced decision theorists was not the game-theoretical part but it was the theory of choice. Catherine Herfeld: In your work, you are concerned with empirical research, not primarily with theory building. How important did you consider formal decision theory to be at the time? Daniel Kahneman: Amos was a decision theorist. He had been doing formal theory; that was what he was doing. So for him, that came completely natural. For me, it didn't. And so, that was very useful, because Amos had just an enormous respect for utility theory, much more than me. 13 On the one hand, that I did not have this immense respect was very helpful, because I could see problems that he couldn't see. So that's the way we were a very good combination. On the other hand, I could not do the theory, so I had nothing to do with the axioms. The axioms Amos did with David Krantz, a friend of ours. I just remember that the only thing that I noticed about the axioms were that one of them wasn’t true, empirically. Because the funny thing is, in prospect theory, there's one critical assumption, which is that the decision weights remain the same when you have two outcomes or three outcomes. That assumption is false. But without that assumption, the theory doesn't work. There were many ironies in that. I'm an outsider when it comes to theory. Catherine Herfeld: Is the irony here that there is also a false assumption? Daniel Kahneman: Yes, I'd say so. Catherine Herfeld: I mean as you said at the beginning, every theory has certainly false assumptions that it has to make. Daniel Kahneman: You know, I've talked about theory-induced blindness and I can see that prospect theory is having the same effect, that people are finding it difficult to see obvious violations of prospect theory. Catherine Herfeld: Would you consider regret theory as a follow up on prospect theory, capturing those violations? Daniel Kahneman: Yes, although, I am not fully sure. What happened was that prospect theory came out from regret. That's a big deal and regret is important. But the interesting thing is that when you move from utility theory to prospect theory, you gain a lot of new predictions that were interesting. When you move from prospect theory to regret theory, you gain almost nothing. So it's not that prospect theory is true because the difference between prospect theory and regret theory is about as big as the difference between utility theory and prospect theory. It's just that you don't gain much. This is because in regret theory you're going to need an asymmetry between regret animation and loss aversion does most of the work for that. So the two theories become very hard to distinguish. Nobody has come up with interesting, dramatic predictions from regret theory that make a difference but that was a complete accident, at least in my view. Catherine Herfeld: You identify yourself very strongly with psychology, where the primary goal might not be arriving at a general theory of human behavior. What were your motivations to work on such a theory? Daniel Kahneman: Prospect theory was, for me, a departure, because I hadn't done theory before. I've done theory once since of that kind. I did the theory of experience utility with Peter 14 Wakker. That was a theoretical exercise. It was very much the same. We said: “Well, let's find what the axioms are that will provide us with a possible way” and I thought that was very interesting work. I loved doing it. And there, I suggested the direction to Peter and then Peter did all of the mathematics. But I had an idea of what is involved in having a theory of experience utility, which is in part a normative theory. That's the only time I've done that after prospect theory, and that was very interesting, but again, I couldn't do it myself. I had to work with Peter. Catherine Herfeld: In your early work with Amos Tversky you mainly reacted to the work undertaken by Leonard Savage and Maurice Allais. In your Nobel lecture, however, you also mention Herbert Simon and his early work on bounded rationality. Do you consider Herbert Simon’s work as having had any direct influence on you at all in these early years? Daniel Kahneman: No, not at all. Simon went in a completely different direction from the direction that we went. And his psychological assumptions were very different. We did bounded rationality and in that sense we were within the Simon paradigm, but there was really no influence. He liked our work. In a sense, he was very instrumental. He nominated us for the Nobel Prize for many years, and he wanted us to succeed, but there was no direct influence. Catherine Herfeld: What do you think are the future questions of behavioral economics and neuroeconomics? Daniel Kahneman: I cannot make reliable predictions about the future of behavioral economics. But there is one thing that one could say with certainty. Over the next 20 years, it's going to be a very active field. And the reason for that is because top graduate students at Harvard and Berkeley and in other placed are going to do research in neuroeconomics and behavioral economics and come out with a degree. This guarantees the future of behavioral economics for another 15-20 years. The same is true for neuroeconomics. I do not know where they will go but there is no question that some interesting things will happen. Catherine Herfeld: Do you think they should search for an alternative theory, or do you think they should go on to make discoveries? Daniel Kahneman: I don't know what they should do. They are all highly intelligent people. It would be completely silly for me to say what people in another field should do in ten years. There are going to be very intelligent and they are going to do the best thing at that time, and it is really impossible to see from now, from here, and having preferences about it is even sillier. It's going to change, that's the only thing we can be sure of. Catherine Herfeld: Are you after truth? Daniel Kahneman: I am after small truths, not after truth with a capital T
 
Interview 23. TED Adam Grant Taken for Granted: Daniel Kahneman Doesn't Trust Your Intuition

Adam Grant:
Hey WorkLifers, it’s Adam Grant. Season 4 is right around the corner, but today I wanted to share a special conversation in our “Taken For Granted” series.
I’m talking to Daniel Kahneman.
Danny won a Nobel Prize in Economics. He’s been named one of the most influential economists in the world. But he’s not on board with that.
Daniel Kahneman:
Oh, my God, no. (Laughs) I'm not a behavioral economist. I'm not any kind of economist.
Adam Grant:
Danny is one of the great psychologists of our time-- actually, of all time. You may have read his influential book Thinking Fast and Slow, and he has a new book, Noise, coming out later this spring with Cass Sunstein and Olivier Sibony.
This is Taken For Granted, my podcast with the TED Audio Collective. I’m an organizational psychologist. My job is to think again about how we work, lead, and live.
This conversation with Danny challenged one of my core beliefs about intuition. It also gave me a new way of thinking about which ideas are worth pursuing.
Since Danny is an expert on decision-making, I thought I’d start by asking about what we’re seeking in so many of our decisions...
Adam Grant:
You've spent a lot of your career studying happiness and related topics. And really For the first time in my career, I started to wonder, why are we so obsessed with happiness as psychologists? You know, I'm all for people leading enjoyable, satisfying lives. But if I had to choose, I would much rather have people focused on character. On, you know, trying to build their generosity, their integrity, their commitment to justice, their humility. And I wonder if you could talk to me a little bit about whether you think we've lost our way a bit, and character has, has been too little in focus or too far in the background, or whether you think happiness deserves the attention it's gotten.
Daniel Kahneman:
I think my focus would be neither happiness, nor character. It would be misery. And I think that there is a task for society to reduce misery, not to increase happiness. And when you think of reducing misery, you would be led into very different policy directions. You would be led into mental health issues. You would be led into a lot of other problems. So reducing misery would be my focus. Character and happiness or misery are not substitutes. And the idea that’s been laid out of many other people, which has been accepted both in the UK and in many other places in quite a few other countries by now, is that the objective of society, the objective of policy should be increasing human welfare. Or human wellbeing in a general way. I think that's a better objective for policy than increasing the quality of the population's character. I think it's a better objective. I think it's a, it's a more achievable objective, except I would not focus on the positive end. I would focus on the negative end and I would say it is a responsibility of society to try to reduce misery. Um, that's focused on that.
That is we speak of length and not the shortness. And we speak of happiness, the dimension is labeled by its positive pole. And that's very unfortunate because actually increasing happiness and reducing misery are very different things.
Adam Grant:
I agree. And it's interesting to hear you say that reducing misery is more important than promoting happiness. In some ways that feels like a critique of the positive psychology movement.
Daniel Kahneman:
It is.
Adam Grant:
And tell me a little bit more about why.
Daniel Kahneman:
Well, uh, I think the positive psychology movement has, in some ways, a deeply conservative position, that it says let's accept people's condition as it is. And let's make people feel better about their unchanging condition. You know, there has been some critique of positive psychology along those lines. I'm not, uh, I'm not innovating here. But I think that focusing on changing circumstances and dealing directly with misery is more important, and is a worthier objective for society, than making people feel better about their situation.
Adam Grant:
Yeah. I mean, I think it certainly tracks with how I think about in general, bad being stronger than good. And the alleviation of misery contributing more to the quality of people's lives, then, you know, some degree of elevating of, of the amount of joy that they feel. But I also wonder at times, if this is not a false dichotomy, that if you want to make people happy, it's awfully difficult to do that if you don't pay attention to the misery or suffering that they might experience.
Daniel Kahneman:
Actually, uh, we once, did a study in which we, we were measuring how people feel. How much of the day are people in different states, positive or negative. And it turns out that people are in a positive state on average 80% of the time, more than 80% of the time. On average, people are on the positive side of zero. Now look at say the 10% of the time that people spend suffering overall, most of the suffering is concentrated in about 10 to 15% of the population. So it actually is not the same people that you would make less miserable or happier. Those are different populations. And the question is where do you direct the weight of policy and what do you pay more attention to?
Adam Grant:
Very interesting. I like it. So you're, you're basically saying, look, if we have scarce resources, whether those are financial or time or energy, we want to concentrate on the group of people who are suffering, as opposed to those who might be languishing.
Daniel Kahneman:
It seems to me that to some extent we have been trapped by a word. I mean, it's the word, happiness, which seems to stand for the whole dimension. And, uh, and, and I think this has, this is leading to some policies—actually, is failing to lead to policies that would, that would really be directed at, I think, recent human wellbeing by decreasing misery.
Adam Grant:
Yeah, I think so too. And it's something I've thought about a lot at work. Given, given that the hat I wear most often is organizational psychologist. I feel like the obsession with employee engagement has really missed the mark. I don't, I don't go to work hoping that I'm going to be engaged today.
I hope that I'm going to have motivation and meaning, and that I'm going to have a sense of wellbeing. And I wonder if, if one of the effects that the pandemic has had on a lot of people and a lot of leaders in workplaces is to get them to recognize, you know what, we need to care about people's wellbeing in their lives, and not just their engagement at work.
Daniel Kahneman:
Well, I thought that, you know, I'm not an expert, this is your field not mine, but I thought that the engagement was close to feeling good at work. I mean, we, whether it's the responsibility of workplaces to deal with people's wellbeing in general, I agree that it's, they're responsible for dealing with people's wellbeing at work.
And that doesn't seem to me to be very different from trying to make people engaged and happy with what they're doing. So I'm a bit curious to hear more about the dichotomy or the distinction that you're drawing between engagement and wellbeing. My interpretation of engagement, was -- it's fairly close to wellbeing at work.
Adam Grant:
Yeah, I think, I think in large part, it depends on which conceptualization and measure of engagement we're talking about. But one of the, one of the more interesting patterns in the literature that's gotten me thinking quite a bit is that it's possible to be, uh, an engaged workaholic. And this, this has been differentiated recently from being a compulsive workaholic. Are you working a lot because you find it interesting and worthwhile or are you doing it because you feel guilty when you're not working and you feel kind of obsessed with the problem that you're trying to solve? And I think that one version of engagement is probably healthier than the other. And I associate well-being much more with, you know, with being an intrinsically motivated workaholic than with a compulsive workaholic, even though both are highly engaged.
Daniel Kahneman:
I agree. Uh, you know, I worked for a while with Gallup. I was a consultant with Gallup many years ago. And their concept of engagement, I think was a positive concept. One of the criteria that I remember for people being happy at work is having a friend at work. So, uh, clearly at least their concept of engagement, which is the one that the only one that I know much about is by and large, a positive concept.
And certainly, uh, the word, we don't want people to be compulsive. Although. Although, I don't know how to describe myself, for example. When, when I work hard or when I used to work very hard, was I doing so compulsively? Was I doing so out of intrinsic motivation? I think both. I was intrinsically motivated and I was compulsive about it. So I'm not sure of the distinction that you're drawing between being compulsive and, uh, being intrinsically motivated.
Adam Grant:
Well, I like the call to look at ambivalence there because I think it speaks to the point that you raised earlier, which is that positive emotions and negative emotions can coexist. You can work because you're passionate about it, and because you feel bad if you're not doing it right.
Daniel Kahneman:
That’s right.
Adam Grant:
I want to ask you about the joy of being wrong. The place I wanted to begin on this is to ask you when, when you were growing up or earlier in your life, how did you handle making mistakes?
Daniel Kahneman:
I'm hesitating because I can't. It's not that I didn't make any mistakes. I certainly made many, but I wasn't very impressed by my mistakes. And then they were not very salient in my life. So if you're asking about my early, you know, as a student and so I don't have much to report that's of any interest. As a researcher, uh, I found my mistakes, very instructive and, and they were sort of positive experiences by and large.
Adam Grant:
It's such an odd thing to hear you say, because most of us, most of us experience pain, not pleasure when, you know, when we find out that we're wrong or we discover that we've made a mistake. So how did you arrive at a place where you've found that to be a teachable moment?
Daniel Kahneman:
Well, You know, those are situations in which you're surprised. I mean, I've really enjoyed changing my mind because I enjoy being surprised and I enjoy being surprised because I feel I'm learning something. So it's been that way. I've been lucky, I think you're right that, uh, this is not universal, the positive emotion to, uh, to corrected mistakes, but it's just a matter of luck. I mean, I'm not, you know, not claiming high, moral ground here.
Adam Grant:
It's fascinating to watch though, because I've, I've seen your eyes light up and, you know, it's -- it's palpable. Right? When you, when you discover that you were wrong about a hypothesis or a prediction, uh, you, you look like you are experiencing joy and I've started, uh, to think a lot about what prevents people from getting to that place.
And I think a lot of it is for so many people, they get trapped in either a preacher or a prosecutor mindset of saying, you know, I, I know my beliefs are correct, or I know other people are wrong. And at some point their ideas become part of their identity.
And I know even scientists struggle with this, right. I think at least when I was trained as a social scientist, I was taught to be passionately dispassionate, but I know a lot of scientists who struggle with detachment and you don't seem to. So how do you keep your ideas from, I guess, becoming part of your identity?
Daniel Kahneman:
Well, I think that, I mean, this is going to sound awful. I have never thought that ideas are rare. And you know, if that idea isn't any good, then there is another that's going to be better. And I think that is probably generally true, but not generally acknowledged.
So that for people to give up on an idea, may in many cases lead to sort of panic. If I don't have that idea, then what do I have? Who am I am if I don't have that idea. So being less identified with your ideas is also associated, I think, with having many of them, discovering that most of them are no good. And trying to do the best you can with a few that are good.
Adam Grant:
So it's, it's seeing ideas as abundant rather than scarce. That makes it easy to stay detached.
Daniel Kahneman:
I mean, I used to tell my students ideas are a dime a dozen. I mean, don't overinvest in your old ideas. And so I used to encourage my students to give up at a certain point I certainly never wanted to read a dissertation by a student with a chapter that would explain why their experiment failed. So that was the kind of advice that I would give them. Think of another idea.
Adam Grant:
Do you ever worry about getting too detached? I think for example, about messenger RNA technology, which was seen as I think a joke for a long time and if not for the courage and tenacity of a small group of scientists who persisted with it anyway, we might not have a COVID vaccine right now.
Daniel Kahneman:
I think, well, in the first place, science like many other social systems. Um, doesn't thrive on everybody being the same. So, uh, you may have some advice that is good for some people. And it's clear that some people who are irrationally persistent achieve great successes.
And indeed, if you look back at rate successes, you will generally find that there is some irrational persistence behind them and irrational optimism behind them. That doesn't mean that when you are looking from the other side, that irrational optimism is more irrational, uh, persistence, uh, are good things to have. So the expected value of it might be negative. Although when you look back every big success, you can trace to some irrationality.
Adam Grant:
Well, that goes beautifully to one of my favorite ideas of yours, which is that we look at successful people and we learn from their habits, not realizing that we haven't compared them with people who failed who had many of the same habits.
And I wanted to, I guess, ask you a broader question, which is having put these kinds of decision heuristics and cognitive biases on the map, which one do you fall victim to the most? Is it confirmation bias? It sounds like maybe not? I just wondered which of, which of the biases that you've documented is your greatest demon.
Daniel Kahneman:
All of them, really. Except as you said, confirmation bias, by the way people close to me find this irritating. That is that whenever they have a problem with someone, I automatically take the other side and try to explain why that someone might be right after all. So I have that contrarian aspect to what I am.
Adam Grant:
This, this reminds me a little bit of a possibly apocryphal story. That's, uh, I think told to every doctoral student in social science these days, which is that not long after you won the Nobel prize for your work on decision-making, there was a journalist who asked you how you made tough decisions and you said you flip a coin.Is this true?
Daniel Kahneman:
No.
Adam Grant:
Okay, good.
Daniel Kahneman:
Absolutely not. I've never flipped a coin to make a decision in my life.
Adam Grant:
The version of the story I heard was that you flip, you would flip the coin to observe your own emotional reaction and figure out what your biases were.
Daniel Kahneman:
I might have said that this is one of the benefits of flipping a coin, but I personally have never used it. But it's true, flipping a coin would be a way of discovering how you feel if you didn't know earlier that I still believe.
Adam Grant:
I feel very relieved to know that cause I was worried about you, given all you know about decision-making, making important life choices with a coin toss.

Adam Grant:
Welcome back to Taken for Granted, and my conversation with Danny Kahneman. He was just setting the record straight that as an eminent scholar of decision making, he does not make decisions based on a coin toss.
So -- how does he make decisions?
Daniel Kahneman:
You know, when I look back at my life, it's been a series of things that, you know, ultimately I made decisions or I made life choices clearly. But I did not experience them as decisions in the way that you know of you. I have very little to say describing myself as making decisions in part, because I have pretty strong intuitions and I follow them.
So the decision doesn't feel hard if you know what you're going to do and if you know yourself and you're going to do it anyway, it doesn't feel very hard.
Adam Grant:
I have to say, Danny, I'm a little shocked to hear you say that you follow your intuition because you have spent most of your career highlighting all the fallacies that come into play when we over rely on our intuition.
Daniel Kahneman:
Well, uh, you really have to distinguish judgment from decision-making. And most of the intuitions that we've studied were fallacies of judgment rather than decision-making. And, second, my attitude to intuition is not that I've spent my life, you know, saying that it's no good. Uh, in, in the book that we're right writing—just finished writing—our advice is not to do without intuition. It is to delay it. That is, it is not to decide prematurely and not to have intuitions very early. If you can delay your intuitions, I think that they are your best guide, probably about what you should be doing.
Adam Grant:
Okay. So two questions there. One is, how? The other is, why?
Daniel Kahneman:
Well, you delay your intuitions. Now I'm talking about formal decisions, decision, that might be taken within an organization or a decision that an interviewer might take in deciding whether or not to hire a candidate and here the advice of delaying intuition is simply because when you have formed an intuition, you are no longer taking in information. You are just, rationalizing your own decision, or you're confirming your own decision. And there's a lot of research indicating that this is actually what happens in interviews. That interviewers spent a lot of time, they make their mind up very quickly and they spend the rest of the interview confirming what they believe, which is really a waste of time.
Adam Grant:
Yes. Yes. so the idea of delaying your intuition is to make sure that you've gathered comprehensive, accurate, unbiased information. So that then when your intuition forms it's based on better sources, better data, is that, is that what you're after?
Daniel Kahneman:
Yes, because I don't think you can make decisions without their being endorsed by your intuitions. You have to feel conviction. You have to feel that there is some good reason to be doing what you're doing. So ultimately intuition must be involved, but if it's involved, if you jump to conclusions too early or jump to decisions too early, uh, then you're going to make avoidable mistakes.
Adam Grant:
This is an interesting twist on, I guess, how I've thought about intuition, especially in a hiring context, but I think it applies to a lot of places. My, my advice for a long time has been don't trust your intuition, test your intuition, because I think about intuition as subconscious pattern recognition, and I want to make those patterns conscious so I can figure out whether whatever relationship I've detected in the past is relevant to the present.
And it, it seems like that's what, what you've argued as well. When you've said, look, you know, you can trust your intuition. If you're in a predictable environment, you have regular practice and you get immediate feedback on your judgment. I think the tension for me here is I don't know how capable people are of delaying their intuition. And I wonder if what might be more practical is to say, okay, let's make your intuition explicit instead of implicit early on. So that then you can rigorously challenge it and figure out if it's valid in this situation.
Daniel Kahneman:
I've been deeply influenced by something that I did very early in my career. I mean, I was 22 years old. I set up an interviewing system for the Israeli army. Um, for it was to determine suitability for combat units. The interview system that I designed broke up the problem so that you had six traits that you were interviewing about, you're asking factual questions about each trait at the time. And you were scoring each trait once you had completed the questions about that trait.
Adam Grant:
Jumping in here, because this is such a cool example, but it needs a little explaining. Danny created a system for interviewers to rate job candidates on specific traits-- like work ethic, analytical ability, or integrity. But interviewers did not take it well.
Daniel Kahneman:
They really hated that system when I introduced it. And they told me, I mean, I vividly remember one of them saying, 'you're turning us into robots,'
Adam Grant:
Danny decided to test which approach worked best. Was it their intuition or their ratings from the data? The answer… was both. Their ratings plus their intuition. But not their intuition at the beginning… their intuition at the end, after they did the ratings.
Daniel Kahneman:
That is you rate those six traits, and then close your eyes and just have an intuition. it turned out that that intuition, that, that intuition at the end was the best single predictor. It was just as good as the average of the six traits and it added information. You know, I was surprised. You know, I just was doing that as a favor to them, letting them have intuitions, but the discovery was very clear and we ended up with a system in which the average of the sixth traits and the final intuition had equal weight.
Adam Grant:
It sounds like what you recommend then concretely is for a manager to make a list of the skills and values that they're trying to select on. To do ratings that are anchored on those dimensions. So, you know, I might judge somebody who's coding skills, if they're a programmer or their ability to sell, if they're a sales person. And then I might also be interested in whether they, you know, they're aligned on our organizational values. And then once I've done that, I want to form an overall impression of the candidate because I may have picked up on other pieces of information that didn't fit the model that I had.
Daniel Kahneman:
I think that's about right.
Adam Grant:
It's such a powerful step that I think should bring the best of both worlds from algorithms and human judgment. There's something that's a little puzzling to me about it though, which is, Why are managers and people in general so enamored with intuition?
Daniel Kahneman:
I think it's because people don't have an alternative. It's because when they try to reason their way to a conclusion, they end up confusing themselves. And so the intuition wins by default. It makes you feel good. It's easy to do. And it's something that you can do quickly. Whereas careful thinking in a, in a situation of judgment where there is no clearly good answer, careful thinking it's painful, it's difficult.
And it leaves you in a state of indecision or in a state of, even if one option is better than the other, you know that the difference is not something you can be sure of. Whereas when you go the intuitive route, you'll end up with overconfident certainty and feeling good about yourself. So it's an easy choice. I think.
Adam Grant:
You, you wrote about this topic at length, in what, some have called your Magnum Opus, Thinking Fast and Slow. I'm wondering what you've rethought since you published that book?
Daniel Kahneman:
Well, um, you know, there were, there were things I published in that book that were wrong. I mean. Literature I quoted that didn't hold up.
Now the interesting thing about that is that I haven't changed my mind about much of anything, but that is because changing your mind is really quite difficult. That is, Dan Gilbert has a beautiful word he called that un-believing. And un-believing things is very difficult. So I find it extremely hard to unbelieve, uh, aspects or parts of Thinking Fast and Slow, even though I know that my grounds for believing them are now much weaker than they were.
But the more significant thing that I have begun to rethink is that Thinking Fast and Slow, like most of the study of judgment and decision-making, is completely oblivious to individual differences, and all my career I made fun of anybody who was studying individual differences. I say I'm interested in main effects, I'm interested in characterizing the human mind. But it turns out that when you go into detail, people the, those studies that you have, uh, it's not that everybody's behaving like the average of the study—that's simply false. There are different subgroups who are doing different things.
And, uh, life turns out to be much more complicated than if you were just trying to explain the average. So the necessity for studying individual differences is I think the most important thing that I have rethought, it doesn't have any implications for me because it's too late for me to study individual differences and I wouldn't like doing it anyway. It's not my style. But, but I think there is much more room for it than I thought when I was writing, Thinking Fast and Slow.
Adam Grant:
Another thing I wanted to ask you about is the choices you make, about what problems and projects to work on.
Daniel Kahneman:
I'm not a good example for anybody. I've really never had a plan. More or less followed my nose. And I did many things that I shouldn't have done. I wasted a lot of time on, on projects that I shouldn't have carried out, but, I've been lucky.
Adam Grant:
Well, I think that's, that's probably an encouraging message for a lot of us.
Daniel Kahneman:
The idea is an area where there is gold, and I'm willing to look for it. I mean, that's, that's an idea. And formulating a new question, that's an idea in my book.
Adam Grant:
I'm going to use that, “this is an area where I think there might be gold and I want to look for it.” Such a nice reframe. So, Danny, you mentioned your new book Noise. One of my favorite ideas when I read Noise was the idea of the inner crowd. And I wondered if you could explain that?
Daniel Kahneman:
There've been two lines of research by Bullen Pashler and by Hertwig on asking people the same question on two occasions or into different frames of mind. And it turns out that when you ask the same question, like an estimate of, you know, the number of airports, when you ask people the same question twice separated by some time, then they tend to give you different answers and the average or the answers is more accurate than each of them separately.
Also in the case that the first answer is more valid than the second. And it's also the case that the longer you wait, the better, the average is. The more information there is in the second judgment that you make.
And you know, what it indicates is clearly that what we come up with when we ask ourselves a question is we're sampling from our mind. We are not extracting the answer from our mind. We are sampling an answer from our mind, and there are many different ways that that sample could come out. And sampling twice, uh, especially if you make them independent, sampling twice is going to be better than sampling once.
Adam Grant:
This is, this is one of the most practical sort of unexpected decision-making and judgment, uh, perspectives that, that I've come across in the last few years in part, because it says, I don't always need a second opinion if I can get better at forming my own second opinions.
Daniel Kahneman:
I think, as we say in that chapter, sleep over it. It is really very much the same thing that is sleep over it. Just wait. And tomorrow you might think differently. So the advice is out there. Reinforcing it may be useful.
Adam Grant:
Your collaboration with Amos Tversky is obviously legendary. There's a whole Michael Lewis book about it. Is there, uh, a lesson that you took away from that collaboration that's informed either how you choose your collaborators now or how you work with the people on your teams?
Daniel Kahneman:
I think that one really important thing in, uh, is to be genuinely interested in what your collaborator is saying. Um, uh, you know, I'm quite competitive. Amos was also quite competitive. We were not competitive when we worked together. The joy of collaboration for me always was that. But that's almost, that was more with Amos than with almost anyone else. That I would say something and he would understand it better than I had. And that's the greatest joy of collaboration, but in my other collaborations, taking pleasure in the ideas of your collaborator seem to be very useful. And that'd been lucky that way.
Adam Grant:
On that note, almost anyone who's ever won a Nobel Prize has complained that it hurt their career. Uh, and I've wondered what the experience has been like for you.
Daniel Kahneman:
Oh, I mean, it hurts people's career if they're young. Um, you know, I got mine when I was 68 and for me it was a net plus.
Adam Grant:
Why does it get people in trouble if they get it earlier?
Daniel Kahneman:
Oh, In, uh, you know, there are a variety of ways that this can happen. In the first place, it's very destructive. I mean, people start taking you more seriously than they did and hanging on your every word and a lot of nonsense. And if you begin to take yourself too seriously, that's not good. If you take time away from your work to do what you're invited to do when you get a Nobel, which is a lot of talking and a lot of talking on thing that you don't know much, that's a loss. And then if it makes you self-conscious that everything that you have to do has to be important, that's a loss. So there are many different ways I think in which getting a Nobel early is a bad idea. Uh, I mean, this is not the best.
I was at a good age to get it because I had some years left in my career and it made many things much easier having an Nobel. It made the end of my career more productive, I think, and happier than it would have been otherwise.
 
Interview 24. Daniel Kahneman on wellbeing and how to measure it | University of Oxford 2022

The sources contain excerpts from the transcript of the video "Daniel Kahneman on wellbeing and how to measure it | University of Oxford 2022" but not a full transcript. However, I can provide the excerpts of the interview with speaker names.
Host: "Foreign that we are incredibly thrilled and honoured um to have Daniel Coleman with us today and we're incredibly grateful to you Danny for making a trip all the way from New York thank you most of you will know Danny and the fact that he received the Nobel Prize in economics for his incredible work on judgment and decision making and pretty much starting the field of Behavioral economics but in preparing for for this interview I also looked up Danny's Google Scholar page and I couldn't believe my eyes so for the academics in the room sit tight Danny has 486 000 academic citations I see some people I know I'm not raising the collective well-being of the academics in the room by saying this for the non-academics as an academic throughout your career you can probably Aspire too if you do really well about 10 15 000 academic citations so we're sitting arm sitting and we're all sitting in front of a legend here um most of you will have read his book Thinking Fast and Slow um which brings all his wonderful research together in an accessible way what not all of you will know or what is slightly less known out there in the public is that danius had a very and seems to continue to have a very impactful line of research on happiness and well-being which he coined as experienced utility in the context of Economics we tend to talk about decision utility or reveal preferences um it's also that line of research I found that over the years that Danny started I think late 80s early 90s inspired people like Richard Laird Paul Dolan who's here with us today as well to really turn their attention to this to this line of research and terms so thank you Danny for inspiring what are now becoming mentors to many other people let me start by asking your original story um why did you take an interest or how did you come around to taking an interest in happiness and as well experienced utility".
Daniel Kahneman: "Okay it's a long story uh when I was working with amostursky on prospect theory so that was in in the late 70s I invented a puzzle and the puzzle with this imagine that you have an illness that requires you for treatment to receive one injection every day and it's painful uh and you don't adapt because it's once a day how much would you pay to reduce the number of injections say from 20 to 15 or from 10 to 5. and it's immediately obvious that you wouldn't pay the same amount and yet you should pay the same amount and so clearly there was a distinction here between the utility that is experienced where 20 is clearly twice as much as 10 and and the decision utility so that that was in the back of my mind and and I knew that sometime you know I would get back to it and to that project and much much later in the late 80s and early 90s I I actually got to the question of whether people can predict their future enjoyment of things and whether people can correctly remember experiences that they have had and evaluate experiences that they have had and the there was a paradoxical result which is quite easy to to duplicate we first found it in a questionnaire actually and then we we confirmed it in various ways which is that if you take an unpleasant episode and you add and and you add to it you add more unpleasantness but diminishing unpleasantness the memory or the global evaluation or the entire episode improves and so that led to the formulation of something that they're called the peak and Rule but mainly it led to the idea that experience and how you think about your experience are completely separate things and at the time I thought that experience is reality and that what we think about experience is just you know it's just biased judgment and and the biases are interesting but I thought there is reality in and so that's where that's how I began my work on well-being that's what the origin of the work and will be in the late 1990s I think I was invited by Richard layer to give a series of talks at LSC and I think I presented that work in one of the lectures and it was cleared or it appeared to be clear that life that well-being research was being conducted with life satisfaction questions but life satisfaction is a judgment so I thought oh all of this we can redo the study of Life of well-being with experience and we'll find completely different things so I engage in that exercise with a with colleagues we developed the the Dairy construction method that was just mentioned and that's how I became interested sorry for the very long answer but I'm not going to answer all questions at that time I promise".
Host: "But then I think people are here to to hear you and to hear these stories um I do want to we'll get back into because throughout the conference we've had a lot of information already about evaluative measures life satisfaction and the more experienced matters such as um affect and unhappiness in the moment the experience of it itself we'll get back to that in a second but I want to dig a little bit into that story of how the economics world and got to find out about your amazing work and I think you were the first one to in one of the very top economic journals the quarterly Journal of economics in 97 published a piece called back to Bentham explorations of experienced utility and I was wondering at the time it was very much still field preferences decision utility the ordinal measure of utility that economists were using and to some extent are still using today what was the reception of that famous piece that hit the very best journals what your colleagues at Princeton in the economics Department that they dismissed this that like this what did they think".
Daniel Kahneman: "You know I think the it was ignored I mean you know like everything else that the psychologists do so I don't the Nobel actually made a lot of difference so after the Nobel it was it's been you know it's been read much more but the initial reaction was very little interest I think and and I should add this was published after remostovsky's death in a special issue in his memory so it was barely refereed if it all and if it had been refereed I'm not sure it would have been published so we know of another famous paper a few years later in the American Economic Review one of the other big places by uh Andrew Oswald and others which did go through proper review and it also didn't make it almost because of very tough referees you mentioned already your interest in the field came through these the colonoscopy studies and others with the pecan Rule and the the fact that sometimes um evaluations of or memories of the experience don't quite suit what actually happened uh but then in a piece in 2018 and I I've got a copy with me here Danny did an interview with Harrod's magazine and the title of the piece uh was the follo".
Host: "Wing Nobel Prize why Nobel Prize winner Daniel Kahneman gave up on happiness as a title obviously very attention grabbing luckily there is a byline but yet now considers life satisfaction of Greater importance as you can imagine in the field of well-being science that was circulating quite widely I didn't know that and we're keen to hear how um you may not want to fully transition I gather but how you feel today about um which of the two measures could be an optimal Criterion for policy makers or individuals to strive to optimize is it the experience or is it the memory of the experience".
Daniel Kahneman: "Well uh so I've started out with a position that it's the experience and that you know life evaluation is it's just the biased judgment uh and I was I held that position for for quite a few years and eventually something hit me which is that life satisfaction well let me add we had a group that I set up and and the group was the idea of the group was to get economists interested in well-being I mean the two Andrews had were there but they were pretty isolated I brought Alan Krueger who was a famous the late Alan krugeroo very well-known Economist at Princeton and a whole group to develop an instrument to measure experience that was that the day reconstruction myth and it enabled us to look at quite specifically what predicts life satisfaction and what predates emotional happiness and it only turns out you know they're different in obvious ways so life satisfaction is largely predictable as conventional success so our idea of success in life is widely accepted and people measure themselves by roughly by that Criterion happiness is primarily at least in our work it seemed to be determined primarily by who you are with by whether you're people with people you like in a pleasant interaction and and a lot of so income was much more predictive of one than it was predictive of the other there was those very large differences so we knew that but then they know something hit me that that I should have seen earlier about life satisfaction which is that life satisfaction is what people actually want that is when when people set goals for themselves and make decisions long-term decisions uh they're looking they're actually the term that th".
Daniel Kahneman: "Ey use they're serving their remembering self that is they're evaluating the outcomes they're anticipating their memories and this is what they're they want to maximize in short people want to have a good story for their life and so I discovered that I had a theory of well-being that didn't correspond to what people wanted for themselves and that seemed extremely awkward and it's not that I gave up on unhappiness I gave up on happiness as a dissolution and it's not the very adopted life evaluation it's just that I became totally puzzled and baffled and I didn't know how to solve it and I moved on to other things but hopefully this conference brings you back into some extent certainly but can I push a little bit on that point how do we know that people may prefer the story of their life life evaluations over the experience of it well how do we know that when you look at the determinants of Life satisfaction those are turned out to be goals that you know many people aspire to they they turn out to be how people evaluate each other as well as how they evaluate themselves so that's that's pretty obvious and it's also obvious actually that if we wanted to maximize our experience we wouldn't know how to do it because all we get to keep from our experience is our memories and so maximizing experience is a very difficult thing it's an art that maybe you know maybe it's learnable maybe it's teachable but it's very different from life satisfaction and what brings life satisfaction thank you Danny".
Host: "Um I want to change talk a little bit back in 2012 I received an email from you and as a junior scholar this is the kind of stuff but obviously uh you never forget and by the way I I've heard of a number of Junior Scholars after publishing a paper that you send them a note congratulating them on a paper or pushing their thinking a little bit further so I want to thank you for that and I know the other Junior Scholars at the time also really appreciate that so thank you but in that email which I looked up again to get the actual text and it's something that has resonated with me ever since and I've been looking for which is you you wrote something I'm increasingly troubled by the problem of labeling labeling results by one pole o".
Host: "F a dimension which reflects deep linguistic habits rather than the structure of the data for example and it's so simple and so clever this example and yet so telling uh suppose that I suppose that being very short is more likely to make one miserable than being very tall to make one happy but the relationship would still be described as connecting happiness to height and I've seen that also picked up in um in in studies where a lot of the action is often driven by the bottom end of the well-being scale um yet it's described as matching X to well-being or happiness but can you can you elaborate a bit on this for us because I know it still is something that you care much about".
Daniel Kahneman: "Oh yes and that's one of the few points I think where Richard Laird and I disagree I mean I have always thought that we should be studying misery and that and that and that the objective of social policy should be to reduce misery rather than to increase happiness and in part this was because the dominant view of what increasing happiness was at at that time like 15 20 years ago with positive psychology and positive psychology aimed to change the way you think about your life which which is nice in a way but it's also very conservative message in some sense it doesn't so much matter to improve your circumstances or to change your life as to make you happier with whatever whatever it is that you have so I was questioning that and I thought that producing misery is should be the objective and that the focus on happiness which is really linguistic uh it's like you know we measure length and not shortness uh that the focus of Happiness was guiding us in a different direction if we were thinking of objectives of policy that's what I thought let me say that this conference shows that that I was wrong but I thought that if you focus on happiness you wouldn't focus on reducing misery that was my it turns out that Richard Laird focused on happiness and on the reduction of misery and that's very clear in this conference and in the book that you've written that I've just read that many people are thinking about this and that you know and in terms of talking to the public then happiness is a much better word than misery that's that's clean thank you t".
Host: "Hough so I'm glad we can get to stay Scholars of happiness and well-being but perhaps put some extra weights on the people at the bottom of the distribution scale I want to ask you for all of us especially the young scholars in the room what are some of the big next research Frontiers that you see where you've seen some of the sessions today you've been thinking about this quite a lot where do you see the research Frontier where is it genetics is it experience sampling there is a Twitter data where do you think the exciting new avenues for our understanding of well-being will come from".
Daniel Kahneman: "You know we never asked a forecasting question uh I'm reminded of a of a Hebrew proverb which said that prophecy Is For Fools and and I really don't you know I don't have any forecasts I think that it's obvious that if you want to know what's going to be interesting in in the next 20 years and 30 years you should be looking at what graduate students are doing now you know I personally am fascinated by the brain I'm fascinated by artificial intelligence and by genetics you know I think that those are big departures but I wouldn't forecast that this is really what's going to happen thank you Danny um it's been a great privilege to me to be able to sit here and ask a few questions but I think I should and I would want to share their privilege with everyone in the room who if if you have a question for Danny um please raise your hand and we'll make sure um that uh Stewart gets to you with a microphone I must say it's a real pleasure to be able to ask a question like this if you think about all the things that you discovered think of the things you discovered not just pure ideas looking back what do you think was the thing that most surprised you the one discovery that sticks in your mind is you would really not expecting that is there one it's very hard to say because when you really understand something then it seemed that you understood it always so uh I think that the discovery that excited me the most that of Discovery was was that people make non-regressive predictions and ignore base rates when they're making predictions that was that was quite new to me and surprising and exciting other things that I've worked on are typically".
Daniel Kahneman: "Sort of main effects that are pretty obvious to introspections so I I haven't I haven't had deep theoretical insights that you know I deal with obvious things questions ah mark thank you so much for this opportunity".
Mark Williamson: "Mark Williamson from action for happiness you talked about alleviating misery as opposed to promoting happiness but I'd love to ask you about this sort of action side of that which is at two different levels really what would be your top recommendation from what you've looked at for a policy maker big picture to try and alleviate misery where we're struggling and also from an individual perspective so many people are struggling right now with low well-being what would be your top insight for an individual to try and help them get further up that that well-being scale".
Daniel Kahneman: "Well you know in terms of software policy what I'm going to say is Trivial to all of you I would say mental health and loneliness you know would be the first obvious concerns and and I think that that they're widely accepted as as aims as goals for policy I would say something very similar to what we just heard that time is a very limited resource and spending it well is at the most important decision that you're going to make and making decisions and constraining yourself in the sense of setting up habits and setting up structures that that make you use your time wisely would be my best advice I don't personally follow it much but uh Casper I haven't you haven't given me the opportunity to say something that I wanted to say that my my main contribution to the study of well-being has been was really to get Richard LED interested in it and my that is really something uh that I feel very proud of actually uh and I actually made another contribution that's not well known I participated in the setting up of the World Poll and I actually wrote the emotion questions and it turns out which I didn't know that they convinced Jim Clifton who directed The Gallup at the time to to use the Cantrell ladder which I know John doesn't like but can I belabor that point a little bit as though because we've now been talking about um different definitions of well-being and what could be optimized so it's more conceptual in nature but the latest data we saw".
Host: "This morning some of the larger Trends in well-being by John and others um what I know that you've been reading the Jim cliff and son John Clifton's work and his recent piece in the economist about the disturbing trends that we're seeing on negative emotions and do you want to elaborate a little bit on that".
Daniel Kahneman: "Yeah I mean you know when I've is clear from the Gallup data I mean that's a huge change it's like 10 percent increase over the last decade in negative emotions so when you see a finding of that magnitude I think your first thought ought to be is there an artifact I mean and but what I what I gather is that actually there are many data from other sources that broadly confirm it and this is huge because you know things are really very stable in the domain of uh and to see it to see such a change and 10 is enormous can I it's actually worse than 10 I looked up the statistics in the last decade it increased negative emotions globally increased 20 percent so and it's especially worry and stress have moved up with about um what was it about 25 of people experiencing them on a day-to-day basis in 2010 and that's now up to well above 30 of the time that people are experiencing these negative emotions on a day-to-day basis what's really striking I think is what I meant by 10 was not 10 percent of how it was I meant 10 in absolute terms in terms data it goes from 25 to 35 percent thank you Danny you're right the I do want to point out I I find that personally very disturbing too in no small part because it's against the backdrop of growth low in employment and the pandemic obviously exacerbated this trend um and now at the end of the pandemic has come back on that negative Trend uh that it was on so it is something that I think we as well-being Scholars should really be sounding the alarm bells on just like Andrew Oswald did this morning or John Clifton is doing in his pieces is that these negative emotions are such a rising Trend that um it should be active upon yeah I mean I certainly resonated to Andrew's talk this morning that you know this looks like something that's getting ready to explode certainly in the United States questions um oh Casper oh you Casper you're ready to go thank you".
Casper: "So I know that you're th".
Casper: "At you're not a prophet um but but you were involved in both the experience sampling method and the the day reconstruction method so I'm just wondering what do you think how will we maybe globally measure well-being in 30 years".
Daniel Kahneman: "Uh well I mean I have no idea really uh clearly one thing that we didn't anticipate when we did the day reconstruction method it we thought of it as a very as a substitute for experience sampling which was Impractical you know then shortly thereafter the the iPhone came on the scene and the problem was saw it's going you know we're going to continue to measure experience that's clear it's also clear already so I'm not making you know long-term prophecies about 30 years from now but wearables are going to to come you know we're going to know a lot more about what happens to our bodies and and this is going to happen soon it's it's happening now and certainly those things are going to interact and to be used together uh Paul Dolan and then we'll go to the other side about 60 of people choose to be choose to maximize life satisfaction over happiness and 40 of our sample choose to maximize happiness over life sat so that's the first point I made um the second point is time use we all agree is absolutely Central to our own happiness and well-being that does require us I think to measure experiences more directly um and then the third point was very quickly on the motivation and the goals that individuals have is a not necessarily the best yardstick by which to judge which measure people should use because we know that people make all sorts of mistakes and errors in their in assessing happiness can you oh boy now I think the first question really is Paul did some work uh survey work at the end with LLC students showing that 60 of them do indeed prefer life satisfaction but that's not an overwhelming majority either so I think Paul thank you so I think but Paul is cautioning you a little bit on that move from affect to life evaluations yeah on on that question uh I think that what guides people in the in their long-term decisions is not a view of experience and and I was talking long-term decisions not the you know if I'm if I'm asked do I prefer you know something today or something tomorrow t".
Daniel Kahneman: "Hen I prefer something today uh that's clear and I prefer experiences when they are short-term I was referring to the long term and in the long term I don't even know what it would mean to try to maximize experience but clearly maximizing success in life for maximizing life satisfaction which is really I think I don't know which is a proxy for which but it's clear that what defines life satisfaction in terms of its predictors is really quite conventional success and much less experience I knew my name is Nova genevi I came from United Arab Emirates University it's a it's an honor to see you in person my question for you is an advice that you would give to a new researcher like myself sometimes those who are interested in the field of well-being sometimes I find myself I'm talking about my experience and my colleagues as well that we struggle between defining well-being measuring well-being educating well-being and trying to influence policy makers at the same time what advice would you give us".
Daniel Kahneman: "I wouldn't give you any advice you know I'm you know there is a lot of diversity people pick different things to do and the the mix more or less works out and more or less corrects itself and I you know as individuals you really have the luxury of choosing your problems and that would be the advice I would give which is really it right thank you I think we've got time for two more questions uh yeah thank you Amanda thank you very much um so you were talking about how particularly around emotional happiness it's so much about who we are with so the importance of social connection and not feeling lonely but I was wondering if you've done any research or have considered also looking into a lot of the like data around how our relationship with nature and spending time also in nature has huge impacts on our our happiness clearly that's something that you know studied experience sampling I'm sure are going to bring out to light that this is a huge effect on how people feel it's the weather it's nature it's you know it's trees Greenery water and it and there are children in you know Urban the urban poor who've never seen nature making that part of Education and making sure that everybody knows the joys of nature that I think is".
Daniel Kahneman: "A worthy policy objective that's not about reducing misery but it's really about something positive it's the wonderful work done by George McCarron and mappiness and these kind of experience based sampling using geotags as part of a iPhone pulse surveys they've really been able to show very concretely the proximity to green or blue spaces like the Thames for example and the Royal happiness report chapter very positively related to how you feel and especially if it's with other people that you enjoy spending time with and even more so if you're doing it actively by moving such as joking together last question yes just going back to the idea of this experience versus the memory of you know mindfulness which I know Richard's a big fan of as well we talk a lot about you know focusing so much about being in the present moment and not worrying about the future or ruminating about the past and how do you acknowledge how do you marry that with saying okay let's focus on life satisfaction or memory of things when we know a lot of research is showing that more mindful we are the more we are in the present moment the happier we are and there is you know mindfulness is actually highly active I mean you're doing nothing but it's that that you're actually completely focused and I was interested when we were mentioning television earlier and the amount of Television watching that there is television and mindfulness are both passive physically but they're radically different and so it's not that when you watch television it's not that you're in the moment you you are nowhere in some sense and so being in the moment is a very different art yes thank you um I wanted to say when we started the conference planning we became pretty clear to us that we wanted to come up with Awards or prizes to recognize exceptional research and contributions at different stages in people's careers and the first of three prizes that we thought up was the distinguished career award and um Danny featured Tai on the list to begin with when we found out he was actually coming it was decided pretty soon and direct who we would want to award the distinguished career award in well-being science too now we we were joking at the center needless to say that i".
Host: "T doesn't quite figure next to a Nobel Prize but but but Danny please consider this a heartfelt thank you from everybody in the well-being science community thank you".
 
Interview 25. UNSW 
Here is the full transcript of the UNSW conversation with speakers Daniel Kahneman and Ben Newell.
BEN NEWELL: Welcome to Daniel Kahneman in conversation. My name is Ben Newell and I'm a Professor of Cognitive Psychology here at UNSW Sydney. This event is presented by the UNSW Centre For Ideas. Throughout the discussion you can comment on Facebook or use the live chat on YouTube or post on Twitter using the hashtag UNSWideas. I would like to acknowledge the Bedegal people that are the traditional custodians of this land. I would also like to pay my respects to the Elders both past and present and extend that respect to other Aboriginal and Torres Strait Islanders who are present here today. This event celebrates the launch of the book Noise, written by Daniel Kahneman with Oliver Sibony and Cass Sunstein. It is my very great pleasure to introduce Daniel Kahneman.
Daniel Kahneman is best known for his work with Amos Tversky on human judgment and decision making, for which he was awarded the Nobel Prize in Economics in 2002. Kahneman has also studied a number of other topics, including attention, the memory of experiences, wellbeing, counterfactual thinking and behavioural economics. He published Thinking Fast and Slow in 2010 which has sold more than 7 million copies worldwide. He is currently the Eugene Higgins Professor of Psychology at Princeton University. Today Professor Kahneman is joining us from New York.
Danny, thank you so much for speaking with me today.
DANIEL KAHNEMAN: My pleasure.
BEN NEWELL: I'd like to begin by asking a question that some of our audience might wonder about. How does a psychologist end up being awarded the Nobel Prize in Economics?
DANIEL KAHNEMAN: Well, of course, you know, luck must be involved and luck was involved. Amos Tversky and I studied judgment and decision making, which are topics that economists are interested in. Decision theory, which we were working on, is considered one of the foundations of economic theory and a paper that we published on decision making was published in the major theory journal of economics called Econometrica. We didn't publish it because we wanted to influence economics, that was not our objective, but that was just the major journal for publishing papers on decision making. But economists paid attention to the work. It influenced a few people. It influenced in particular Richard Thaler, who's now known as the guru of behavioural economics and got a Nobel Prize four years ago and is my best living friend.
And we influenced him, we published a few articles together. He created behavioural economics and I got too much credit for what he did. So that's how it happened.
BEN NEWELL: I think that's a very modest response. I wonder - so a lot of that analysis and paper and discussion came out of thinking about whether or not people are rational and one question that I always wonder about is to what extent does it make sense to describe people as rational versus irrational, given that that word has so many meanings, different meanings to different people?
DANIEL KAHNEMAN: Well, I think it makes very little sense. I very rarely use the word rational and I never use the word irrational. Rationality is a technical concept in decision theory and it's a logic. So it tells you how to - how your beliefs and your preferences must be organised to be internally consistent and coherent and this is how rationality is defined. And rationality as defined is completely impractical for human minds. A human mind, finite human mind, simply cannot meet the requirements of rationality as defined in decision theory.
So the question of whether people are rational or not is in some sense not even an interesting question. Rationality is sort of a convenient assumption for economists. And it is true that when Amos Tversky and I did our work like more than 40 years ago, economists sort of believed in rationality as a useful description of how people think. They didn't believe their wives or spouses were rational, they didn't believe their deans were rational - that was a comment that Amos Tversky always made - but they believed that people in general are rational.
and the work that we did was considered a critique of that idea, of that assumption, that people in general are rational and it's an easy target. I mean, it was very easy to show that people do not satisfy the extremely demanding axioms of rationality, the logic of rationality. So that's what I think about rationality.
BEN NEWELL: Okay. I wanted to turn now briefly to discuss your previous book, the Thinking, Fast and Slow book, which has been incredibly popular and influential. One of the central ideas - indeed, the characters really in that book -
were system 1 and system 2, so the two systems that produce our judgments and decisions, and this idea has become immensely popular. I find myself talking to doctors, lawyers, government, firefighters who all now use Kahneman's two systems in their discussions. My question is do you think that this systems dichotomy has become too literal and that what might have started as a useful characterisation has ended up potentially oversimplifying the complexities of human cognition?
DANIEL KAHNEMAN: Oh, absolutely. I mean, there is a familiar rule that psychologists are taught very early which is not to explain the behaviour of people by the behaviour of little people inside their brain - homunculi they're called - and this is a no-no when you're doing psychological theory and it's a no-no that I very deliberately violated, that is, I chose the language, I didn't invent system 1 and system 2, both the ideas and the terms existed when I started working on it, on the topic. I borrowed them and developed them. But I deliberately chose this image of agents with personalities, system 1
and system 2 and they have propensities and they have traits and they do things and they interact with each other and this is clearly an oversimplification. What I really meant to say - and I was very explicit in the book about what it did mean - is that there are two types of processes, two main types of processes, and even that is an oversimplification, but there is one process that is rapid and automatic and effortless and there is another process that is effortful and controlled and, in general, slower.
So there are those two kinds of processes and all I did was in effect say the processes of type 1, think of them as if an agent called system 1 is producing them, and similarly for type 2. It turns out, and that's the reason that I did it, that people find it very easy to think about agents. Thinking about agents is a lot simpler and easier and more compelling than thinking about categories or types. So system 1 and system 2 as systems of thinking are much easier to deal with and much easier to think about than type 1 and type 2.
However - and here I agree with you completely - people have taken me much too literally and so people believe, seem to believe, quite a few of them, that I suggested there are two actual systems in the brain and that these two systems fight it out or interact with each other and I get questions like do dogs have system 2 or do infants - whether there's system 2 in infants and things that really make very little sense because that description, as I think you were indicating, has been oversimplified. So part of the appeal of the book is that oversimplification.
Part of the appeal of the book is that it made it easy for people to think about a distinction that is real and important, which is a distinction between two fundamentally different ways I think in which thoughts and ideas come to mind. Some ideas happen to you, like 2 plus 2 and then 4 just as a thought happens to you, and other ideas you've got to produce, like 24 times 17, you'd have to work at it to figure out - I think the answer is 408 - -
BEN NEWELL: I'll believe you.
DANIEL KAHNEMAN: - - but most people would have
to figure it out. I happen to remember it. And that is work and that is really very different what happens to you when you are filling in an income tax form or when you are computing multiplications or when you're deliberately searching your memory. That is a very different state of mind than the state of mind in which you are when you're responding to 2 plus 2 or responding emotionally when somebody says your mother, that evokes an emotion, or the word vomit, that evokes an emotion. Those are immediate, they happen to you.
So that's system 1 and system 2 or type 1 and type 2 and there are costs and benefits. I think knowing about system 1 and system 2 is better than not knowing that there are those two types of thinking, but at the same time, oversimplification should be discouraged if possible.
BEN NEWELL: Yeah. I guess one of my concerns with the distinction between system 1 and system 2 - and you write a little bit about this in the new book, which we'll get to in a moment - is that there can be a kind of laziness in the use of biases
and errors and almost like an abdication of responsibility that people say, "Oh, that's my system 1, there's nothing I can do about it", and it kind of reinforces perhaps in a self-fulfilling way this notion of irrational, errorful humans that can then paint perhaps too negative a picture. That's one worry I have.
DANIEL KAHNEMAN: I think you are giving the book much too much credit. I don't think it has any influence about how people think, good or bad. I don't think it helps people think much better and I don't think that it makes people more tolerant
of their own intuitive thoughts. That's a criticism I would not accept I think. I think it is true that a lot of thinking is automatic and intuitive and not founded on logical reasoning and yet completely convincing and compelling. I think that most of the things that we believe we believe for reasons that have very little to do with logic or with reasoning. So in that sense I may be more extreme in assuming that the role of type 1 processes or the role of system 1 is larger than perhaps you do.
BEN NEWELL: Okay.
Another - it's the final question on the two systems, is the contrast between the automatic and the more deliberative. The deliberative thinking is often - we describe it as effortful and hard and, you know, the thing that's involved in doing our tax returns, but there are also instances in which we seek out that effortful thought. So I'm thinking of mental games that we like to play - cross words, sudoku. Some of your very early work on attention and thinking about attention - I wonder what's your thoughts
about that value of mental effort versus the cost of mental effort?
DANIEL KAHNEMAN: Well, it's absolutely clear that mental effort is one of the major sources of joy for many people. So the states of flow, you know, that sort of extraordinary states in which people are totally absorbed in what they're doing to the point of forgetting themselves because they are so absorbed, is a marvellous state to be in and it's a very effortful state. People are intensely concentrated and intensely focused and intentional.
Their mind is not wandering. They're working and they're enjoying the work. So that is certainly the case. It is also true that when people are not deliberately and intentionally challenging themselves, the law of least effort tends to govern. That is, if there is an easy way and a harder way of getting to a goal, we have a preference for the easier way and that is true both in the mental context and in the physical context I believe.
BEN NEWELL: Okay. I'd like to turn now to your new book, Noise. You can see that I've been - it's on the camera.
You can see that I've been reading it intently and marking various different sections. So just to begin, you write provocatively that whenever there is judgment, there is noise and more of it than you think. I'm going to delve into those different types of noise in a moment, but just to start off, can you describe what you mean by noise and how it differs from that more familiar concept of bias?
DANIEL KAHNEMAN: Well - well, noise is a complicated concept, as we'll see, because there are forms of noise, but the form
of noise that we are most interested in and that motivated the writing of this book is system noise and this is not a phenomenon within one person. This is variability across people, this is variability in a system that produces judgment and there are many such systems. So the judicial system produces sentences. The underwriting system in an insurance company produces evaluations of risk and sets premiums. The patent system grants patents to some discoveries and denies them to others. The emergency room in a hospital is a system
for producing diagnoses and treatments. And now those systems when we are considering them, they are populated by different people who fulfil the same roles. So there are judges passing sentences, different underwriters, different ER physicians. And what we would want in facing such a system is we would want them to have one voice. That is, clearly you would not want the sentence of defendants, the time that a defendant would spend in prison, to be determined by which judge happened to be responsible for the case that day.
Somebody who faces an insurance company and asks for a premium really does not want the premium to be determined by a lottery. And so system noise is a problem and system noise can be viewed as a source of errors, and here maybe I should elaborate for just a minute.
BEN NEWELL: Please.
DANIEL KAHNEMAN: The concept of noise in judgment is borrowed from measurement noise and altogether I view judgment as a species of measurement and measurement noise is when you're trying to measure the same thing, the same weight, the same length of line.
When you're trying to measure the same thing with an instrument and you do that repeatedly, you really want to get measurements as close as possible. You want variability to be as small as possible. That variability is called noise and the noise - and there is an immediate analogy between measurement noise and system noise within organisations. So that's the concept of noise. It's completely different from the concept of bias. Bias is a concept within individual psychology. That is, we think of bias as a psychological process
and we detect or identify bias sometimes in a particular error in a particular judgment, but we cannot identify noise in a particular judgment. Noise is a characteristic of a set of judgments, it's a statistical concept, and in that way it's very different from bias.
BEN NEWELL: And do you think that the fact that it is a statistical concept is one of the reasons why it's remained obscure? You write about it in the book as it being obscure in the public conscience, it's not something that's widely discussed, because it's a less tangible kind of -
•	DANIEL KAHNEMAN: You know, one of the themes that I developed in my previous book, in Thinking, Fast and Slow, was that people have a preference for thinking causally and about particular events and objects and they have a lot of difficulty thinking statistically and thinking about properties, statistical - non-causal, statistical properties of ensembles of objects and that maps very precisely on to thinking about biases and thinking about noise, that thinking about bias or about - you can see it in an individual error and bias is really causal, whereas noise
is inherently statistical. And I think for that reason bias is much easier to think about. Noise is quite difficult to think about. So it tends to go undetected and undiscussed and that was the motivation for writing that book.
BEN NEWELL: And in the book you distinguish between several different types of noise - system noise, level noise, pattern noise. I wanted to talk a little bit about the pattern noise for a while, if we may. So I understood pattern noise to have these two different aspects to it, a stable pattern noise and a transient pattern noise.
So to start with, this stable pattern noise is the kind of idiosyncrasies we have as individuals. I think at one point you talk about it as a judgment personality. And so what I wonder is how we reconcile our desire for creativity, for individual difference in opinion and in thinking with this need to eliminate the unwanted variability, the noise? So, for example, in a hiring decision we might like to have different opinions from different people. How do we deal with that balance?
DANIEL KAHNEMAN: Well, there are contexts
in which we clearly want diversity, we want diversity of opinions, and we are really not interested in uniformity. So we don't want all film reviewers to have exactly the same opinion. So there are many contexts in which diversity is desirable. We define noise as undesirable variability. That is, noise is variability where you don't want it. And in the context of hiring, for example, you really have to distinguish two different aspects of the problem. You could have several people involved in hiring a candidate and if each
of them brings a separate angle, so one of them is an expert on subject matter and the other one is a psychologist who evaluates the person's characteristics, or whatever, then they are bringing different inputs to the decision. This is very different from a situation in which you have an individual who is hiring who is interviewing a candidate and is making the decision to hire and another individual could face the same candidate and make a different decision. That is noise. It's not diversity that we want.
So we want the final decision to be the same, but we very frequently want different people to provide different inputs and when they provide different inputs, we simply don't call it noise. Noise is unwanted variability in a final integrated judgment or decision.
BEN NEWELL: So thinking of it in that way puts the onus on the organisation or the system as a who will to define the situations in which noise is desirable versus - or variability, rather, is desirable versus isn't desirable?
DANIEL KAHNEMAN: Absolutely.
And altogether - I mean, this is the orientation that I have in general, and I had it I think even in the previous book, that organisations - it's much easier to improve the thinking and the decision making of organisations than to improve the thinking and the decision making of individuals. Organisations think slowly, they have procedures, you can intervene in the procedures, you can standardise procedures, and there is a chance of improving things that really doesn't exist when you're trying to improve your own thinking.
BEN NEWELL: It's an interesting thought that changing the way an organisation thinks is easier than changing the way an individual thinks. I can think of university committees where that doesn't appear to be the case, but - -
DANIEL KAHNEMAN: Well, I mean, you know, I'm not saying that it's easy. I'm just saying that changing individuals is even harder.
BEN NEWELL: Right.
DANIEL KAHNEMAN: And achieving real change is even harder.
BEN NEWELL: So the second element of pattern noise that you talk about is the transient occasion noise and the idea here
is that there are irrelevant features of the context or the situation that nonetheless influence judgments. You give an example in the book of a judge potentially being more lenient on a Monday if their football team won on the weekend. You also discuss some of the work of my colleague Joe Forgas on how mood affects people's judgments. I wonder how concerned should we be about these irrelevant features that we're potentially unaware of influencing our judgment?
DANIEL KAHNEMAN: Well, I think the general picture is this,
that - take the example of judges passing sentences. So the first thought that comes to people's mind when they think about noise is that some judges are more severe than others, so that on average there are differences in their biases. That's one type of noise. And also judges differ in - I mean, within judge there are variations from one day to the other and we should be concerned about that. We don't want - the defendant really should not - well, the defendant's fate should not be determined by, you know,
the football events of the previous Monday or by the judge's current mood. So none of these sources of noise is really acceptable and some of them are harder to cope with than others.
BEN NEWELL: I might try to relate - so one of the thoughts I had when thinking about these occasion noise or these contextual situations that affect our behaviour whilst remaining somewhat out of our awareness, it put me in mind of some of the studies that you talked about in a great deal in the earlier book, in Thinking, Fast and Slow, where they're high-profile studies
in which people's behaviour was said to be influenced by features that they were unaware of. So I'm thinking of the social priming-type studies where perhaps, you know, I read about an old person and then I walk more slowly down the corridor, and I can see by the reaction on your face that you know where this question is headed, but there was - the inability to be able to replicate some of these standout studies led you to warn of an impending train wreck for the discipline a few years back and subsequent ripples of that - your letter
across multiple disciplines. We're seeing these patterns of replication, these attempts to see what's real in our science. And I'm fascinated to know whether or not you think we've emerged from that wreckage or avoided that wreck. What's your current thinking on these sorts of studies?
DANIEL KAHNEMAN: Oh, that's a dramatic change of topic. It is true that when I wrote Thinking, Fast and Slow I was very impressed by literature on priming and those were subtle, fascinating effects where a small change in context seemed
to have a significant effect on behaviour and I think now that I was gullible. I think that I believed in these results, although if I had looked more carefully I would have seen that the studies were individually fairly weak and with small samples, the effects were too large to be true in some sense. So yes, I became - and that really hurt me because I had put a lot of faith in it. And so I wrote a letter which, by the way, I did not intend to be published - I wrote a letter to people in the priming field
and I still believed in priming when I wrote that letter. I believed in it much more than I do now, in priming has a strong effect, and I asked them to get their act together and to replicate themselves so that people would believe them because it was clear that people were already failing to replicate priming. I think the current state of play is quite interesting that researchers in priming have never admitted that they were wrong. Other people have failed to replicate them very consistently, but the main thing that's happened is that, in part as a result
of this and in part as a result of the whole issue of replication in other sciences, not only in psychology, the science of psychology has improved enormously over the last decade. I think standards have become much higher. I think sample sizes are higher. People are much more careful about their reasoning and pre-registering their studies. And the methodological quality of psychological research, it's hard to believe how much it has changed. You know, the letter that we're talking about that was not intended
to be published was written in 2012 - -
BEN NEWELL: Mmm-hmm.
DANIEL KAHNEMAN: - - and in nine years the field has really changed completely - no thanks to my letter but because of other events that were already happening within the field and in the context of replication more generally.
BEN NEWELL: So you have a very positive outlook then on the future for the discipline? You think that it's now headed much more in the right direction?
DANIEL KAHNEMAN: I mean, I think it's remarkable how much has happened in a very short time.
I mean, it is now standard to - the kinds of problems that gave rise to unreplicable findings have really been tackled and so there was a very important element of self-deception. This was not fraud, but researchers allowed themselves degrees of freedom in interpreting the results and, you know, I know because I did it myself, I caught myself having made those errors. And today people are much stricter with themselves and they have to be public about the precautions that they take in carrying out their research.
So I think the main thing, you know, the priming scandal is a minor event relatively and the change in the methodological advance in the discipline is a major event and that's what's really happened over the past decade.
BEN NEWELL: Okay. Thank you for allowing me that segue or that brief tangent there. So I want to return now to the issues that come up in the new book, in Noise, and a central feature of your career has been on trying to understand the benefits and pitfalls of intuitive judgment, and many of us often like to rely
on what we think of as our intuition when we're making these kinds of judgments. Intuition is a term which I guess is perhaps hard to define. I like the definition that you often use, which is Herbert Simon's one, that it's nothing more and nothing less than recognition. But in the book you write that intuition should not be banned, but it should be informed, disciplined and delayed. This might seem at odds with the sort of fast and automatic way that people often claim to use intuition. So why do you think we need to delay and why is it that that internal signal
delivered by intuition is so seductive? And if I might just append a question from a current student that was submitted. So Irfan Muhammad, a current UNSW student, asks "Why sometimes when we focus and eliminate all kinds of noise we don't arrive at a solution in our minds, but when we do something else, the solution can suddenly turn up like a Eureka moment?" Is that an example of what you think of as intuition?
DANIEL KAHNEMAN: Well, that's a separate question. Let's return to it. I will probably forget it by the time I finish
answering one question, but you'll have to forgive me for that. The definition of intuition as recognition is sort of a technical definition. The way that people - the definition that captures people's attention is that intuition is knowing something without knowing how you know it and that is a subjective feeling of confidence that there is something that you know or something that you understand, although you cannot quite justify it. And quite often, there's no question about it, there are intuitions that people have which are truly marvellous and
they are very rapid in many cases. So all of us - my favourite example of that is talking to your spouse on the telephone and you can tell your spouse's mood on the telephone from the first word that you hear and this is a lot of practice and we're rarely wrong. You can tell whether he or she is happy or angry or depressed. We can tell an awful lot from one word. That's intuition and it's marvellous intuition. It is usually very - it's usually correct. Many professionals have intuitions that are marvellous.
So chess players can look at a chess board and have an immediate intuition about what is the correct move. Physicians can recognise, can make a diagnosis from across the room in some cases and very likely to be correct. So intuition can be marvellous and it's a characteristic of fast thinking that it happens quickly. However, that subjective sense of having an intuition, you can get it without justification. You can get it when actually what is happening is you are going wrong, you're following a mistaken heuristic of rule of thumb.
Some inconsequential or uninformative bit of information is leading you astray. The characteristic of our thinking, of intuitive thinking, is very high subjective confidence and confidence - and that is a fundamental fact about I think human thinking is that confidence is really imperfectly correlated with accuracy. So it's true that we're confident when our intuitive thinking is right, but we're also confident when our thinking, our rapid thinking, is wrong. So the recommendation in the current book that was explicit was
to delay intuition and if you want me to I can describe the origin of that idea, but I don't know whether this is where you want me to go.
BEN NEWELL: No, I would like to hear where that idea comes from and how we know when we should delay it, I suppose, and how to do it.
DANIEL KAHNEMAN: Well, in my mind the idea goes back a very long time ago when I was a lieutenant in the Israeli Army - and that was in the 1950s and I'm really embarrassed to say how long ago it was - and I was assigned the task of setting
up an interview system for combat recruits which was really intended to evaluate the suitability of recruits to combat units and there had been an interview - there was an interview system in existence which was the standard unstructured interview where the interviewer spoke to an individual and tried to form a general impression and eventually got a sense that he or she knew the individual, could tell how good a soldier that individual would be. And that actually had very low validity. So people had high confidence in their intuitions and
they were essentially useless and this is very common - that is, it's well known that unstructured interview produces a lot of confidence in the interviewer and very poor validity on average. Now, the system that I devised under the influence of an important psychologist, Paul Meehl, who had just published a book on that - the system I devised involved the interviewer giving six scores to the recruit on different characteristics - on punctuality, on sociability, on - I had a characteristic you wouldn't use now, masculine pride,
and there were six of them and the idea was for the interviewer to ask factual questions leading to a score on each of these six attributes. And my initial plan was that we would just take the average of these six scores and that would be a judgment of how well the recruit - you know, the best guess as to how well a recruit would do. The interviewers who were on the job and who had been using unstructured board of interviewing were furious with me and they were furious because they wanted that sense of intuition, they wanted the sense of getting
to know someone and they wanted to use their clinical ability and I remember being told by one of them, "You're turning us into robots", that is by this sort of mechanical way of doing it. So I compromised and my compromise was I told them, "Well, you do things the way I told you, you get those six scores, but once you have completed the six scores, close your eyes and make a judgment, an intuitive judgment, how good a soldier would that person be." Now, a few months later we had the results of that study
and the results were that we were doing a lot better than in the unstructured interview. Today that's not a surprise at all. But what was surprising to me then was that the final intuitive judgment, close your eyes and make a judgment, was highly valid and it added content, it added validity beyond the six traits that had been evaluated. So now the lesson I drew from that was that intuition does work, but you want to resist forming an intuition too quickly. You want to resist in the more recent terms, you want to resist fast thinking.
You want to collect the information, you want to develop a profile of the case and then you can allow yourself an intuitive judgment. And this I realised many decades later can be generalised to decision making. So when you are making a decision between different investments, you can think of options as candidates and apply the same logic to options as you would to candidates, by which I mean that any option you can characterise in terms of a set of attributes that make that option more or less desirable, you can evaluate each
of these attributes in a fact-based way and collect a series of scores and create a profile for that option and then, and only then, allow yourself to have an intuitive global evaluation of that option. So that's the idea of delaying intuition and I think there is a fair amount of support for it and certainly it's a major recommendation in my last book, so it was personally quite satisfying to go back to an idea that I had developed 60 years earlier and use it again.
BEN NEWELL: Yes. I found that that theme running through was very kind of -
I guess maybe I was getting an internal signal from the coherence or the cohesiveness of the argument there. You made a comment just now about the resistance of being turned into robots and one of the decision hygiene strategies that you talk about in the book, ways to sort of avoid noise or clean up noise, is to do with relying more on algorithms, so there's a rise of advisor systems of algorithms everywhere at the moment. One of our audience, university alumni Lenore Guildthorpe, asks "Do you believe that artificial intelligence,
relying on algorithms, will be able to match the way that humans think?" We also had a question about whether - how best should we work with algorithms, how should humans interact with these algorithms?
DANIEL KAHNEMAN: Well, you know, this is a very loaded topic and artificial intelligence is going to I think produce major problems for humanity in the next few decades. But with respect to judgment, there is a long history of research covering human judgment to rules, to various - the rules can be very simple, but the essential aspect of those rules
is that they are noise free. That is, when you apply an algorithm or a rule to the same case on different occasions, you are going to come up with exactly the same answer. That's noise free. It turns out there is so much noise in human judgment that for that reason alone rules tend to be superior in many cases to human judgment and in some cases vastly superior. Now, that's even - that was true even before artificial intelligence. It was true applying simple statistical rules and even imperfect statistical
rules just applied consistently will do better than people. Now, there is a history of trying to use - to combine rules and intuition that is providing people with the input of say artificial intelligence or some statistical analysis and one of the best-known examples of that was in chess. So in 1998 Garry Kasparov, who was then the world champion in chess, was defeated by IBM Deep Blue. That was sort of a very important moment in the competition between artificial intelligence and human judgment and Garry Kasparov, who has quite an opinion as well
as a brilliant man, he really did not like the style of the computer that defeated him. He felt that there was something mechanical, robot-like in Deep Blue and the style of Deep Blue. And his idea, which he maintained for several years, was that the optimal way to play chess would be by combining a very good chess player
 
Interview 26. The Psychology Podcast Best of Series: A Remarkable Life, Fast and Slow || Daniel Kahneman
 
Interview 27. TED Audio Collective 
ANDERSON: Hello welcome to the ted interview i'm chris anderson this is the podcast series where i get to sit down with a ted speaker we get to dive much deeper into their ideas than was possible during their short ted talk today i am delighted to have with us daniel kahneman danny kahneman is truly one of the greatest minds of our time he won a nobel prize in 2002 for his work on behavioral economics but his thinking has been influential not just in economics but in psychology and beyond the thing about danny is that he understands more than pretty much anyone just how weird our minds are and that means that he has something unexpected and fascinating to say about almost every psychological topic on everything from decision making through to something like happiness there is a huge wave of interest in happiness among researchers there is a lot of happiness coaching everybody would like to make people happier but there are several cognitive traps that sort of make it almost impossible to think straight about happiness the first of these trap is a reluctance to admit complexity turns out that the word happiness is just not a useful word anymore because we apply to too many different things my goal today is to talk with danny about how we view our own minds he's been examining human behavior for close to 60 years so what an incredible opportunity to look back on some of the insights he's gained over that time and discuss how they apply to our modern age danny welcome
KAHNEMAN: It's a pleasure to be here
ANDERSON: Danny you've had this extraordinary life you're in your 80s now tell us a bit about what put you on this path in the first place
KAHNEMAN: I think i've been a psychologist since i was a child I really I always blame my mother for it or give her credit for it she was a very interesting gossip and I loved to follow her gossip the sense that people were very interesting and very complicated and that nothing was black or white I spent a lot of time and I had a lot of time during the war I spent the war years in france and then under nazi occupation in part and in part in southern france running away from them and i had a lot of time to myself because I didn't go to school all the time there were periods where it was too dangerous to go to school so I was quite an introspective little boy but but I was thinking about about psychology really well
ANDERSON: And something amazing happened in paris that you've spoken about before
KAHNEMAN: So I was seven years old it was 1941 there was a curfew for jews and we had to wear a star of david a yellow star for which we had to pay with coupons the coupons for clothing and I was visiting a friend of mine and playing and I was told it was about seven o'clock I had missed the curfew so I put on my sweater inside out and I walked home and not far from home it was a deserted street I saw somebody walking towards me and he was a german soldier not only a german soldier he was wearing a black uniform that was the uniform of dss and they were those the most frightening of all and as we came close to each other he beckoned me and picked me up and I remember being terrified that he would see inside my sweater that he was picking up a little jew he picked me up and he hugged me very tight and then he put me down and took a wallet out and showed me a picture of a little boy and gave me money
ANDERSON: So that was a story that fitted with what my mother was telling me about people being very complicated and nothing being quite black or white no one who you think is evil is completely evil no one you think is good is completely good
KAHNEMAN: That was part of it that's right that sort of thing
ANDERSON: And so this this idea of the nuance of human nature really does seem to have been a foundation of so much of what you've done because many people go through life with quite a simple picture of humans talk about the that traditional what that traditional view of human nature has been especially even in economics
KAHNEMAN: Well there are many versions of what makes humans tick a particular version is the foundation of the science of economics and this is the so-called rational agent model the assumptions that economic agents are rational they're also supposed to be selfish and they're also supposed to know what they want and of course as a psychologist this sounds wrong and of course economists know that it's wrong it's just very useful to their theories
ANDERSON: And so was it in the the 70s that you formed this extraordinary partnership with amos tversky and started to question some of these ideas tell us about how that happened
KAHNEMAN: Our partnership and our friendship actually started in 1969 i had a seminar and i invited amos to talk to us in the seminar and he presented work that was not his work but that was a mixture of the traditions of economics and psychology and the conclusion they had reached was that humans are good intuitive statisticians and i thought that was ridiculous and so we had a heated argument israelis like to argue and it was one of those arguments where you know no quarter is given but people really quite like each other at the end of that argument we decided that we wanted to pursue it and i think i won the argument so amos was interested in following up the ideas that I had expressed and then we got together and we started collaborating and then eventually fairly quickly we discovered that we really liked each other and that we really liked spending a lot of time with each other that began an exceptional collaboration that lasted about 12 years
ANDERSON: So give us a hint of it because the core of the papers that you were publishing back then were around human decision making and the many ways that we kind of get it wrong in a sense is that right
KAHNEMAN: Well we started out asking about judgment under uncertainty that is how people assess probabilities how they make intuitive predictions and how they test hypotheses
ANDERSON: Give us give us an example
KAHNEMAN: I'll give you my best example actually I think it's a fairly complicated one but your listeners will follow so suppose I ask you to think about a woman I'll call her julie I'll tell you two things about her she is a graduating senior at the university and she read fluently when she was age four when she was four years old what is her gpa and a remarkable thing happens is that you every one of you has a number a number popped into your head and a gpa for those outside the us is is grade point average so and in the us it's on a four-point scale where four is very good and everybody has a number and the number comes to mind immediately and intuitively and we know two things about that number we know exactly what happens in the mind when the number is produced and we know also with certainty that that number is statistically wrong
ANDERSON: Okay so the number I came up with was 3.5
KAHNEMAN: Well you were on the low side most people said 3.7 but I will tell you possibly because I don't know what their gpa is right you didn't go to school here I'll tell you what happens because it's an example of how intuition works so you hear she was a precocious reader quite a precautious reader and you have an impression of how precocious she was it's not that you're thinking in percentiles but you have an impression of how strong it is and let's say it is in percentiles so she is somewhere maybe the 95th percentile now you also have an idea about the distribution of gpa and if you pick the 95th percentile for julie's reading ability you find the gpa which is also the 95th percentile and that's the number that comes to your mind now this is a very complex calculation nobody is aware that this is what they did but in fact this is what they do so they take the evidence they evaluate how strong it is and then they map the evidence directly on the conclusion and that matching is the result and the reason this goes wrong is that reading is only one component of gpa there are many others so if judged just on reading that 3.7 might not be a an unreasonable guess but her actual gpa is more likely to be the best guess about her gpa is that it's slightly above average but very slightly above average that's the best guess because indeed reading age is an inferior cue to a person's gpa and yet intuitively we predict as if we could predict perfectly on the basis of weak evidence that was one of the major findings of our early research
ANDERSON: So this work and much more you had many other super productive partnerships eventually led really to the field of behavioral economics flourishing
KAHNEMAN: Well I'm sometimes described as among the founding fathers of behavior economics I'm not I really I can't accept the credit for that paternity I'm sort of the godfather the real father of behavior economics is richard thaler who got a nobel prize this year and is my best living friend I think he's a genius I think the nobel prize was overdue and I'm very very happy he got it
ANDERSON: In the way that you have described your thinking in the book that you published a few years ago thinking fast and slow you talk about these two different systems of thinking that humans have can you elaborate on that a bit
KAHNEMAN: Yeah you know it's intuitively very obvious that there are two quite different ways in which thoughts come to mind so you know if I say two plus two a number comes to mind and you can see how that number comes to mind you can feel it you didn't choose it you didn't work for it it just came to your mind that's intuitive thinking that's fast thinking and you call that system one and I call that system one there are many kinds of fast thinking when you're an experienced driver and you drive it's system one type behavior emotions are part of that fast reaction system but it's both emotion and skills and then you have another system another way of thinking which you know is exemplified by you know what happens if I ask you to multiply 17 by four now you can do it you can do it in your head but it will take you some work and it's that work that defines system two the thinking of system two of slower thinking is effortful and it's focused which means that when you're doing one thing you're severely impaired or in some cases quite incapable of doing other things so you couldn't compute 17 times 14 while taking a left turn into traffic and you'd better not try because it would blind you actually if you went on with the computation you might not see traffic
ANDERSON: So how much can you equate to those two systems with actual different parts of the brain I mean is sister one more driven by older evolved brain structures and system two is the sort of frontal cortex overlay on top of that or is that
KAHNEMAN: Well not right you know because I don't think of system one as being primarily emotional I can't locate it I mean you know so emotions are localized somewhere else entirely you know memories memory somewhere else the system two which links self-control and intelligence that is in the prefrontal cortex or you know anyway we can identify that locus uh being active when people reason and when they invest mental effort whether it be in reasoning or in self-control
ANDERSON: I mean if you're going to write a book about system one system two and argue for people that they should understand their own minds better that is an appeal really to the system two and people's minds correct
KAHNEMAN: Yes but on the other hand we have to recognize that system two is slow and inadequate and if we try to let system to govern everything we do we'd be completely paralyzed I mean we're dependent on system one to cross the street we're dependent on system one to start us eating something and stop us when we're fed system one rules really and we can't turn over everything to system two what we can do maybe is when when you realize you're in a situation where you know that you're likely to make a mistake slow down and use system two but you can only do that sparingly it is not advice for how to run your life every minute of the day
ANDERSON: So whoever came up with count to ten before losing your temper had a point
KAHNEMAN: That's exactly it yeah 10 may not be quite enough but
ANDERSON: Well it's interesting because you developed one aspect of this in a in a different way when you when you came to ted in 2010 and gave your ted talk which was about two selves I think not the system one system two selves but um what you call the experiencing self and the remembering self and I think this came out of you'd spent years now starting to think about what I think you call hedonic psychology it's the sort of the psychology of happiness and well-being and discovered some really surprising things when you actually dug into that including that it doesn't really even make sense just to ask blandly whether people are happy that question is full of pitfalls talk about those issues and about the experiencing self and the remembering self
KAHNEMAN: Well I'll describe an anecdote which highlights the difference and I was giving a talk somewhere and talking about these things about experience and memory and and somebody said well I recently listened to a symphony and it was absolutely marvelous and at the end there was something wrong with the record and there was a loud screeching sound and it ruined the whole experience and if you reflect upon that sentence you know for a moment clearly it hadn't ruined the experience he had had the experience 20 minutes of glorious music but it ruined with the memory of the experience so that indicates that there is a real difference between actual experiences and what we get to keep but we get to store and what we get to store our memories and the memories are often not faithful to the actual event the emotional memory that we keep how much we like memory how much we hate it that's very strongly affected by how it ends how the episode ended like the screech at the end of the symphony and it's completely insensitive to the duration of the experience so almost completely insensitive so how we feel about memories really doesn't correspond to essential aspects of experience
ANDERSON: This is so interesting to me because it's it's not clear to me which self we should be championing here I mean you've done this remarkable research actually lots of different categories of research that track in the moment how people are feeling and then contrast that with how they report an event after in the ted talk you talked about these colonoscopies that a longer on any reasonable basis worse colonoscopy that had more pain over more time but which eased off the pain towards the end was reported by those who suffered it as less bad than those who suffered a shorter one that stopped suddenly
KAHNEMAN: You can absolutely improve the memory of a painful medical procedure these days colonoscopy is not a good example because uh people right out no no they don't remember anything but in the days that we did that research about 20 years ago going on 25 colonoscopy was really quite painful and you felt every second of it but it turns out that you could make the mem improve the memory of the colonoscopy by just adding some time to it provided that that time was relaxed or not completely relaxed still uncomfortable but less uncomfortable than before so it can improve a memory by adding an unpleasant bit to the experience provided that it's a diminishingly unpleasant bit
ANDERSON: And so you give these other examples of vacations where the vacation that is kind of bad but ends really well will be remembered as better than than the vacation that was long and wonderful and then ended in turmoil and that was the worst one that you then you then wouldn't choose to repeat that vacation even though many ways that seems irrational I mean do you have a view as to which of those two selves are remembering self or are experiencing self we should use our system to rationality to edit and say now wait a sec don't be taken in by that bug about ourselves should we edit better for experience or should we say no it's actually the story is what matters
KAHNEMAN: Well I don't have a clear answer to that but on the vacation I had a thought experiment which I think is useful which is you're contemplating a vacation and now suppose I tell you that at the end of the vacation you'll get a drug that will make you completely amnesic you won't remember anything and will destroy all your pictures so you'll have no record of it now does that change your vacation plans and that's an important question because here the remembering self has known will have kept nothing but the experience of self will have an intact experience and if you discover that you will change your plans that means that you're having memories you're having vacations to serve your remembering self that is you are constructing memories and you want to keep them I started out the research thinking that I was completely on the side of the experience itself I said you know there are two things there is living life and thinking about it and so you live life most of the time and that's the experiencing self and occasionally you stop and you say well how am I doing you know am I satisfied with my life and that's the remembering self so I thought experience is it we should measure experience that's the real happiness what people think about it really shouldn't matter and I held that opinion quite strongly for a few years and I gave it up and the reason I gave it up was that it turns out that this is not what people want people actually want a story they want their life to be a good story and they want to add elements to that story and those elements are good memories and so people really treasure memories and want to have them and so I was faced with with the position of you know holding a view of well-being which didn't correspond to what people wanted and so I'm now confused and I admit it there are those two cells the experiencing self and the remembering self and to make them happy you would have to do different things it is not the same thing that maximizes the quality of your experiences and that maximizes your satisfaction with your life
ANDERSON: And when you say people want the story is that both their system one thinking and their system two thinking wants the story
KAHNEMAN: Oh I mean I couldn't distinguish that you know we want the story I mean that's this is very deep and the way we think of our lives is we think of our lives as a story which is why by the way death bed reconciliation sometimes matter a lot you know people think that this is a very important thing to do to get back together which in terms of experience is nonsensical but what you have done because of the imports of ending you have changed the story
ANDERSON: But it seems really important when it comes to measuring happiness or human well-being because it seems like there are two fundamentally different research methods that do this one of which essentially is tapping into the experiencing self it's asking people at random moments uh what are you feeling right now are you happy uncomfortable right now and then there's the research that just says to people more generally you know taking your life as a whole how happy would you rate yourself on a scale of one to ten which seems to be more about the remember remember itself exactly are both those research forms valid and what do they actually reveal about the world now like how different are they the results
KAHNEMAN: I'm not sure everybody would agree but I think I should take some credit for the fact that current research on well-being typically measures both it measures the emotions not by tapping every minute which is the gold standard but by asking people questions about the emotions they have experienced and in addition they're asked what do you think about your life how satisfied are you with your life so both sets of questions are asked and it turns out that they're different what makes people happy in terms of experience I believe from our research is primarily social it's primarily spending time with people you love and who love you back that's what makes people happy in the moment what makes people satisfied with their lives is much more conventional you know it's success I mean it's also having a meaningful life having I don't want to define a meaningful life but having the sense that your life is meaningful is quite important and certainly if your sense is that your life is meaningless then you're probably depressed then you're certainly very unhappy
ANDERSON: There have been all these attempts to try to find a better way of measuring society's progress that somehow bring happiness into the mix you know how happy are people um happiness numbers don't seem to have moved much in america in 50 years you know and this is causing distress how could we measure that better
KAHNEMAN: I think you've proposed that we're looking at the wrong thing that there's so much ambiguity about happiness measurements generally a much more powerful thing to focus on would be some kind of misery index of minimizing misery I mean I think if I had my brothers and I don't but uh I would rename the field and I think if we said we're studying misery it would be a less joyful topic to deal with but it would be more useful to society and steps that would be taken to reduce misery would be more acceptable I think morally to people then steps to increase happiness mental health grief counselling old age
ANDERSON: Danny it feels like your work has made a huge difference in psychology and in economics but maybe it hasn't yet percolated that far out into other fields like journalism like democracy like just everyday conversation I'm curious if you have a view on this whether you think that we could do with much broader understanding of these issues of who we are and how we make decisions
KAHNEMAN: Well it certainly wouldn't hurt for people to be psychologically sophisticated I mean that's uh if I had to choose a focus I would choose walter mischel's focus on self-control rather than trying to improve your thinking I think working on self-control is easier and more manageable and has more immediate consequences than trying to control your thoughts or reduce your cognitive biases so I'm not a great believer in individuals improving their own thinking I do believe that organizations can improve their thinking but not individuals on the other hand I think working on self-control seems to be more promising
ANDERSON: There's a lot of hand-wringing at the moment about how people's self-control on the internet for example is not that impressive we we seem to be in this culture of gut-driven outrage instant responses click bait you know it's arguably driving a sort of cycle of unintended consequences including people gathering together in clans where they inflame their own anger at each other I think you're quite pessimistic about this and about whether we could change this but it seems to me in the seeds of what you've just said that people learning that they have these two parts to them and think knowing that there are tools whereby they could gain better self-control wouldn't that over time potentially yield a better culture online as well
KAHNEMAN: Well I mean you know you speak of this this was something that we could do it would certainly be a good thing to do if we could do it but you know it would mean changing the culture it would mean changing the educational system and uh and there would be a lot of opposition so it's not easy to to see it it would be better if people were more reflected and I I think there is no doubt that the ease with which news travel has detrimental effects but quite a bit of it might be doable just by changing the attitudes in some of the big media firms and in the silicon valley firms that drive what people see you know the algorithms that drive what we see are arguably designed right now based on a kind of you know system one what what they just observe what people do in the moment they're designed for fast thinking and they don't give anyone a chance to apply their slow thinking you've never been asked by an internet site would you actually like it if we shielded you from all the clickbait crap that were otherwise put in your site to try and make money I mean people might respond to that and I think that many of the people who are building those algorithms actually have good intent um they think they're operating for human choice they're just it's just a naive view of human psychology they haven't read you they haven't understood that there might be a different way of thinking that some people would actually elect to design for if they were given the chance
KAHNEMAN: Well you know my mother was a pessimist and so I'm a pessimist and I always see the dark side of things I'm not very optimistic about changing the media I mean you you could change things at the margin but basically these are market forces and people are getting what they want
ANDERSON: And let me push back on people are getting what they want people are getting what they want in the moment of clicking absolutely but society as a whole is absolutely not getting what it wants right now and you can feel that in the huge pushback so I think redefining what we say by what we want
KAHNEMAN: I was going to make a point about think of british tabloids you know which are the naked lady on page two and the stories of murders and rapes on page one that seems to be the popular press that's you know the look at the press in new york people want a certain kind of content and the media offers it to them now the kind of world in which all the media were like npr so many of us you know would think well npr is all anybody needs but it is not all that people want and so there are market forces which push media to give people what they want in the moment and it's very difficult to fight those market forces
ANDERSON: But in the old media world there were also market forces that created if you like quality media that apply different more reflective journalistic standards one worry of the current world is that unintentionally we've built these machines that automatically suck people to you may only have tabloid content we are going to drive you into an angry person by only seeing the stuff that will you will respond to and I I think you could make the case that there is there is at least some room to open a space for more reflective online media today that reflect the broader balance that there was
KAHNEMAN: You know I I completely agree that at the margin you can make marginal changes and whether you can change the essence of the system and you know make a really big difference that I'm less optimistic about people were living in their tribes before the media it has intensified a certain kind of thing that that you're completely oblivious to the other side and there's that echo chamber effect that the new media produced that is possibly stronger than existed earlier the phenomenon of political polarization and whether that phenomenon is controlled or caused by what is happening in the media that's unclear uh or whether what the media doing is they're reflecting the fact that we are in an age of increasing polarization and my sense of that polarization started first when you look at the political history you know things started earlier I mean in the early 90s the post-reagan world in in the reagan world which many of us you know were not we didn't think that was such a great world but in the reagan world there was a lot of civility and committee between the parties there was overlap and so on polarization began in the 90s it began before the the media the media just feeding it they're not causing it
ANDERSON: Well it's interesting to you describe yourself as a pessimist I definitely I'm an optimist but um I would like to think in in the kind of um the david deutsch definition of the term which is it's not a feeling of hope about the future it's just a belief that when you have a problem there's going to be a solution there somewhere we just have to try and find it and so definitely my mind's going to keep worrying on that in search of that possible solution even if it turns out to be only a marginal one let's turn to a slightly happier topic partnerships you've had an extraordinary series of extremely productive partnerships in in your life um starting with amos talk a bit about what makes a partnership a great productive wonderful partnership
KAHNEMAN: Well one condition is that people have to like each other so they have to like to spend time with each other I mean that's for true partnerships there are different kinds of collaborations there are some collaborations where different people each bring a particular skill and all the skills are needed but there is no overlap in scale between the individuals I have been in different kinds of collaborations where actually the skill sets overlap there is something distinctive and that can be really happy when people understand each other very quickly but keep surprising each other and I've had that several times in my life and there are a few things are more pleasurable than that in you know an academic's life than a happy partnership
ANDERSON: How much of a role does humor play
KAHNEMAN: Oh you have to be laughing you have to be laughing this is unless it's funny you can't go on so laughter is really the lubricant that keeps the whole thing going
ANDERSON: And occasionally if I'm not mistaken it sometimes sparks actual ideas like like laughter that you and amos had for example would occasionally spark a research question or
KAHNEMAN: Well I mean in our case our research was ironic research I mean we studied foibles weaknesses in our own thinking and in other people thinking so the topic of our research was funny but I've had collaborations on topics that were not specifically funny and where humor was always present I don't think you can do really without it you can do really good work without it
ANDERSON: Danny will you talk a bit about the partnership with your wife anne that was a professional relationship initially
KAHNEMAN: Well not quite I mean I heard ann give a talk 51 years ago she came to harvard and cambridge she was a young phd from england and she gave her absolutely brilliant talk to a very large audience of other mighty people it was sort of uh an unusual event and she was pretty and she was nice and and and I sort of fell for her and enough so that I changed my line of work and I became more more focused on attention which is what she was studying so and not to trace her but because I had changed my line of work I went to conferences where I met her and over the years we became friends
ANDERSON: So wait wait wait wait so you changed your line of work because you were interested in attention all because you wanted to go to conferences where you would see
KAHNEMAN: My landmark work because I was interested in what she had done uh she was doing fascinating work but it had the happy side effect that you you had the happy side effect that we saw each other conferences and eventually fell for each other and now 51 years later that's been a long relationship and you've published together and we did but that was not the happiest of collaborations we we actually our marriage survived but we we had a very hard time together we published some fairly important papers but we were not yeah we were we were not very generous intellectually to each other and we were really did not have the same intellectual style
ANDERSON: Danny you've led a long and extraordinary life what does your reflective self your system to yourself your your remembering self make of that life how do you describe your own life's meaning or purpose
KAHNEMAN: I have been extraordinarily lucky in all the public aspects of my life there have been some I've been unlucky in other ways but I've been extremely lucky in my professional life and the main bit of luck is that I've met wonderful people and they've become friends and I've worked with them and it's I attribute it entirely to luck but it's also the case that I was able to exploit it and to do something with it but it's mostly my friends you know when I look back at the history it's the friends of heart I've almost never worked alone and I've always loved working with others
ANDERSON: Danny um ted's mission is to spread ideas that are worse spreading if you could inject one idea into the minds of millions of people what would the idea be
KAHNEMAN: Don't trust yourself too much don't trust in ideas and beliefs just because you can't imagine another alternative to them overconfidence is really the enemy of good thinking and I wish that sort of that humility about our beliefs could spread
ANDERSON: Danny kahneman it's been an extraordinary treat to have you for so long thank you for the generosity of your time and the generosity of your life and for the brilliance and wisdom you've brought to so many people thank you very much
KAHNEMAN: Thank you
 
Interview 28. The Observer 2021
Daniel Kahneman, 87, was awarded the Nobel prize in economics in 2002 for his work on the psychology of judgment and decision-making. His first book, Thinking, Fast and Slow, a worldwide bestseller, set out his revolutionary ideas about human error and bias and how those traits might be recognised and mitigated. A new book, Noise: A Flaw in Human Judgment, written with Olivier Sibony and Cass R Sunstein, applies those ideas to organisations. This interview took place last week by Zoom with Kahneman at his home in New York.
I guess the pandemic is quite a good place to start. In one way it has been the biggest ever hour-by-hour experiment in global political decision-making. Do you think it’s a watershed moment in the understanding that we need to “listen to science”?
Yes and no, because clearly, not listening to science is bad. On the other hand, it took science quite a while to get its act together.
One of the key problems seems to have been the widespread inability to grasp the basic idea of exponential growth. Does that surprise you?
Exponential phenomena are almost impossible for us to grasp. We are very experienced in a more or less linear world. And if things are accelerating, they’re usually accelerating within reason. Exponential change [as with the spread of the virus] is really something else. We’re not equipped for it. It takes a long time to educate intuition.
Do you think the cacophony of opinion on social media exacerbates that?
I know too little about social media, there’s just too large a generational gap. But clearly the potential for misinformation to spread has grown. It’s a new kind of media that has essentially no responsibility for accuracy and not even reputational controls.
Could you define what you mean by “noise” in the book, in layman’s terms – how does it differ from things like subjectivity or error?
Our main subject is really system noise. System noise is not a phenomenon within the individual, it’s a phenomenon within an organisation or within a system that is supposed to come to decisions that are uniform. It’s really a very different thing from subjectivity or bias. You have to look statistically at a great number of cases. And then you see noise.
Some of the examples you describe – the extraordinary variance seen in sentencing for the same crimes (even influenced by such external matters as the weather, or the weekend football results), say, or the massive discrepancies in insurance underwriting or medical diagnosis or job interviews based on the same baseline information – are shocking. The driver of that noise often seems to lie with the protected status of the “experts” doing the choosing. No judge, I imagine, wants to acknowledge that an algorithm would be fairer at delivering justice?
The judicial system, I think, is special in a way, because it’s some “wise” person who is deciding. You have a lot of noise in medicine, but in medicine, there is an objective criterion of truth.
Have you been on a jury yourself – or spent much time in courtrooms?
I haven’t. But I have had many conversations with judges about the possibility of doing research on how noise affects their judgment. But, you know, it’s not in the interest of the judicial community to investigate themselves.
I suppose people are instinctively or emotionally still more inclined to trust human systems than more abstract processes?
That is certainly the case. We see that, for example, in terms of the attitude to vaccination. People are willing to take far, far fewer risks when they face vaccination than when they face the disease. So this gap between the natural and the artificial is found everywhere. In part that is because when artificial intelligence makes a mistake, that mistake looks completely foolish to humans, or almost evil.
You don’t talk about driverless cars in your analysis. But that, I guess, is becoming a key arena of this argument, isn’t it? However much safer automated cars might be statistically, every time they cause an accident, it will be excessively magnified?
Being a lot safer than people is not going to be enough. The factor by which they have to be more safe than humans is really very high.
It’s 50 years since you and the late Amos Tversky first started researching these questions. Do you feel that your conclusions about measurable human bias and fallibility should have been more widely understood by now?
You know, we didn’t have any particular expectations of changing the world when we did our research. And my own experience of how little this knowledge has changed the quality of my own judgment can be sobering. Avoiding noise in judgment is not really something individuals are going to be very good at. I really put my faith, if there is any faith to be placed, in organisations.
I wonder if you see your work in almost a satirical tradition, highlighting human folly?
Not really. I see myself as really quite an objective psychologist. Obviously, humans are limited. But they’re also pretty marvellous. In Thinking, Fast and Slow, I really was trying to talk about the marvels of intuitive thinking and not only about its flaws – but flaws are more amusing so there is more attention paid there.
One of the things that struck me reading the book is that however much individuals and organisations profess the desire to be efficient and rational, there’s a fundamental part of us that is bored by predictability and just wants to roll the dice. Do you think you take enough account of that?
There are many domains where you really want diversity and creativity. But there is also a need for uniformity in well-defined tasks. If the effort to achieve uniformity gets people unmotivated, or if it becomes excessively bureaucratic, that in itself can be a problem. That is something that organisations are going to have to negotiate.
I was struck watching the American elections by just how often politicians of both sides appealed to God for guidance or help. You don’t talk about religion in the book, but does supernatural faith add to noise?
I think there is less difference between religion and other belief systems than we think. We all like to believe we’re in direct contact with truth. I will say that in some respects my belief in science is not very different from the belief other people have in religion. I mean, I believe in climate change, but I have no idea about it really. What I believe in is the institutions and methods of people who tell me there is climate change. We shouldn’t think that because we are not religious, that makes us so much cleverer than religious people. The arrogance of scientists is something I think about a lot.
When linear people are faced with exponential change, they’re not going to be able to adapt very easily
You end your book with some ideas for eliminating noise, creating checklists for decision making, having “designated decision observers” and so on. I was reminded of those studies that show how corporate efforts to reduce unconscious racial and gender bias through compulsory training have been either ineffective or counter-productive. How do you take account of such unforeseen consequences?
There is always a risk of that. And those ideas you mention are largely untested but, we think, worth considering. Others in the book are founded on more experience, are more solid.
Do you feel that there are wider dangers in using data and AI to augment or replace human judgment?
There are going to be massive consequences of that change that are already beginning to happen. Some medical specialties are clearly in danger of being replaced, certainly in terms of diagnosis. And there are rather frightening scenarios when you’re talking about leadership. Once it’s demonstrably true that you can have an AI that has far better business judgment, say, what will that do to human leadership?
Are we already seeing a backlash against that? I guess one way of understanding the election victories of Trump and Johnson is as a reaction against an increasingly complex world of information – their appeal is that they are simple impulsive chancers. Are we likely to see more of that populism?
I have learned never to make forecasts. Not only can I certainly not do it – I’m not sure it can be done. But one thing that looks very likely is that these huge changes are not going to happen quietly. There is going to be massive disruption. The technology is developing very rapidly, possibly exponentially. But people are linear. When linear people are faced with exponential change, they’re not going to be able to adapt to that very easily. So clearly, something is coming… And clearly AI is going to win [against human intelligence]. It’s not even close. How people are going to adjust to this is a fascinating problem – but one for my children and grandchildren, not me.
Your own life began in even more extreme uncertainty – as a boy in occupied France: your father was first arrested by the Nazis as a Jew, then spared and your family escaped into hiding. How much of your lifelong interest in these questions – the need to understand human motivations – was rooted in those anxieties and fears do you think?
When I look back, I think I was always going to be a psychologist. I had curiosity from a really early age about how the mind works. I don’t think that my personal history had much to do with it though, it was always there.
Do you feel that you’re fundamentally still the child that you were when you were six or seven?
Yes. There’s certainly a continuity. I can still recognise something within myself.
When you embarked on this work, could you imagine you would still be hard at it at 87?
No, I imagined I would be dead! But to my surprise, I still have the same curiosity. I’m collaborating on several projects and investigations since I finished the book. One is how the inability to solve the famous “bat and ball problem” correlates with belief in God and that 9/11 was a conspiracy. It’s all as fun to me as it ever was.





